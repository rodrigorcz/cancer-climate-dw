{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "6ba8cbc5",
   "metadata": {},
   "source": [
    "# ETL\n",
    "\n",
    "## Definição da Constelação de Fatos\n",
    "\n",
    "**Tabelas de dimensão**\n",
    "\n",
    "- dim_data (data_pk, data_completa, data_dia, data_mes, data_semestre, data_ano)\n",
    "- dim_localidade (localidade_pk, latitude, longitude, cidade, estado, regiao, pais)\n",
    "- dim_tipo_cancer (tipo_cancer_pk, tipo_cancer, mortalidade, taxa_incidencia_total)\n",
    "- dim_faixa_etaria (faixa_pk, faixa_idade, idade_min, idade_max, id_idade)\n",
    "- dim_metrica (metrica_pk, tipo_metrica)\n",
    "- dim_sexo (sexo_pk, sexo)\n",
    "\n",
    "**Tabelas de fatos**\n",
    "\n",
    "- fato_cancer (ano_pk, estado_pk, tipo_cancer_pk, sexo_pk, faixa_pk, metrica_pk, obitos_cancer, incidencia_cancer, prevalencia_cancer)\n",
    "- fato_clima (data_pk, localidade_pk, temperatura_media, temperatura_max, temperatura_min, radiacao_uv, radiacao_uva, radiacao_uvb, precipitacao)\n",
    "\n",
    "**Views**\n",
    "\n",
    "- vw_cidade (localidade_pk, latitude, longitude, clima_cidade, clima_estado, clima_regiao, clima_pais)\n",
    "- vw_estado (estado_pk, cancer_regiao, cancer_pais)\n",
    "- vw_dia (data_pk, clima_data_completa, clima_dia, clima_mes, clima_semestre, clima_ano)\n",
    "- vw_ano (ano_pk, cancer_ano, cancer_decada)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6a96bd58",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from pyspark.sql.types import StructType, StructField, IntegerType, StringType, DoubleType\n",
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql import functions as F\n",
    "from pyspark.sql.window import Window\n",
    "from dotenv import load_dotenv\n",
    "import psycopg2\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f4eaecfd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ":: loading settings :: url = jar:file:/home/rodrigo/.local/lib/python3.11/site-packages/pyspark/jars/ivy-2.5.1.jar!/org/apache/ivy/core/settings/ivysettings.xml\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Ivy Default Cache set to: /home/rodrigo/.ivy2/cache\n",
      "The jars for the packages stored in: /home/rodrigo/.ivy2/jars\n",
      "org.apache.hadoop#hadoop-aws added as a dependency\n",
      "com.amazonaws#aws-java-sdk-bundle added as a dependency\n",
      ":: resolving dependencies :: org.apache.spark#spark-submit-parent-9dc84400-7eb6-4561-b034-755dc34c16b6;1.0\n",
      "\tconfs: [default]\n",
      "\tfound org.apache.hadoop#hadoop-aws;3.3.4 in central\n",
      "\tfound com.amazonaws#aws-java-sdk-bundle;1.12.262 in central\n",
      "\tfound org.wildfly.openssl#wildfly-openssl;1.0.7.Final in central\n",
      ":: resolution report :: resolve 736ms :: artifacts dl 10ms\n",
      "\t:: modules in use:\n",
      "\tcom.amazonaws#aws-java-sdk-bundle;1.12.262 from central in [default]\n",
      "\torg.apache.hadoop#hadoop-aws;3.3.4 from central in [default]\n",
      "\torg.wildfly.openssl#wildfly-openssl;1.0.7.Final from central in [default]\n",
      "\t:: evicted modules:\n",
      "\tcom.amazonaws#aws-java-sdk-bundle;1.11.1026 by [com.amazonaws#aws-java-sdk-bundle;1.12.262] in [default]\n",
      "\t---------------------------------------------------------------------\n",
      "\t|                  |            modules            ||   artifacts   |\n",
      "\t|       conf       | number| search|dwnlded|evicted|| number|dwnlded|\n",
      "\t---------------------------------------------------------------------\n",
      "\t|      default     |   4   |   0   |   0   |   1   ||   3   |   0   |\n",
      "\t---------------------------------------------------------------------\n",
      ":: retrieving :: org.apache.spark#spark-submit-parent-9dc84400-7eb6-4561-b034-755dc34c16b6\n",
      "\tconfs: [default]\n",
      "\t0 artifacts copied, 3 already retrieved (0kB/9ms)\n",
      "25/06/27 09:16:20 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable\n",
      "25/06/27 09:16:21 WARN DependencyUtils: Local jar /home/rodrigo/jars/postgresql-42.7.3.jar does not exist, skipping.\n",
      "25/06/27 09:16:22 INFO SparkContext: Running Spark version 3.4.0\n",
      "25/06/27 09:16:22 INFO ResourceUtils: ==============================================================\n",
      "25/06/27 09:16:22 INFO ResourceUtils: No custom resources configured for spark.driver.\n",
      "25/06/27 09:16:22 INFO ResourceUtils: ==============================================================\n",
      "25/06/27 09:16:22 INFO SparkContext: Submitted application: OLAP - P2\n",
      "25/06/27 09:16:22 INFO ResourceProfile: Default ResourceProfile created, executor resources: Map(cores -> name: cores, amount: 1, script: , vendor: , memory -> name: memory, amount: 1024, script: , vendor: , offHeap -> name: offHeap, amount: 0, script: , vendor: ), task resources: Map(cpus -> name: cpus, amount: 1.0)\n",
      "25/06/27 09:16:22 INFO ResourceProfile: Limiting resource is cpu\n",
      "25/06/27 09:16:22 INFO ResourceProfileManager: Added ResourceProfile id: 0\n",
      "25/06/27 09:16:22 INFO SecurityManager: Changing view acls to: rodrigo\n",
      "25/06/27 09:16:22 INFO SecurityManager: Changing modify acls to: rodrigo\n",
      "25/06/27 09:16:22 INFO SecurityManager: Changing view acls groups to: \n",
      "25/06/27 09:16:22 INFO SecurityManager: Changing modify acls groups to: \n",
      "25/06/27 09:16:22 INFO SecurityManager: SecurityManager: authentication disabled; ui acls disabled; users with view permissions: rodrigo; groups with view permissions: EMPTY; users with modify permissions: rodrigo; groups with modify permissions: EMPTY\n",
      "25/06/27 09:16:23 INFO Utils: Successfully started service 'sparkDriver' on port 42837.\n",
      "25/06/27 09:16:23 INFO SparkEnv: Registering MapOutputTracker\n",
      "25/06/27 09:16:23 INFO SparkEnv: Registering BlockManagerMaster\n",
      "25/06/27 09:16:23 INFO BlockManagerMasterEndpoint: Using org.apache.spark.storage.DefaultTopologyMapper for getting topology information\n",
      "25/06/27 09:16:23 INFO BlockManagerMasterEndpoint: BlockManagerMasterEndpoint up\n",
      "25/06/27 09:16:23 INFO SparkEnv: Registering BlockManagerMasterHeartbeat\n",
      "25/06/27 09:16:23 INFO DiskBlockManager: Created local directory at /tmp/blockmgr-f37b58be-686b-4c3d-92ce-a6eda9464c7a\n",
      "25/06/27 09:16:23 INFO MemoryStore: MemoryStore started with capacity 434.4 MiB\n",
      "25/06/27 09:16:23 INFO SparkEnv: Registering OutputCommitCoordinator\n",
      "25/06/27 09:16:23 INFO JettyUtils: Start Jetty 0.0.0.0:4040 for SparkUI\n",
      "25/06/27 09:16:24 WARN Utils: Service 'SparkUI' could not bind on port 4040. Attempting port 4041.\n",
      "25/06/27 09:16:24 INFO Utils: Successfully started service 'SparkUI' on port 4041.\n",
      "25/06/27 09:16:24 ERROR SparkContext: Failed to add /home/rodrigo/jars/postgresql-42.7.3.jar to Spark environment\n",
      "java.io.FileNotFoundException: Jar /home/rodrigo/jars/postgresql-42.7.3.jar not found\n",
      "\tat org.apache.spark.SparkContext.addLocalJarFile$1(SparkContext.scala:1968)\n",
      "\tat org.apache.spark.SparkContext.addJar(SparkContext.scala:2023)\n",
      "\tat org.apache.spark.SparkContext.$anonfun$new$12(SparkContext.scala:507)\n",
      "\tat org.apache.spark.SparkContext.$anonfun$new$12$adapted(SparkContext.scala:507)\n",
      "\tat scala.collection.mutable.ResizableArray.foreach(ResizableArray.scala:62)\n",
      "\tat scala.collection.mutable.ResizableArray.foreach$(ResizableArray.scala:55)\n",
      "\tat scala.collection.mutable.ArrayBuffer.foreach(ArrayBuffer.scala:49)\n",
      "\tat org.apache.spark.SparkContext.<init>(SparkContext.scala:507)\n",
      "\tat org.apache.spark.api.java.JavaSparkContext.<init>(JavaSparkContext.scala:58)\n",
      "\tat java.base/jdk.internal.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method)\n",
      "\tat java.base/jdk.internal.reflect.NativeConstructorAccessorImpl.newInstance(NativeConstructorAccessorImpl.java:62)\n",
      "\tat java.base/jdk.internal.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45)\n",
      "\tat java.base/java.lang.reflect.Constructor.newInstance(Constructor.java:490)\n",
      "\tat py4j.reflection.MethodInvoker.invoke(MethodInvoker.java:247)\n",
      "\tat py4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:374)\n",
      "\tat py4j.Gateway.invoke(Gateway.java:238)\n",
      "\tat py4j.commands.ConstructorCommand.invokeConstructor(ConstructorCommand.java:80)\n",
      "\tat py4j.commands.ConstructorCommand.execute(ConstructorCommand.java:69)\n",
      "\tat py4j.ClientServerConnection.waitForCommands(ClientServerConnection.java:182)\n",
      "\tat py4j.ClientServerConnection.run(ClientServerConnection.java:106)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:829)\n",
      "25/06/27 09:16:24 INFO SparkContext: Added file file:///home/rodrigo/.ivy2/jars/org.apache.hadoop_hadoop-aws-3.3.4.jar at file:///home/rodrigo/.ivy2/jars/org.apache.hadoop_hadoop-aws-3.3.4.jar with timestamp 1751026581992\n",
      "25/06/27 09:16:24 INFO Utils: Copying /home/rodrigo/.ivy2/jars/org.apache.hadoop_hadoop-aws-3.3.4.jar to /tmp/spark-31ba9380-36db-4954-9948-bfe14e3daf3d/userFiles-dff658e8-3234-418d-af2e-3ce0fa18f1f5/org.apache.hadoop_hadoop-aws-3.3.4.jar\n",
      "25/06/27 09:16:24 INFO SparkContext: Added file file:///home/rodrigo/.ivy2/jars/com.amazonaws_aws-java-sdk-bundle-1.12.262.jar at file:///home/rodrigo/.ivy2/jars/com.amazonaws_aws-java-sdk-bundle-1.12.262.jar with timestamp 1751026581992\n",
      "25/06/27 09:16:24 INFO Utils: Copying /home/rodrigo/.ivy2/jars/com.amazonaws_aws-java-sdk-bundle-1.12.262.jar to /tmp/spark-31ba9380-36db-4954-9948-bfe14e3daf3d/userFiles-dff658e8-3234-418d-af2e-3ce0fa18f1f5/com.amazonaws_aws-java-sdk-bundle-1.12.262.jar\n",
      "25/06/27 09:16:24 INFO SparkContext: Added file file:///home/rodrigo/.ivy2/jars/org.wildfly.openssl_wildfly-openssl-1.0.7.Final.jar at file:///home/rodrigo/.ivy2/jars/org.wildfly.openssl_wildfly-openssl-1.0.7.Final.jar with timestamp 1751026581992\n",
      "25/06/27 09:16:24 INFO Utils: Copying /home/rodrigo/.ivy2/jars/org.wildfly.openssl_wildfly-openssl-1.0.7.Final.jar to /tmp/spark-31ba9380-36db-4954-9948-bfe14e3daf3d/userFiles-dff658e8-3234-418d-af2e-3ce0fa18f1f5/org.wildfly.openssl_wildfly-openssl-1.0.7.Final.jar\n",
      "25/06/27 09:16:25 INFO Executor: Starting executor ID driver on host hal9000\n",
      "25/06/27 09:16:25 INFO Executor: Starting executor with user classpath (userClassPathFirst = false): ''\n",
      "25/06/27 09:16:25 INFO Executor: Fetching file:///home/rodrigo/.ivy2/jars/org.wildfly.openssl_wildfly-openssl-1.0.7.Final.jar with timestamp 1751026581992\n",
      "25/06/27 09:16:25 INFO Utils: /home/rodrigo/.ivy2/jars/org.wildfly.openssl_wildfly-openssl-1.0.7.Final.jar has been previously copied to /tmp/spark-31ba9380-36db-4954-9948-bfe14e3daf3d/userFiles-dff658e8-3234-418d-af2e-3ce0fa18f1f5/org.wildfly.openssl_wildfly-openssl-1.0.7.Final.jar\n",
      "25/06/27 09:16:25 INFO Executor: Fetching file:///home/rodrigo/.ivy2/jars/com.amazonaws_aws-java-sdk-bundle-1.12.262.jar with timestamp 1751026581992\n",
      "25/06/27 09:16:25 INFO Utils: /home/rodrigo/.ivy2/jars/com.amazonaws_aws-java-sdk-bundle-1.12.262.jar has been previously copied to /tmp/spark-31ba9380-36db-4954-9948-bfe14e3daf3d/userFiles-dff658e8-3234-418d-af2e-3ce0fa18f1f5/com.amazonaws_aws-java-sdk-bundle-1.12.262.jar\n",
      "25/06/27 09:16:25 INFO Executor: Fetching file:///home/rodrigo/.ivy2/jars/org.apache.hadoop_hadoop-aws-3.3.4.jar with timestamp 1751026581992\n",
      "25/06/27 09:16:25 INFO Utils: /home/rodrigo/.ivy2/jars/org.apache.hadoop_hadoop-aws-3.3.4.jar has been previously copied to /tmp/spark-31ba9380-36db-4954-9948-bfe14e3daf3d/userFiles-dff658e8-3234-418d-af2e-3ce0fa18f1f5/org.apache.hadoop_hadoop-aws-3.3.4.jar\n",
      "25/06/27 09:16:25 INFO Utils: Successfully started service 'org.apache.spark.network.netty.NettyBlockTransferService' on port 34557.\n",
      "25/06/27 09:16:25 INFO NettyBlockTransferService: Server created on hal9000:34557\n",
      "25/06/27 09:16:25 INFO BlockManager: Using org.apache.spark.storage.RandomBlockReplicationPolicy for block replication policy\n",
      "25/06/27 09:16:25 INFO BlockManagerMaster: Registering BlockManager BlockManagerId(driver, hal9000, 34557, None)\n",
      "25/06/27 09:16:25 INFO BlockManagerMasterEndpoint: Registering block manager hal9000:34557 with 434.4 MiB RAM, BlockManagerId(driver, hal9000, 34557, None)\n",
      "25/06/27 09:16:25 INFO BlockManagerMaster: Registered BlockManager BlockManagerId(driver, hal9000, 34557, None)\n",
      "25/06/27 09:16:25 INFO BlockManager: Initialized BlockManager: BlockManagerId(driver, hal9000, 34557, None)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3.4.0\n"
     ]
    }
   ],
   "source": [
    "# Python 3.11\n",
    "# Java 11\n",
    "# PySpark == 3.4\n",
    "\n",
    "spark = SparkSession.builder \\\n",
    "    .appName(\"OLAP - P2\") \\\n",
    "    .config(\"spark.jars.packages\",\n",
    "            \"org.apache.hadoop:hadoop-aws:3.3.4,\"\n",
    "            \"com.amazonaws:aws-java-sdk-bundle:1.11.1026\") \\\n",
    "    .config(\"spark.jars\", \"/home/rodrigo/jars/postgresql-42.7.3.jar\") \\\n",
    "    .config(\"spark.jars.ivyLogLevel\", \"ERROR\") \\\n",
    "    .config(\"spark.hadoop.fs.s3a.endpoint\", \"http://localhost:9000\") \\\n",
    "    .config(\"spark.hadoop.fs.s3a.access.key\", \"minioadmin\") \\\n",
    "    .config(\"spark.hadoop.fs.s3a.secret.key\", \"minioadmin\") \\\n",
    "    .config(\"spark.hadoop.fs.s3a.path.style.access\", \"true\") \\\n",
    "    .config(\"spark.hadoop.fs.s3a.impl\", \"org.apache.hadoop.fs.s3a.S3AFileSystem\") \\\n",
    "    .config(\"spark.hadoop.fs.s3a.connection.ssl.enabled\", \"false\") \\\n",
    "    .getOrCreate()\n",
    "\n",
    "print(spark.version)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4b264e8c",
   "metadata": {},
   "source": [
    "## Extract"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "bc5bd568",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "25/06/27 09:16:26 INFO SharedState: Setting hive.metastore.warehouse.dir ('null') to the value of spark.sql.warehouse.dir.\n",
      "25/06/27 09:16:26 INFO SharedState: Warehouse path is 'file:/home/rodrigo/Projects/cancer-climate-dw/spark-warehouse'.\n",
      "25/06/27 09:16:29 WARN MetricsConfig: Cannot locate configuration: tried hadoop-metrics2-s3a-file-system.properties,hadoop-metrics2.properties\n",
      "25/06/27 09:16:29 INFO MetricsSystemImpl: Scheduled Metric snapshot period at 10 second(s).\n",
      "25/06/27 09:16:29 INFO MetricsSystemImpl: s3a-file-system metrics system started\n",
      "25/06/27 09:16:31 INFO InMemoryFileIndex: It took 187 ms to list leaf files for 1 paths.\n",
      "25/06/27 09:16:35 INFO InMemoryFileIndex: It took 19 ms to list leaf files for 1 paths.\n",
      "25/06/27 09:16:36 INFO FileSourceStrategy: Pushed Filters: \n",
      "25/06/27 09:16:36 INFO FileSourceStrategy: Post-Scan Filters: \n",
      "25/06/27 09:16:36 INFO FileSourceStrategy: Pushed Filters: \n",
      "25/06/27 09:16:36 INFO FileSourceStrategy: Post-Scan Filters: \n",
      "25/06/27 09:16:37 INFO CodeGenerator: Code generated in 472.010714 ms\n",
      "25/06/27 09:16:38 INFO MemoryStore: Block broadcast_0 stored as values in memory (estimated size 203.2 KiB, free 434.2 MiB)\n",
      "25/06/27 09:16:38 INFO MemoryStore: Block broadcast_0_piece0 stored as bytes in memory (estimated size 35.4 KiB, free 434.2 MiB)\n",
      "25/06/27 09:16:38 INFO BlockManagerInfo: Added broadcast_0_piece0 in memory on hal9000:34557 (size: 35.4 KiB, free: 434.4 MiB)\n",
      "25/06/27 09:16:38 INFO SparkContext: Created broadcast 0 from count at NativeMethodAccessorImpl.java:0\n",
      "25/06/27 09:16:38 INFO FileSourceScanExec: Planning scan with bin packing, max size: 11024413 bytes, open cost is considered as scanning 4194304 bytes.\n",
      "25/06/27 09:16:38 INFO MemoryStore: Block broadcast_1 stored as values in memory (estimated size 203.2 KiB, free 434.0 MiB)\n",
      "25/06/27 09:16:38 INFO MemoryStore: Block broadcast_1_piece0 stored as bytes in memory (estimated size 35.4 KiB, free 433.9 MiB)\n",
      "25/06/27 09:16:38 INFO BlockManagerInfo: Added broadcast_1_piece0 in memory on hal9000:34557 (size: 35.4 KiB, free: 434.3 MiB)\n",
      "25/06/27 09:16:38 INFO SparkContext: Created broadcast 1 from count at NativeMethodAccessorImpl.java:0\n",
      "25/06/27 09:16:38 INFO FileSourceScanExec: Planning scan with bin packing, max size: 4194304 bytes, open cost is considered as scanning 4194304 bytes.\n",
      "25/06/27 09:16:38 INFO DAGScheduler: Registering RDD 6 (count at NativeMethodAccessorImpl.java:0) as input to shuffle 0\n",
      "25/06/27 09:16:38 INFO DAGScheduler: Got map stage job 0 (count at NativeMethodAccessorImpl.java:0) with 9 output partitions\n",
      "25/06/27 09:16:38 INFO DAGScheduler: Final stage: ShuffleMapStage 0 (count at NativeMethodAccessorImpl.java:0)\n",
      "25/06/27 09:16:38 INFO DAGScheduler: Parents of final stage: List()\n",
      "25/06/27 09:16:38 INFO DAGScheduler: Missing parents: List()\n",
      "25/06/27 09:16:38 INFO DAGScheduler: Submitting ShuffleMapStage 0 (MapPartitionsRDD[6] at count at NativeMethodAccessorImpl.java:0), which has no missing parents\n",
      "25/06/27 09:16:39 INFO MemoryStore: Block broadcast_2 stored as values in memory (estimated size 19.4 KiB, free 433.9 MiB)\n",
      "25/06/27 09:16:39 INFO MemoryStore: Block broadcast_2_piece0 stored as bytes in memory (estimated size 9.6 KiB, free 433.9 MiB)\n",
      "25/06/27 09:16:39 INFO BlockManagerInfo: Added broadcast_2_piece0 in memory on hal9000:34557 (size: 9.6 KiB, free: 434.3 MiB)\n",
      "25/06/27 09:16:39 INFO SparkContext: Created broadcast 2 from broadcast at DAGScheduler.scala:1535\n",
      "25/06/27 09:16:39 INFO DAGScheduler: Submitting 9 missing tasks from ShuffleMapStage 0 (MapPartitionsRDD[6] at count at NativeMethodAccessorImpl.java:0) (first 15 tasks are for partitions Vector(0, 1, 2, 3, 4, 5, 6, 7, 8))\n",
      "25/06/27 09:16:39 INFO TaskSchedulerImpl: Adding task set 0.0 with 9 tasks resource profile 0\n",
      "25/06/27 09:16:39 INFO TaskSetManager: Starting task 0.0 in stage 0.0 (TID 0) (hal9000, executor driver, partition 0, PROCESS_LOCAL, 8005 bytes) \n",
      "25/06/27 09:16:39 INFO TaskSetManager: Starting task 1.0 in stage 0.0 (TID 1) (hal9000, executor driver, partition 1, PROCESS_LOCAL, 8005 bytes) \n",
      "25/06/27 09:16:39 INFO TaskSetManager: Starting task 2.0 in stage 0.0 (TID 2) (hal9000, executor driver, partition 2, PROCESS_LOCAL, 8005 bytes) \n",
      "25/06/27 09:16:39 INFO TaskSetManager: Starting task 3.0 in stage 0.0 (TID 3) (hal9000, executor driver, partition 3, PROCESS_LOCAL, 8005 bytes) \n",
      "25/06/27 09:16:39 INFO TaskSetManager: Starting task 4.0 in stage 0.0 (TID 4) (hal9000, executor driver, partition 4, PROCESS_LOCAL, 8005 bytes) \n",
      "25/06/27 09:16:39 INFO TaskSetManager: Starting task 5.0 in stage 0.0 (TID 5) (hal9000, executor driver, partition 5, PROCESS_LOCAL, 8005 bytes) \n",
      "25/06/27 09:16:39 INFO TaskSetManager: Starting task 6.0 in stage 0.0 (TID 6) (hal9000, executor driver, partition 6, PROCESS_LOCAL, 8005 bytes) \n",
      "25/06/27 09:16:39 INFO TaskSetManager: Starting task 7.0 in stage 0.0 (TID 7) (hal9000, executor driver, partition 7, PROCESS_LOCAL, 8005 bytes) \n",
      "25/06/27 09:16:39 INFO Executor: Running task 2.0 in stage 0.0 (TID 2)\n",
      "25/06/27 09:16:39 INFO Executor: Running task 7.0 in stage 0.0 (TID 7)\n",
      "25/06/27 09:16:39 INFO Executor: Running task 4.0 in stage 0.0 (TID 4)\n",
      "25/06/27 09:16:39 INFO Executor: Running task 5.0 in stage 0.0 (TID 5)\n",
      "25/06/27 09:16:39 INFO Executor: Running task 3.0 in stage 0.0 (TID 3)\n",
      "25/06/27 09:16:39 INFO Executor: Running task 0.0 in stage 0.0 (TID 0)\n",
      "25/06/27 09:16:39 INFO Executor: Running task 6.0 in stage 0.0 (TID 6)\n",
      "25/06/27 09:16:39 INFO Executor: Running task 1.0 in stage 0.0 (TID 1)\n",
      "25/06/27 09:16:39 INFO FileScanRDD: Reading File path: s3a://datalake/cancer-1.csv, range: 55122065-66146478, partition values: [empty row]\n",
      "25/06/27 09:16:39 INFO FileScanRDD: Reading File path: s3a://datalake/cancer-1.csv, range: 22048826-33073239, partition values: [empty row]\n",
      "25/06/27 09:16:39 INFO FileScanRDD: Reading File path: s3a://datalake/cancer-1.csv, range: 77170891-84001007, partition values: [empty row]\n",
      "25/06/27 09:16:39 INFO FileScanRDD: Reading File path: s3a://datalake/cancer-1.csv, range: 44097652-55122065, partition values: [empty row]\n",
      "25/06/27 09:16:39 INFO FileScanRDD: Reading File path: s3a://datalake/cancer-1.csv, range: 66146478-77170891, partition values: [empty row]\n",
      "25/06/27 09:16:39 INFO FileScanRDD: Reading File path: s3a://datalake/cancer-1.csv, range: 33073239-44097652, partition values: [empty row]\n",
      "25/06/27 09:16:39 INFO FileScanRDD: Reading File path: s3a://datalake/cancer-1.csv, range: 0-11024413, partition values: [empty row]\n",
      "25/06/27 09:16:39 INFO FileScanRDD: Reading File path: s3a://datalake/cancer-1.csv, range: 11024413-22048826, partition values: [empty row]\n",
      "25/06/27 09:16:39 INFO CodeGenerator: Code generated in 43.5818 ms\n",
      "25/06/27 09:16:41 INFO Executor: Finished task 7.0 in stage 0.0 (TID 7). 2065 bytes result sent to driver\n",
      "25/06/27 09:16:41 INFO Executor: Finished task 0.0 in stage 0.0 (TID 0). 2065 bytes result sent to driver\n",
      "25/06/27 09:16:41 INFO Executor: Finished task 4.0 in stage 0.0 (TID 4). 2022 bytes result sent to driver\n",
      "25/06/27 09:16:41 INFO Executor: Finished task 3.0 in stage 0.0 (TID 3). 2065 bytes result sent to driver\n",
      "25/06/27 09:16:41 INFO Executor: Finished task 6.0 in stage 0.0 (TID 6). 2022 bytes result sent to driver\n",
      "25/06/27 09:16:41 INFO TaskSetManager: Starting task 8.0 in stage 0.0 (TID 8) (hal9000, executor driver, partition 8, PROCESS_LOCAL, 8005 bytes) \n",
      "25/06/27 09:16:41 INFO Executor: Running task 8.0 in stage 0.0 (TID 8)\n",
      "25/06/27 09:16:41 INFO FileScanRDD: Reading File path: s3a://datalake/cancer-2.csv, range: 0-3668986, partition values: [empty row]\n",
      "25/06/27 09:16:41 INFO Executor: Finished task 1.0 in stage 0.0 (TID 1). 2022 bytes result sent to driver\n",
      "25/06/27 09:16:41 INFO TaskSetManager: Finished task 3.0 in stage 0.0 (TID 3) in 2204 ms on hal9000 (executor driver) (1/9)\n",
      "25/06/27 09:16:41 INFO TaskSetManager: Finished task 7.0 in stage 0.0 (TID 7) in 2205 ms on hal9000 (executor driver) (2/9)\n",
      "25/06/27 09:16:41 INFO TaskSetManager: Finished task 1.0 in stage 0.0 (TID 1) in 2221 ms on hal9000 (executor driver) (3/9)\n",
      "25/06/27 09:16:41 INFO TaskSetManager: Finished task 4.0 in stage 0.0 (TID 4) in 2219 ms on hal9000 (executor driver) (4/9)\n",
      "25/06/27 09:16:41 INFO TaskSetManager: Finished task 6.0 in stage 0.0 (TID 6) in 2207 ms on hal9000 (executor driver) (5/9)\n",
      "25/06/27 09:16:41 INFO TaskSetManager: Finished task 0.0 in stage 0.0 (TID 0) in 2278 ms on hal9000 (executor driver) (6/9)\n",
      "25/06/27 09:16:41 INFO Executor: Finished task 5.0 in stage 0.0 (TID 5). 2022 bytes result sent to driver\n",
      "25/06/27 09:16:41 INFO TaskSetManager: Finished task 5.0 in stage 0.0 (TID 5) in 2282 ms on hal9000 (executor driver) (7/9)\n",
      "25/06/27 09:16:41 INFO Executor: Finished task 2.0 in stage 0.0 (TID 2). 2022 bytes result sent to driver\n",
      "25/06/27 09:16:41 INFO TaskSetManager: Finished task 2.0 in stage 0.0 (TID 2) in 2356 ms on hal9000 (executor driver) (8/9)\n",
      "25/06/27 09:16:41 INFO Executor: Finished task 8.0 in stage 0.0 (TID 8). 1979 bytes result sent to driver\n",
      "25/06/27 09:16:41 INFO TaskSetManager: Finished task 8.0 in stage 0.0 (TID 8) in 233 ms on hal9000 (executor driver) (9/9)\n",
      "25/06/27 09:16:41 INFO TaskSchedulerImpl: Removed TaskSet 0.0, whose tasks have all completed, from pool \n",
      "25/06/27 09:16:41 INFO DAGScheduler: ShuffleMapStage 0 (count at NativeMethodAccessorImpl.java:0) finished in 3.041 s\n",
      "25/06/27 09:16:41 INFO DAGScheduler: looking for newly runnable stages\n",
      "25/06/27 09:16:41 INFO DAGScheduler: running: Set()\n",
      "25/06/27 09:16:41 INFO DAGScheduler: waiting: Set()\n",
      "25/06/27 09:16:41 INFO DAGScheduler: failed: Set()\n",
      "25/06/27 09:16:42 INFO CodeGenerator: Code generated in 33.868975 ms\n",
      "25/06/27 09:16:42 INFO SparkContext: Starting job: count at NativeMethodAccessorImpl.java:0\n",
      "25/06/27 09:16:42 INFO DAGScheduler: Got job 1 (count at NativeMethodAccessorImpl.java:0) with 1 output partitions\n",
      "25/06/27 09:16:42 INFO DAGScheduler: Final stage: ResultStage 2 (count at NativeMethodAccessorImpl.java:0)\n",
      "25/06/27 09:16:42 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 1)\n",
      "25/06/27 09:16:42 INFO DAGScheduler: Missing parents: List()\n",
      "25/06/27 09:16:42 INFO DAGScheduler: Submitting ResultStage 2 (MapPartitionsRDD[9] at count at NativeMethodAccessorImpl.java:0), which has no missing parents\n",
      "25/06/27 09:16:42 INFO MemoryStore: Block broadcast_3 stored as values in memory (estimated size 12.1 KiB, free 433.9 MiB)\n",
      "25/06/27 09:16:42 INFO MemoryStore: Block broadcast_3_piece0 stored as bytes in memory (estimated size 5.8 KiB, free 433.9 MiB)\n",
      "25/06/27 09:16:42 INFO BlockManagerInfo: Added broadcast_3_piece0 in memory on hal9000:34557 (size: 5.8 KiB, free: 434.3 MiB)\n",
      "25/06/27 09:16:42 INFO SparkContext: Created broadcast 3 from broadcast at DAGScheduler.scala:1535\n",
      "25/06/27 09:16:42 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 2 (MapPartitionsRDD[9] at count at NativeMethodAccessorImpl.java:0) (first 15 tasks are for partitions Vector(0))\n",
      "25/06/27 09:16:42 INFO TaskSchedulerImpl: Adding task set 2.0 with 1 tasks resource profile 0\n",
      "25/06/27 09:16:42 INFO TaskSetManager: Starting task 0.0 in stage 2.0 (TID 9) (hal9000, executor driver, partition 0, NODE_LOCAL, 7363 bytes) \n",
      "25/06/27 09:16:42 INFO Executor: Running task 0.0 in stage 2.0 (TID 9)\n",
      "25/06/27 09:16:42 INFO ShuffleBlockFetcherIterator: Getting 9 (540.0 B) non-empty blocks including 9 (540.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks\n",
      "25/06/27 09:16:42 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 43 ms\n",
      "25/06/27 09:16:42 INFO Executor: Finished task 0.0 in stage 2.0 (TID 9). 4038 bytes result sent to driver\n",
      "25/06/27 09:16:42 INFO TaskSetManager: Finished task 0.0 in stage 2.0 (TID 9) in 184 ms on hal9000 (executor driver) (1/1)\n",
      "25/06/27 09:16:42 INFO TaskSchedulerImpl: Removed TaskSet 2.0, whose tasks have all completed, from pool \n",
      "25/06/27 09:16:42 INFO DAGScheduler: ResultStage 2 (count at NativeMethodAccessorImpl.java:0) finished in 0.205 s\n",
      "25/06/27 09:16:42 INFO DAGScheduler: Job 1 is finished. Cancelling potential speculative or zombie tasks for this job\n",
      "25/06/27 09:16:42 INFO TaskSchedulerImpl: Killing all running tasks in stage 2: Stage finished\n",
      "25/06/27 09:16:42 INFO DAGScheduler: Job 1 finished: count at NativeMethodAccessorImpl.java:0, took 0.248612 s\n",
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Numero de Tuplas:  520506\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "25/06/27 09:16:42 INFO FileSourceStrategy: Pushed Filters: \n",
      "25/06/27 09:16:42 INFO FileSourceStrategy: Post-Scan Filters: \n",
      "25/06/27 09:16:42 INFO FileSourceStrategy: Pushed Filters: \n",
      "25/06/27 09:16:42 INFO FileSourceStrategy: Post-Scan Filters: \n",
      "25/06/27 09:16:42 INFO CodeGenerator: Code generated in 54.690023 ms\n",
      "25/06/27 09:16:42 INFO MemoryStore: Block broadcast_4 stored as values in memory (estimated size 203.2 KiB, free 433.7 MiB)\n",
      "25/06/27 09:16:42 INFO MemoryStore: Block broadcast_4_piece0 stored as bytes in memory (estimated size 35.4 KiB, free 433.7 MiB)\n",
      "25/06/27 09:16:42 INFO BlockManagerInfo: Added broadcast_4_piece0 in memory on hal9000:34557 (size: 35.4 KiB, free: 434.3 MiB)\n",
      "25/06/27 09:16:42 INFO SparkContext: Created broadcast 4 from showString at NativeMethodAccessorImpl.java:0\n",
      "25/06/27 09:16:43 INFO FileSourceScanExec: Planning scan with bin packing, max size: 11024413 bytes, open cost is considered as scanning 4194304 bytes.\n",
      "25/06/27 09:16:43 INFO BlockManagerInfo: Removed broadcast_3_piece0 on hal9000:34557 in memory (size: 5.8 KiB, free: 434.3 MiB)\n",
      "25/06/27 09:16:43 INFO CodeGenerator: Code generated in 134.921808 ms\n",
      "25/06/27 09:16:43 INFO MemoryStore: Block broadcast_5 stored as values in memory (estimated size 203.2 KiB, free 433.5 MiB)\n",
      "25/06/27 09:16:43 INFO BlockManagerInfo: Removed broadcast_2_piece0 on hal9000:34557 in memory (size: 9.6 KiB, free: 434.3 MiB)\n",
      "25/06/27 09:16:43 INFO MemoryStore: Block broadcast_5_piece0 stored as bytes in memory (estimated size 35.4 KiB, free 433.5 MiB)\n",
      "25/06/27 09:16:43 INFO BlockManagerInfo: Added broadcast_5_piece0 in memory on hal9000:34557 (size: 35.4 KiB, free: 434.3 MiB)\n",
      "25/06/27 09:16:43 INFO SparkContext: Created broadcast 5 from showString at NativeMethodAccessorImpl.java:0\n",
      "25/06/27 09:16:43 INFO FileSourceScanExec: Planning scan with bin packing, max size: 4194304 bytes, open cost is considered as scanning 4194304 bytes.\n",
      "25/06/27 09:16:43 INFO SparkContext: Starting job: showString at NativeMethodAccessorImpl.java:0\n",
      "25/06/27 09:16:43 INFO DAGScheduler: Got job 2 (showString at NativeMethodAccessorImpl.java:0) with 1 output partitions\n",
      "25/06/27 09:16:43 INFO DAGScheduler: Final stage: ResultStage 3 (showString at NativeMethodAccessorImpl.java:0)\n",
      "25/06/27 09:16:43 INFO DAGScheduler: Parents of final stage: List()\n",
      "25/06/27 09:16:43 INFO DAGScheduler: Missing parents: List()\n",
      "25/06/27 09:16:43 INFO DAGScheduler: Submitting ResultStage 3 (MapPartitionsRDD[17] at showString at NativeMethodAccessorImpl.java:0), which has no missing parents\n",
      "25/06/27 09:16:43 INFO MemoryStore: Block broadcast_6 stored as values in memory (estimated size 33.8 KiB, free 433.4 MiB)\n",
      "25/06/27 09:16:43 INFO MemoryStore: Block broadcast_6_piece0 stored as bytes in memory (estimated size 11.2 KiB, free 433.4 MiB)\n",
      "25/06/27 09:16:43 INFO BlockManagerInfo: Added broadcast_6_piece0 in memory on hal9000:34557 (size: 11.2 KiB, free: 434.3 MiB)\n",
      "25/06/27 09:16:43 INFO SparkContext: Created broadcast 6 from broadcast at DAGScheduler.scala:1535\n",
      "25/06/27 09:16:43 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 3 (MapPartitionsRDD[17] at showString at NativeMethodAccessorImpl.java:0) (first 15 tasks are for partitions Vector(0))\n",
      "25/06/27 09:16:43 INFO TaskSchedulerImpl: Adding task set 3.0 with 1 tasks resource profile 0\n",
      "25/06/27 09:16:43 INFO TaskSetManager: Starting task 0.0 in stage 3.0 (TID 10) (hal9000, executor driver, partition 0, PROCESS_LOCAL, 8016 bytes) \n",
      "25/06/27 09:16:43 INFO Executor: Running task 0.0 in stage 3.0 (TID 10)\n",
      "25/06/27 09:16:43 INFO FileScanRDD: Reading File path: s3a://datalake/cancer-1.csv, range: 0-11024413, partition values: [empty row]\n",
      "25/06/27 09:16:43 INFO CodeGenerator: Code generated in 97.505602 ms\n",
      "25/06/27 09:16:43 INFO Executor: Finished task 0.0 in stage 3.0 (TID 10). 4022 bytes result sent to driver\n",
      "25/06/27 09:16:43 INFO TaskSetManager: Finished task 0.0 in stage 3.0 (TID 10) in 309 ms on hal9000 (executor driver) (1/1)\n",
      "25/06/27 09:16:43 INFO TaskSchedulerImpl: Removed TaskSet 3.0, whose tasks have all completed, from pool \n",
      "25/06/27 09:16:43 INFO DAGScheduler: ResultStage 3 (showString at NativeMethodAccessorImpl.java:0) finished in 0.363 s\n",
      "25/06/27 09:16:43 INFO DAGScheduler: Job 2 is finished. Cancelling potential speculative or zombie tasks for this job\n",
      "25/06/27 09:16:43 INFO TaskSchedulerImpl: Killing all running tasks in stage 3: Stage finished\n",
      "25/06/27 09:16:43 INFO DAGScheduler: Job 2 finished: showString at NativeMethodAccessorImpl.java:0, took 0.381142 s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+------------+-----------+------------------+------+---------+------+-----------+--------+--------------------+---------+-----------+----+--------------------+--------------------+--------------------+\n",
      "|measure_id|measure_name|location_id|     location_name|sex_id| sex_name|age_id|   age_name|cause_id|          cause_name|metric_id|metric_name|year|                 val|               upper|               lower|\n",
      "+----------+------------+-----------+------------------+------+---------+------+-----------+--------+--------------------+---------+-----------+----+--------------------+--------------------+--------------------+\n",
      "|         1|      Óbitos|       4761|Mato Grosso do Sul|     1|Masculino|     8|15 -19 anos|     459|Melanoma maligno ...|        1|     Número|2001| 0.03482425671072571| 0.04761777852821798|0.025552037408807626|\n",
      "|         1|      Óbitos|       4761|Mato Grosso do Sul|     2| Feminino|     8|15 -19 anos|     459|Melanoma maligno ...|        1|     Número|2001| 0.04669173267560104| 0.05839894474521824|0.035360607689041534|\n",
      "|         1|      Óbitos|       4761|Mato Grosso do Sul|     1|Masculino|     8|15 -19 anos|     459|Melanoma maligno ...|        2| Percentual|2001|2.000282142983305...|2.725222002453761...|1.471362245684810...|\n",
      "|         1|      Óbitos|       4761|Mato Grosso do Sul|     2| Feminino|     8|15 -19 anos|     459|Melanoma maligno ...|        2| Percentual|2001|6.235319839758375E-4|7.860247437516516E-4|4.759004338465841E-4|\n",
      "|         1|      Óbitos|       4761|Mato Grosso do Sul|     1|Masculino|     8|15 -19 anos|     459|Melanoma maligno ...|        3|       Taxa|2001|0.030420884116819688| 0.04159672192116458|0.022321095764337457|\n",
      "|         1|      Óbitos|       4761|Mato Grosso do Sul|     2| Feminino|     8|15 -19 anos|     459|Melanoma maligno ...|        3|       Taxa|2001|0.041914487883834506| 0.05242388152434661| 0.03174270213625734|\n",
      "|         1|      Óbitos|       4761|Mato Grosso do Sul|     1|Masculino|     9| 20-24 anos|     459|Melanoma maligno ...|        1|     Número|2001| 0.07734976215535724|  0.1011219210713382| 0.05714193352470096|\n",
      "|         1|      Óbitos|       4761|Mato Grosso do Sul|     2| Feminino|     9| 20-24 anos|     459|Melanoma maligno ...|        1|     Número|2001| 0.08850248969165418|  0.1122071902503763| 0.06825472965335583|\n",
      "|         1|      Óbitos|       4761|Mato Grosso do Sul|     1|Masculino|     9| 20-24 anos|     459|Melanoma maligno ...|        2| Percentual|2001|3.303356976993905E-4|4.284620393981866E-4|2.433386550139860...|\n",
      "|         1|      Óbitos|       4761|Mato Grosso do Sul|     2| Feminino|     9| 20-24 anos|     459|Melanoma maligno ...|        2| Percentual|2001|0.001185648958594...|0.001509946298863...|9.207422346738534E-4|\n",
      "|         1|      Óbitos|       4761|Mato Grosso do Sul|     1|Masculino|     9| 20-24 anos|     459|Melanoma maligno ...|        3|       Taxa|2001| 0.07471794048627318| 0.09768125292086058| 0.05519768218283366|\n",
      "|         1|      Óbitos|       4761|Mato Grosso do Sul|     2| Feminino|     9| 20-24 anos|     459|Melanoma maligno ...|        3|       Taxa|2001| 0.08627174911144767| 0.10937896323038462| 0.06653434194721057|\n",
      "|         1|      Óbitos|       4761|Mato Grosso do Sul|     1|Masculino|    10| 25-29 anos|     459|Melanoma maligno ...|        1|     Número|2001| 0.12558285317313825| 0.16768824879189753| 0.09440095215593121|\n",
      "|         1|      Óbitos|       4761|Mato Grosso do Sul|     2| Feminino|    10| 25-29 anos|     459|Melanoma maligno ...|        1|     Número|2001| 0.13204124268633388| 0.17024472934675217| 0.10141231039250705|\n",
      "|         1|      Óbitos|       4761|Mato Grosso do Sul|     1|Masculino|    10| 25-29 anos|     459|Melanoma maligno ...|        2| Percentual|2001|5.412382116957605E-4|7.202957932331872E-4|4.051904226052831...|\n",
      "|         1|      Óbitos|       4761|Mato Grosso do Sul|     2| Feminino|    10| 25-29 anos|     459|Melanoma maligno ...|        2| Percentual|2001|0.001573669752617...|0.002003147226303...|0.001197006073375...|\n",
      "|         1|      Óbitos|       4761|Mato Grosso do Sul|     1|Masculino|    10| 25-29 anos|     459|Melanoma maligno ...|        3|       Taxa|2001|   0.139377219643568| 0.18610758788296705| 0.10477021273803554|\n",
      "|         1|      Óbitos|       4761|Mato Grosso do Sul|     2| Feminino|    10| 25-29 anos|     459|Melanoma maligno ...|        3|       Taxa|2001| 0.14304234089538284| 0.18442877479356495| 0.10986154006906174|\n",
      "|         1|      Óbitos|       4761|Mato Grosso do Sul|     1|Masculino|    11| 30-34 anos|     459|Melanoma maligno ...|        1|     Número|2001| 0.26513048276793955| 0.33825380224368995| 0.20000629723600466|\n",
      "|         1|      Óbitos|       4761|Mato Grosso do Sul|     2| Feminino|    11| 30-34 anos|     459|Melanoma maligno ...|        1|     Número|2001| 0.20338181813764705|  0.2605708990191996|  0.1554574782867933|\n",
      "+----------+------------+-----------+------------------+------+---------+------+-----------+--------+--------------------+---------+-----------+----+--------------------+--------------------+--------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "25/06/27 09:16:43 INFO CodeGenerator: Code generated in 94.458516 ms\n"
     ]
    }
   ],
   "source": [
    "# Extração dos dados no datalake dentro do Minio com a Tipagem\n",
    "\n",
    "schema_cancer = StructType([\n",
    "    StructField(\"measure_id\", IntegerType(), True),\n",
    "    StructField(\"measure_name\", StringType(), True),\n",
    "    StructField(\"location_id\", IntegerType(), True),\n",
    "    StructField(\"location_name\", StringType(), True),\n",
    "    StructField(\"sex_id\", IntegerType(), True),\n",
    "    StructField(\"sex_name\", StringType(), True),\n",
    "    StructField(\"age_id\", IntegerType(), True),\n",
    "    StructField(\"age_name\", StringType(), True),\n",
    "    StructField(\"cause_id\", IntegerType(), True),\n",
    "    StructField(\"cause_name\", StringType(), True),\n",
    "    StructField(\"metric_id\", IntegerType(), True),\n",
    "    StructField(\"metric_name\", StringType(), True),\n",
    "    StructField(\"year\", IntegerType(), True),\n",
    "    StructField(\"val\", DoubleType(), True),\n",
    "    StructField(\"upper\", DoubleType(), True),\n",
    "    StructField(\"lower\", DoubleType(), True),\n",
    "])\n",
    "\n",
    "df_cancer1 = spark.read.csv(\"s3a://datalake/cancer-1.csv\", schema=schema_cancer, header=True, inferSchema=True)\n",
    "df_cancer2 = spark.read.csv(\"s3a://datalake/cancer-2.csv\", schema=schema_cancer, header=True, inferSchema=True)\n",
    "df_cancer = df_cancer1.union(df_cancer2)\n",
    "\n",
    "print(\"Numero de Tuplas: \", df_cancer.count())\n",
    "df_cancer.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c4877af8",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "25/06/27 09:16:43 INFO InMemoryFileIndex: It took 19 ms to list leaf files for 1 paths.\n",
      "25/06/27 09:16:44 INFO FileSourceStrategy: Pushed Filters: \n",
      "25/06/27 09:16:44 INFO FileSourceStrategy: Post-Scan Filters: \n",
      "25/06/27 09:16:44 INFO MemoryStore: Block broadcast_7 stored as values in memory (estimated size 203.2 KiB, free 433.2 MiB)\n",
      "25/06/27 09:16:44 INFO BlockManagerInfo: Removed broadcast_6_piece0 on hal9000:34557 in memory (size: 11.2 KiB, free: 434.3 MiB)\n",
      "25/06/27 09:16:44 INFO MemoryStore: Block broadcast_7_piece0 stored as bytes in memory (estimated size 35.4 KiB, free 433.2 MiB)\n",
      "25/06/27 09:16:44 INFO BlockManagerInfo: Added broadcast_7_piece0 in memory on hal9000:34557 (size: 35.4 KiB, free: 434.2 MiB)\n",
      "25/06/27 09:16:44 INFO BlockManagerInfo: Removed broadcast_4_piece0 on hal9000:34557 in memory (size: 35.4 KiB, free: 434.3 MiB)\n",
      "25/06/27 09:16:44 INFO SparkContext: Created broadcast 7 from count at NativeMethodAccessorImpl.java:0\n",
      "25/06/27 09:16:44 INFO FileSourceScanExec: Planning scan with bin packing, max size: 134217728 bytes, open cost is considered as scanning 4194304 bytes.\n",
      "25/06/27 09:16:44 INFO BlockManagerInfo: Removed broadcast_5_piece0 on hal9000:34557 in memory (size: 35.4 KiB, free: 434.3 MiB)\n",
      "25/06/27 09:16:44 INFO DAGScheduler: Registering RDD 21 (count at NativeMethodAccessorImpl.java:0) as input to shuffle 1\n",
      "25/06/27 09:16:44 INFO DAGScheduler: Got map stage job 3 (count at NativeMethodAccessorImpl.java:0) with 33 output partitions\n",
      "25/06/27 09:16:44 INFO DAGScheduler: Final stage: ShuffleMapStage 4 (count at NativeMethodAccessorImpl.java:0)\n",
      "25/06/27 09:16:44 INFO DAGScheduler: Parents of final stage: List()\n",
      "25/06/27 09:16:44 INFO DAGScheduler: Missing parents: List()\n",
      "25/06/27 09:16:44 INFO DAGScheduler: Submitting ShuffleMapStage 4 (MapPartitionsRDD[21] at count at NativeMethodAccessorImpl.java:0), which has no missing parents\n",
      "25/06/27 09:16:44 INFO MemoryStore: Block broadcast_8 stored as values in memory (estimated size 17.2 KiB, free 433.7 MiB)\n",
      "25/06/27 09:16:44 INFO MemoryStore: Block broadcast_8_piece0 stored as bytes in memory (estimated size 8.7 KiB, free 433.7 MiB)\n",
      "25/06/27 09:16:44 INFO BlockManagerInfo: Added broadcast_8_piece0 in memory on hal9000:34557 (size: 8.7 KiB, free: 434.3 MiB)\n",
      "25/06/27 09:16:44 INFO SparkContext: Created broadcast 8 from broadcast at DAGScheduler.scala:1535\n",
      "25/06/27 09:16:44 INFO DAGScheduler: Submitting 33 missing tasks from ShuffleMapStage 4 (MapPartitionsRDD[21] at count at NativeMethodAccessorImpl.java:0) (first 15 tasks are for partitions Vector(0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14))\n",
      "25/06/27 09:16:44 INFO TaskSchedulerImpl: Adding task set 4.0 with 33 tasks resource profile 0\n",
      "25/06/27 09:16:44 INFO TaskSetManager: Starting task 0.0 in stage 4.0 (TID 11) (hal9000, executor driver, partition 0, PROCESS_LOCAL, 7895 bytes) \n",
      "25/06/27 09:16:44 INFO TaskSetManager: Starting task 1.0 in stage 4.0 (TID 12) (hal9000, executor driver, partition 1, PROCESS_LOCAL, 7895 bytes) \n",
      "25/06/27 09:16:44 INFO TaskSetManager: Starting task 2.0 in stage 4.0 (TID 13) (hal9000, executor driver, partition 2, PROCESS_LOCAL, 7895 bytes) \n",
      "25/06/27 09:16:44 INFO TaskSetManager: Starting task 3.0 in stage 4.0 (TID 14) (hal9000, executor driver, partition 3, PROCESS_LOCAL, 7895 bytes) \n",
      "25/06/27 09:16:44 INFO TaskSetManager: Starting task 4.0 in stage 4.0 (TID 15) (hal9000, executor driver, partition 4, PROCESS_LOCAL, 7895 bytes) \n",
      "25/06/27 09:16:44 INFO TaskSetManager: Starting task 5.0 in stage 4.0 (TID 16) (hal9000, executor driver, partition 5, PROCESS_LOCAL, 7895 bytes) \n",
      "25/06/27 09:16:44 INFO TaskSetManager: Starting task 6.0 in stage 4.0 (TID 17) (hal9000, executor driver, partition 6, PROCESS_LOCAL, 7895 bytes) \n",
      "25/06/27 09:16:44 INFO TaskSetManager: Starting task 7.0 in stage 4.0 (TID 18) (hal9000, executor driver, partition 7, PROCESS_LOCAL, 7895 bytes) \n",
      "25/06/27 09:16:44 INFO Executor: Running task 6.0 in stage 4.0 (TID 17)\n",
      "25/06/27 09:16:44 INFO Executor: Running task 4.0 in stage 4.0 (TID 15)\n",
      "25/06/27 09:16:44 INFO Executor: Running task 0.0 in stage 4.0 (TID 11)\n",
      "25/06/27 09:16:44 INFO Executor: Running task 1.0 in stage 4.0 (TID 12)\n",
      "25/06/27 09:16:44 INFO Executor: Running task 5.0 in stage 4.0 (TID 16)\n",
      "25/06/27 09:16:44 INFO Executor: Running task 7.0 in stage 4.0 (TID 18)\n",
      "25/06/27 09:16:44 INFO Executor: Running task 2.0 in stage 4.0 (TID 13)\n",
      "25/06/27 09:16:44 INFO Executor: Running task 3.0 in stage 4.0 (TID 14)\n",
      "25/06/27 09:16:44 INFO FileScanRDD: Reading File path: s3a://datalake/climate.csv, range: 805306368-939524096, partition values: [empty row]\n",
      "25/06/27 09:16:44 INFO FileScanRDD: Reading File path: s3a://datalake/climate.csv, range: 134217728-268435456, partition values: [empty row]\n",
      "25/06/27 09:16:44 INFO FileScanRDD: Reading File path: s3a://datalake/climate.csv, range: 0-134217728, partition values: [empty row]\n",
      "25/06/27 09:16:44 INFO FileScanRDD: Reading File path: s3a://datalake/climate.csv, range: 536870912-671088640, partition values: [empty row]\n",
      "25/06/27 09:16:44 INFO FileScanRDD: Reading File path: s3a://datalake/climate.csv, range: 268435456-402653184, partition values: [empty row]\n",
      "25/06/27 09:16:44 INFO FileScanRDD: Reading File path: s3a://datalake/climate.csv, range: 402653184-536870912, partition values: [empty row]\n",
      "25/06/27 09:16:44 INFO FileScanRDD: Reading File path: s3a://datalake/climate.csv, range: 939524096-1073741824, partition values: [empty row]\n",
      "25/06/27 09:16:44 INFO FileScanRDD: Reading File path: s3a://datalake/climate.csv, range: 671088640-805306368, partition values: [empty row]\n",
      "25/06/27 09:16:48 INFO Executor: Finished task 2.0 in stage 4.0 (TID 13). 1966 bytes result sent to driver\n",
      "25/06/27 09:16:48 INFO TaskSetManager: Starting task 8.0 in stage 4.0 (TID 19) (hal9000, executor driver, partition 8, PROCESS_LOCAL, 7895 bytes) \n",
      "25/06/27 09:16:48 INFO TaskSetManager: Finished task 2.0 in stage 4.0 (TID 13) in 4287 ms on hal9000 (executor driver) (1/33)\n",
      "25/06/27 09:16:48 INFO Executor: Running task 8.0 in stage 4.0 (TID 19)\n",
      "25/06/27 09:16:48 INFO FileScanRDD: Reading File path: s3a://datalake/climate.csv, range: 1073741824-1207959552, partition values: [empty row]\n",
      "25/06/27 09:16:48 INFO Executor: Finished task 6.0 in stage 4.0 (TID 17). 1966 bytes result sent to driver\n",
      "25/06/27 09:16:48 INFO TaskSetManager: Starting task 9.0 in stage 4.0 (TID 20) (hal9000, executor driver, partition 9, PROCESS_LOCAL, 7895 bytes) \n",
      "25/06/27 09:16:48 INFO TaskSetManager: Finished task 6.0 in stage 4.0 (TID 17) in 4690 ms on hal9000 (executor driver) (2/33)\n",
      "25/06/27 09:16:48 INFO Executor: Running task 9.0 in stage 4.0 (TID 20)\n",
      "25/06/27 09:16:49 INFO FileScanRDD: Reading File path: s3a://datalake/climate.csv, range: 1207959552-1342177280, partition values: [empty row]\n",
      "25/06/27 09:16:49 INFO Executor: Finished task 0.0 in stage 4.0 (TID 11). 2009 bytes result sent to driver\n",
      "25/06/27 09:16:49 INFO TaskSetManager: Starting task 10.0 in stage 4.0 (TID 21) (hal9000, executor driver, partition 10, PROCESS_LOCAL, 7895 bytes) \n",
      "25/06/27 09:16:49 INFO TaskSetManager: Finished task 0.0 in stage 4.0 (TID 11) in 5397 ms on hal9000 (executor driver) (3/33)\n",
      "25/06/27 09:16:49 INFO Executor: Running task 10.0 in stage 4.0 (TID 21)8) / 33]\n",
      "25/06/27 09:16:49 INFO FileScanRDD: Reading File path: s3a://datalake/climate.csv, range: 1342177280-1476395008, partition values: [empty row]\n",
      "25/06/27 09:16:50 INFO Executor: Finished task 1.0 in stage 4.0 (TID 12). 1966 bytes result sent to driver\n",
      "25/06/27 09:16:50 INFO TaskSetManager: Starting task 11.0 in stage 4.0 (TID 22) (hal9000, executor driver, partition 11, PROCESS_LOCAL, 7895 bytes) \n",
      "25/06/27 09:16:50 INFO TaskSetManager: Finished task 1.0 in stage 4.0 (TID 12) in 6243 ms on hal9000 (executor driver) (4/33)\n",
      "25/06/27 09:16:50 INFO Executor: Running task 11.0 in stage 4.0 (TID 22)\n",
      "25/06/27 09:16:50 INFO FileScanRDD: Reading File path: s3a://datalake/climate.csv, range: 1476395008-1610612736, partition values: [empty row]\n",
      "25/06/27 09:16:51 INFO Executor: Finished task 5.0 in stage 4.0 (TID 16). 1966 bytes result sent to driver\n",
      "25/06/27 09:16:51 INFO TaskSetManager: Starting task 12.0 in stage 4.0 (TID 23) (hal9000, executor driver, partition 12, PROCESS_LOCAL, 7895 bytes) \n",
      "25/06/27 09:16:51 INFO Executor: Running task 12.0 in stage 4.0 (TID 23)\n",
      "25/06/27 09:16:51 INFO TaskSetManager: Finished task 5.0 in stage 4.0 (TID 16) in 7650 ms on hal9000 (executor driver) (5/33)\n",
      "25/06/27 09:16:51 INFO FileScanRDD: Reading File path: s3a://datalake/climate.csv, range: 1610612736-1744830464, partition values: [empty row]\n",
      "25/06/27 09:16:51 INFO Executor: Finished task 3.0 in stage 4.0 (TID 14). 1966 bytes result sent to driver\n",
      "25/06/27 09:16:52 INFO TaskSetManager: Starting task 13.0 in stage 4.0 (TID 24) (hal9000, executor driver, partition 13, PROCESS_LOCAL, 7895 bytes) \n",
      "25/06/27 09:16:52 INFO TaskSetManager: Finished task 3.0 in stage 4.0 (TID 14) in 7727 ms on hal9000 (executor driver) (6/33)\n",
      "25/06/27 09:16:52 INFO Executor: Running task 13.0 in stage 4.0 (TID 24)\n",
      "25/06/27 09:16:52 INFO FileScanRDD: Reading File path: s3a://datalake/climate.csv, range: 1744830464-1879048192, partition values: [empty row]\n",
      "25/06/27 09:16:53 INFO Executor: Finished task 4.0 in stage 4.0 (TID 15). 2009 bytes result sent to driver\n",
      "25/06/27 09:16:53 INFO TaskSetManager: Starting task 14.0 in stage 4.0 (TID 25) (hal9000, executor driver, partition 14, PROCESS_LOCAL, 7895 bytes) \n",
      "25/06/27 09:16:53 INFO Executor: Running task 14.0 in stage 4.0 (TID 25)\n",
      "25/06/27 09:16:53 INFO TaskSetManager: Finished task 4.0 in stage 4.0 (TID 15) in 9695 ms on hal9000 (executor driver) (7/33)\n",
      "25/06/27 09:16:54 INFO FileScanRDD: Reading File path: s3a://datalake/climate.csv, range: 1879048192-2013265920, partition values: [empty row]\n",
      "25/06/27 09:16:54 INFO Executor: Finished task 7.0 in stage 4.0 (TID 18). 1966 bytes result sent to driver\n",
      "25/06/27 09:16:54 INFO TaskSetManager: Starting task 15.0 in stage 4.0 (TID 26) (hal9000, executor driver, partition 15, PROCESS_LOCAL, 7895 bytes) \n",
      "25/06/27 09:16:54 INFO Executor: Running task 15.0 in stage 4.0 (TID 26)\n",
      "25/06/27 09:16:54 INFO TaskSetManager: Finished task 7.0 in stage 4.0 (TID 18) in 10073 ms on hal9000 (executor driver) (8/33)\n",
      "25/06/27 09:16:54 INFO FileScanRDD: Reading File path: s3a://datalake/climate.csv, range: 2013265920-2147483648, partition values: [empty row]\n",
      "25/06/27 09:16:58 INFO Executor: Finished task 8.0 in stage 4.0 (TID 19). 1966 bytes result sent to driver\n",
      "25/06/27 09:16:58 INFO TaskSetManager: Starting task 16.0 in stage 4.0 (TID 27) (hal9000, executor driver, partition 16, PROCESS_LOCAL, 7895 bytes) \n",
      "25/06/27 09:16:58 INFO Executor: Running task 16.0 in stage 4.0 (TID 27)\n",
      "25/06/27 09:16:58 INFO TaskSetManager: Finished task 8.0 in stage 4.0 (TID 19) in 10037 ms on hal9000 (executor driver) (9/33)\n",
      "25/06/27 09:16:58 INFO Executor: Finished task 9.0 in stage 4.0 (TID 20). 1966 bytes result sent to driver\n",
      "25/06/27 09:16:58 INFO TaskSetManager: Starting task 17.0 in stage 4.0 (TID 28) (hal9000, executor driver, partition 17, PROCESS_LOCAL, 7895 bytes) \n",
      "25/06/27 09:16:58 INFO Executor: Running task 17.0 in stage 4.0 (TID 28)\n",
      "25/06/27 09:16:58 INFO TaskSetManager: Finished task 9.0 in stage 4.0 (TID 20) in 9667 ms on hal9000 (executor driver) (10/33)\n",
      "25/06/27 09:16:58 INFO FileScanRDD: Reading File path: s3a://datalake/climate.csv, range: 2147483648-2281701376, partition values: [empty row]\n",
      "25/06/27 09:16:58 INFO FileScanRDD: Reading File path: s3a://datalake/climate.csv, range: 2281701376-2415919104, partition values: [empty row]\n",
      "25/06/27 09:16:59 INFO Executor: Finished task 10.0 in stage 4.0 (TID 21). 1966 bytes result sent to driver\n",
      "25/06/27 09:16:59 INFO TaskSetManager: Starting task 18.0 in stage 4.0 (TID 29) (hal9000, executor driver, partition 18, PROCESS_LOCAL, 7895 bytes) \n",
      "25/06/27 09:16:59 INFO TaskSetManager: Finished task 10.0 in stage 4.0 (TID 21) in 9824 ms on hal9000 (executor driver) (11/33)\n",
      "25/06/27 09:16:59 INFO Executor: Running task 18.0 in stage 4.0 (TID 29)\n",
      "25/06/27 09:16:59 INFO FileScanRDD: Reading File path: s3a://datalake/climate.csv, range: 2415919104-2550136832, partition values: [empty row]\n",
      "25/06/27 09:17:01 INFO Executor: Finished task 11.0 in stage 4.0 (TID 22). 1966 bytes result sent to driver\n",
      "25/06/27 09:17:01 INFO TaskSetManager: Starting task 19.0 in stage 4.0 (TID 30) (hal9000, executor driver, partition 19, PROCESS_LOCAL, 7895 bytes) \n",
      "25/06/27 09:17:01 INFO TaskSetManager: Finished task 11.0 in stage 4.0 (TID 22) in 11010 ms on hal9000 (executor driver) (12/33)\n",
      "25/06/27 09:17:01 INFO Executor: Running task 19.0 in stage 4.0 (TID 30)\n",
      "25/06/27 09:17:01 INFO FileScanRDD: Reading File path: s3a://datalake/climate.csv, range: 2550136832-2684354560, partition values: [empty row]\n",
      "25/06/27 09:17:03 INFO Executor: Finished task 13.0 in stage 4.0 (TID 24). 1966 bytes result sent to driver\n",
      "25/06/27 09:17:03 INFO TaskSetManager: Starting task 20.0 in stage 4.0 (TID 31) (hal9000, executor driver, partition 20, PROCESS_LOCAL, 7895 bytes) \n",
      "25/06/27 09:17:03 INFO TaskSetManager: Finished task 13.0 in stage 4.0 (TID 24) in 11700 ms on hal9000 (executor driver) (13/33)\n",
      "25/06/27 09:17:03 INFO Executor: Running task 20.0 in stage 4.0 (TID 31)\n",
      "25/06/27 09:17:03 INFO FileScanRDD: Reading File path: s3a://datalake/climate.csv, range: 2684354560-2818572288, partition values: [empty row]\n",
      "25/06/27 09:17:04 INFO Executor: Finished task 14.0 in stage 4.0 (TID 25). 1966 bytes result sent to driver\n",
      "25/06/27 09:17:04 INFO TaskSetManager: Starting task 21.0 in stage 4.0 (TID 32) (hal9000, executor driver, partition 21, PROCESS_LOCAL, 7895 bytes) \n",
      "25/06/27 09:17:04 INFO TaskSetManager: Finished task 14.0 in stage 4.0 (TID 25) in 10195 ms on hal9000 (executor driver) (14/33)\n",
      "25/06/27 09:17:04 INFO Executor: Running task 21.0 in stage 4.0 (TID 32)\n",
      "25/06/27 09:17:04 INFO FileScanRDD: Reading File path: s3a://datalake/climate.csv, range: 2818572288-2952790016, partition values: [empty row]\n",
      "25/06/27 09:17:04 INFO Executor: Finished task 12.0 in stage 4.0 (TID 23). 2009 bytes result sent to driver\n",
      "25/06/27 09:17:04 INFO TaskSetManager: Starting task 22.0 in stage 4.0 (TID 33) (hal9000, executor driver, partition 22, PROCESS_LOCAL, 7895 bytes) \n",
      "25/06/27 09:17:04 INFO TaskSetManager: Finished task 12.0 in stage 4.0 (TID 23) in 13055 ms on hal9000 (executor driver) (15/33)\n",
      "25/06/27 09:17:04 INFO Executor: Running task 22.0 in stage 4.0 (TID 33)\n",
      "25/06/27 09:17:05 INFO FileScanRDD: Reading File path: s3a://datalake/climate.csv, range: 2952790016-3087007744, partition values: [empty row]\n",
      "25/06/27 09:17:05 INFO Executor: Finished task 15.0 in stage 4.0 (TID 26). 1966 bytes result sent to driver\n",
      "25/06/27 09:17:05 INFO TaskSetManager: Starting task 23.0 in stage 4.0 (TID 34) (hal9000, executor driver, partition 23, PROCESS_LOCAL, 7895 bytes) \n",
      "25/06/27 09:17:05 INFO TaskSetManager: Finished task 15.0 in stage 4.0 (TID 26) in 11012 ms on hal9000 (executor driver) (16/33)\n",
      "25/06/27 09:17:05 INFO Executor: Running task 23.0 in stage 4.0 (TID 34)\n",
      "25/06/27 09:17:05 INFO FileScanRDD: Reading File path: s3a://datalake/climate.csv, range: 3087007744-3221225472, partition values: [empty row]\n",
      "25/06/27 09:17:08 INFO Executor: Finished task 17.0 in stage 4.0 (TID 28). 2009 bytes result sent to driver\n",
      "25/06/27 09:17:08 INFO TaskSetManager: Starting task 24.0 in stage 4.0 (TID 35) (hal9000, executor driver, partition 24, PROCESS_LOCAL, 7895 bytes) \n",
      "25/06/27 09:17:08 INFO TaskSetManager: Finished task 17.0 in stage 4.0 (TID 28) in 9564 ms on hal9000 (executor driver) (17/33)\n",
      "25/06/27 09:17:08 INFO Executor: Running task 24.0 in stage 4.0 (TID 35)\n",
      "25/06/27 09:17:08 INFO FileScanRDD: Reading File path: s3a://datalake/climate.csv, range: 3221225472-3355443200, partition values: [empty row]\n",
      "25/06/27 09:17:08 INFO Executor: Finished task 18.0 in stage 4.0 (TID 29). 2009 bytes result sent to driver\n",
      "25/06/27 09:17:08 INFO TaskSetManager: Starting task 25.0 in stage 4.0 (TID 36) (hal9000, executor driver, partition 25, PROCESS_LOCAL, 7895 bytes) \n",
      "25/06/27 09:17:08 INFO TaskSetManager: Finished task 18.0 in stage 4.0 (TID 29) in 8989 ms on hal9000 (executor driver) (18/33)\n",
      "25/06/27 09:17:08 INFO Executor: Running task 25.0 in stage 4.0 (TID 36)\n",
      "25/06/27 09:17:08 INFO FileScanRDD: Reading File path: s3a://datalake/climate.csv, range: 3355443200-3489660928, partition values: [empty row]\n",
      "25/06/27 09:17:09 INFO Executor: Finished task 16.0 in stage 4.0 (TID 27). 2009 bytes result sent to driver\n",
      "25/06/27 09:17:09 INFO TaskSetManager: Starting task 26.0 in stage 4.0 (TID 37) (hal9000, executor driver, partition 26, PROCESS_LOCAL, 7895 bytes) \n",
      "25/06/27 09:17:09 INFO TaskSetManager: Finished task 16.0 in stage 4.0 (TID 27) in 11223 ms on hal9000 (executor driver) (19/33)\n",
      "25/06/27 09:17:09 INFO Executor: Running task 26.0 in stage 4.0 (TID 37)\n",
      "25/06/27 09:17:09 INFO FileScanRDD: Reading File path: s3a://datalake/climate.csv, range: 3489660928-3623878656, partition values: [empty row]\n",
      "25/06/27 09:17:11 INFO Executor: Finished task 21.0 in stage 4.0 (TID 32). 1966 bytes result sent to driver\n",
      "25/06/27 09:17:11 INFO TaskSetManager: Starting task 27.0 in stage 4.0 (TID 38) (hal9000, executor driver, partition 27, PROCESS_LOCAL, 7895 bytes) \n",
      "25/06/27 09:17:11 INFO TaskSetManager: Finished task 21.0 in stage 4.0 (TID 32) in 6967 ms on hal9000 (executor driver) (20/33)\n",
      "25/06/27 09:17:11 INFO Executor: Running task 27.0 in stage 4.0 (TID 38)\n",
      "25/06/27 09:17:11 INFO FileScanRDD: Reading File path: s3a://datalake/climate.csv, range: 3623878656-3758096384, partition values: [empty row]\n",
      "25/06/27 09:17:11 INFO Executor: Finished task 19.0 in stage 4.0 (TID 30). 1966 bytes result sent to driver\n",
      "25/06/27 09:17:11 INFO TaskSetManager: Starting task 28.0 in stage 4.0 (TID 39) (hal9000, executor driver, partition 28, PROCESS_LOCAL, 7895 bytes) \n",
      "25/06/27 09:17:11 INFO TaskSetManager: Finished task 19.0 in stage 4.0 (TID 30) in 10282 ms on hal9000 (executor driver) (21/33)\n",
      "25/06/27 09:17:11 INFO Executor: Running task 28.0 in stage 4.0 (TID 39)\n",
      "25/06/27 09:17:11 INFO FileScanRDD: Reading File path: s3a://datalake/climate.csv, range: 3758096384-3892314112, partition values: [empty row]\n",
      "25/06/27 09:17:12 INFO Executor: Finished task 22.0 in stage 4.0 (TID 33). 1966 bytes result sent to driver\n",
      "25/06/27 09:17:12 INFO TaskSetManager: Starting task 29.0 in stage 4.0 (TID 40) (hal9000, executor driver, partition 29, PROCESS_LOCAL, 7895 bytes) \n",
      "25/06/27 09:17:12 INFO TaskSetManager: Finished task 22.0 in stage 4.0 (TID 33) in 7516 ms on hal9000 (executor driver) (22/33)\n",
      "25/06/27 09:17:12 INFO Executor: Running task 29.0 in stage 4.0 (TID 40)\n",
      "25/06/27 09:17:12 INFO FileScanRDD: Reading File path: s3a://datalake/climate.csv, range: 3892314112-4026531840, partition values: [empty row]\n",
      "25/06/27 09:17:12 INFO Executor: Finished task 20.0 in stage 4.0 (TID 31). 1966 bytes result sent to driver\n",
      "25/06/27 09:17:12 INFO TaskSetManager: Starting task 30.0 in stage 4.0 (TID 41) (hal9000, executor driver, partition 30, PROCESS_LOCAL, 7895 bytes) \n",
      "25/06/27 09:17:12 INFO TaskSetManager: Finished task 20.0 in stage 4.0 (TID 31) in 9209 ms on hal9000 (executor driver) (23/33)\n",
      "25/06/27 09:17:12 INFO Executor: Running task 30.0 in stage 4.0 (TID 41)\n",
      "25/06/27 09:17:12 INFO FileScanRDD: Reading File path: s3a://datalake/climate.csv, range: 4026531840-4160749568, partition values: [empty row]\n",
      "25/06/27 09:17:13 INFO Executor: Finished task 23.0 in stage 4.0 (TID 34). 1966 bytes result sent to driver\n",
      "25/06/27 09:17:13 INFO TaskSetManager: Starting task 31.0 in stage 4.0 (TID 42) (hal9000, executor driver, partition 31, PROCESS_LOCAL, 7895 bytes) \n",
      "25/06/27 09:17:13 INFO TaskSetManager: Finished task 23.0 in stage 4.0 (TID 34) in 7930 ms on hal9000 (executor driver) (24/33)\n",
      "25/06/27 09:17:13 INFO Executor: Running task 31.0 in stage 4.0 (TID 42)\n",
      "25/06/27 09:17:13 INFO FileScanRDD: Reading File path: s3a://datalake/climate.csv, range: 4160749568-4294967296, partition values: [empty row]\n",
      "25/06/27 09:17:13 INFO Executor: Finished task 25.0 in stage 4.0 (TID 36). 1966 bytes result sent to driver\n",
      "25/06/27 09:17:13 INFO TaskSetManager: Starting task 32.0 in stage 4.0 (TID 43) (hal9000, executor driver, partition 32, PROCESS_LOCAL, 7895 bytes) \n",
      "25/06/27 09:17:13 INFO TaskSetManager: Finished task 25.0 in stage 4.0 (TID 36) in 5475 ms on hal9000 (executor driver) (25/33)\n",
      "25/06/27 09:17:13 INFO Executor: Running task 32.0 in stage 4.0 (TID 43)\n",
      "25/06/27 09:17:13 INFO FileScanRDD: Reading File path: s3a://datalake/climate.csv, range: 4294967296-4356534577, partition values: [empty row]\n",
      "25/06/27 09:17:14 INFO Executor: Finished task 24.0 in stage 4.0 (TID 35). 2009 bytes result sent to driver\n",
      "25/06/27 09:17:14 INFO TaskSetManager: Finished task 24.0 in stage 4.0 (TID 35) in 6218 ms on hal9000 (executor driver) (26/33)\n",
      "25/06/27 09:17:15 INFO Executor: Finished task 32.0 in stage 4.0 (TID 43). 1966 bytes result sent to driver\n",
      "25/06/27 09:17:15 INFO TaskSetManager: Finished task 32.0 in stage 4.0 (TID 43) in 1346 ms on hal9000 (executor driver) (27/33)\n",
      "25/06/27 09:17:15 INFO Executor: Finished task 27.0 in stage 4.0 (TID 38). 1966 bytes result sent to driver\n",
      "25/06/27 09:17:15 INFO TaskSetManager: Finished task 27.0 in stage 4.0 (TID 38) in 4373 ms on hal9000 (executor driver) (28/33)\n",
      "25/06/27 09:17:15 INFO Executor: Finished task 26.0 in stage 4.0 (TID 37). 1966 bytes result sent to driver\n",
      "25/06/27 09:17:15 INFO TaskSetManager: Finished task 26.0 in stage 4.0 (TID 37) in 5792 ms on hal9000 (executor driver) (29/33)\n",
      "25/06/27 09:17:15 INFO Executor: Finished task 28.0 in stage 4.0 (TID 39). 1966 bytes result sent to driver\n",
      "25/06/27 09:17:16 INFO TaskSetManager: Finished task 28.0 in stage 4.0 (TID 39) in 4284 ms on hal9000 (executor driver) (30/33)\n",
      "25/06/27 09:17:16 INFO Executor: Finished task 29.0 in stage 4.0 (TID 40). 1966 bytes result sent to driver\n",
      "25/06/27 09:17:16 INFO TaskSetManager: Finished task 29.0 in stage 4.0 (TID 40) in 3602 ms on hal9000 (executor driver) (31/33)\n",
      "25/06/27 09:17:16 INFO Executor: Finished task 30.0 in stage 4.0 (TID 41). 2009 bytes result sent to driver\n",
      "25/06/27 09:17:16 INFO TaskSetManager: Finished task 30.0 in stage 4.0 (TID 41) in 3351 ms on hal9000 (executor driver) (32/33)\n",
      "25/06/27 09:17:16 INFO Executor: Finished task 31.0 in stage 4.0 (TID 42). 2009 bytes result sent to driver\n",
      "25/06/27 09:17:16 INFO TaskSetManager: Finished task 31.0 in stage 4.0 (TID 42) in 3100 ms on hal9000 (executor driver) (33/33)\n",
      "25/06/27 09:17:16 INFO TaskSchedulerImpl: Removed TaskSet 4.0, whose tasks have all completed, from pool \n",
      "25/06/27 09:17:16 INFO DAGScheduler: ShuffleMapStage 4 (count at NativeMethodAccessorImpl.java:0) finished in 32.198 s\n",
      "25/06/27 09:17:16 INFO DAGScheduler: looking for newly runnable stages\n",
      "25/06/27 09:17:16 INFO DAGScheduler: running: Set()\n",
      "25/06/27 09:17:16 INFO DAGScheduler: waiting: Set()\n",
      "25/06/27 09:17:16 INFO DAGScheduler: failed: Set()\n",
      "25/06/27 09:17:16 INFO SparkContext: Starting job: count at NativeMethodAccessorImpl.java:0\n",
      "25/06/27 09:17:16 INFO DAGScheduler: Got job 4 (count at NativeMethodAccessorImpl.java:0) with 1 output partitions\n",
      "25/06/27 09:17:16 INFO DAGScheduler: Final stage: ResultStage 6 (count at NativeMethodAccessorImpl.java:0)\n",
      "25/06/27 09:17:16 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 5)\n",
      "25/06/27 09:17:16 INFO DAGScheduler: Missing parents: List()\n",
      "25/06/27 09:17:16 INFO DAGScheduler: Submitting ResultStage 6 (MapPartitionsRDD[24] at count at NativeMethodAccessorImpl.java:0), which has no missing parents\n",
      "25/06/27 09:17:16 INFO MemoryStore: Block broadcast_9 stored as values in memory (estimated size 12.1 KiB, free 433.7 MiB)\n",
      "25/06/27 09:17:16 INFO MemoryStore: Block broadcast_9_piece0 stored as bytes in memory (estimated size 5.8 KiB, free 433.7 MiB)\n",
      "25/06/27 09:17:16 INFO BlockManagerInfo: Added broadcast_9_piece0 in memory on hal9000:34557 (size: 5.8 KiB, free: 434.3 MiB)\n",
      "25/06/27 09:17:16 INFO SparkContext: Created broadcast 9 from broadcast at DAGScheduler.scala:1535\n",
      "25/06/27 09:17:16 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 6 (MapPartitionsRDD[24] at count at NativeMethodAccessorImpl.java:0) (first 15 tasks are for partitions Vector(0))\n",
      "25/06/27 09:17:16 INFO TaskSchedulerImpl: Adding task set 6.0 with 1 tasks resource profile 0\n",
      "25/06/27 09:17:16 INFO TaskSetManager: Starting task 0.0 in stage 6.0 (TID 44) (hal9000, executor driver, partition 0, NODE_LOCAL, 7363 bytes) \n",
      "25/06/27 09:17:16 INFO Executor: Running task 0.0 in stage 6.0 (TID 44)\n",
      "25/06/27 09:17:16 INFO ShuffleBlockFetcherIterator: Getting 33 (1980.0 B) non-empty blocks including 33 (1980.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks\n",
      "25/06/27 09:17:16 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 5 ms\n",
      "25/06/27 09:17:16 INFO Executor: Finished task 0.0 in stage 6.0 (TID 44). 4038 bytes result sent to driver\n",
      "25/06/27 09:17:16 INFO TaskSetManager: Finished task 0.0 in stage 6.0 (TID 44) in 54 ms on hal9000 (executor driver) (1/1)\n",
      "25/06/27 09:17:16 INFO TaskSchedulerImpl: Removed TaskSet 6.0, whose tasks have all completed, from pool \n",
      "25/06/27 09:17:16 INFO DAGScheduler: ResultStage 6 (count at NativeMethodAccessorImpl.java:0) finished in 0.147 s\n",
      "25/06/27 09:17:16 INFO DAGScheduler: Job 4 is finished. Cancelling potential speculative or zombie tasks for this job\n",
      "25/06/27 09:17:16 INFO TaskSchedulerImpl: Killing all running tasks in stage 6: Stage finished\n",
      "25/06/27 09:17:16 INFO DAGScheduler: Job 4 finished: count at NativeMethodAccessorImpl.java:0, took 0.175744 s\n",
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Numero de Tuplas:  42721900\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "25/06/27 09:17:16 INFO FileSourceStrategy: Pushed Filters: \n",
      "25/06/27 09:17:16 INFO FileSourceStrategy: Post-Scan Filters: \n",
      "25/06/27 09:17:16 INFO CodeGenerator: Code generated in 69.269784 ms\n",
      "25/06/27 09:17:17 INFO MemoryStore: Block broadcast_10 stored as values in memory (estimated size 203.2 KiB, free 433.5 MiB)\n",
      "25/06/27 09:17:17 INFO MemoryStore: Block broadcast_10_piece0 stored as bytes in memory (estimated size 35.4 KiB, free 433.4 MiB)\n",
      "25/06/27 09:17:17 INFO BlockManagerInfo: Added broadcast_10_piece0 in memory on hal9000:34557 (size: 35.4 KiB, free: 434.2 MiB)\n",
      "25/06/27 09:17:17 INFO SparkContext: Created broadcast 10 from showString at NativeMethodAccessorImpl.java:0\n",
      "25/06/27 09:17:17 INFO FileSourceScanExec: Planning scan with bin packing, max size: 134217728 bytes, open cost is considered as scanning 4194304 bytes.\n",
      "25/06/27 09:17:17 INFO SparkContext: Starting job: showString at NativeMethodAccessorImpl.java:0\n",
      "25/06/27 09:17:17 INFO DAGScheduler: Got job 5 (showString at NativeMethodAccessorImpl.java:0) with 1 output partitions\n",
      "25/06/27 09:17:17 INFO DAGScheduler: Final stage: ResultStage 7 (showString at NativeMethodAccessorImpl.java:0)\n",
      "25/06/27 09:17:17 INFO DAGScheduler: Parents of final stage: List()\n",
      "25/06/27 09:17:17 INFO DAGScheduler: Missing parents: List()\n",
      "25/06/27 09:17:17 INFO DAGScheduler: Submitting ResultStage 7 (MapPartitionsRDD[28] at showString at NativeMethodAccessorImpl.java:0), which has no missing parents\n",
      "25/06/27 09:17:17 INFO MemoryStore: Block broadcast_11 stored as values in memory (estimated size 21.6 KiB, free 433.4 MiB)\n",
      "25/06/27 09:17:17 INFO MemoryStore: Block broadcast_11_piece0 stored as bytes in memory (estimated size 9.0 KiB, free 433.4 MiB)\n",
      "25/06/27 09:17:17 INFO BlockManagerInfo: Added broadcast_11_piece0 in memory on hal9000:34557 (size: 9.0 KiB, free: 434.2 MiB)\n",
      "25/06/27 09:17:17 INFO SparkContext: Created broadcast 11 from broadcast at DAGScheduler.scala:1535\n",
      "25/06/27 09:17:17 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 7 (MapPartitionsRDD[28] at showString at NativeMethodAccessorImpl.java:0) (first 15 tasks are for partitions Vector(0))\n",
      "25/06/27 09:17:17 INFO TaskSchedulerImpl: Adding task set 7.0 with 1 tasks resource profile 0\n",
      "25/06/27 09:17:17 INFO TaskSetManager: Starting task 0.0 in stage 7.0 (TID 45) (hal9000, executor driver, partition 0, PROCESS_LOCAL, 7906 bytes) \n",
      "25/06/27 09:17:17 INFO Executor: Running task 0.0 in stage 7.0 (TID 45)\n",
      "25/06/27 09:17:17 INFO FileScanRDD: Reading File path: s3a://datalake/climate.csv, range: 0-134217728, partition values: [empty row]\n",
      "25/06/27 09:17:17 INFO CodeGenerator: Code generated in 29.075309 ms\n",
      "25/06/27 09:17:17 INFO Executor: Finished task 0.0 in stage 7.0 (TID 45). 2820 bytes result sent to driver\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------------+--------+---------+----+---+-----+-------+-------+-------------------+--------------+--------------+-----------+-----------+-------+------+\n",
      "|         cidade|latitude|longitude|YEAR|DOY|  T2M|T2M_MAX|T2M_MIN|ALLSKY_SFC_UV_INDEX|ALLSKY_SFC_UVA|ALLSKY_SFC_UVB|PRECTOTCORR|codigo_ibge|capital|estado|\n",
      "+---------------+--------+---------+----+---+-----+-------+-------+-------------------+--------------+--------------+-----------+-----------+-------+------+\n",
      "|Abadia de Goiás|-16.7573| -49.4412|2001|  1|23.12|  26.25|  20.85|               2.29|           1.2|          0.04|      10.58|    5200050|  False| Goiás|\n",
      "|Abadia de Goiás|-16.7573| -49.4412|2001|  2|21.86|  24.46|  19.76|               1.95|          1.05|          0.03|        4.7|    5200050|  False| Goiás|\n",
      "|Abadia de Goiás|-16.7573| -49.4412|2001|  3|21.72|  25.39|  18.91|               2.27|           1.2|          0.04|        4.3|    5200050|  False| Goiás|\n",
      "|Abadia de Goiás|-16.7573| -49.4412|2001|  4|23.14|  27.84|   18.3|               1.81|          0.95|          0.03|       1.72|    5200050|  False| Goiás|\n",
      "|Abadia de Goiás|-16.7573| -49.4412|2001|  5|23.18|  29.38|  17.65|               3.03|          1.65|          0.05|       1.83|    5200050|  False| Goiás|\n",
      "|Abadia de Goiás|-16.7573| -49.4412|2001|  6|23.87|   29.6|  17.32|               3.25|          1.77|          0.05|       1.36|    5200050|  False| Goiás|\n",
      "|Abadia de Goiás|-16.7573| -49.4412|2001|  7|23.66|  28.56|  18.69|               2.98|          1.65|          0.05|      18.44|    5200050|  False| Goiás|\n",
      "|Abadia de Goiás|-16.7573| -49.4412|2001|  8|22.67|  26.36|  19.35|               1.93|          1.02|          0.03|      10.83|    5200050|  False| Goiás|\n",
      "|Abadia de Goiás|-16.7573| -49.4412|2001|  9|22.88|  26.02|  20.17|               2.81|           1.5|          0.05|       5.35|    5200050|  False| Goiás|\n",
      "|Abadia de Goiás|-16.7573| -49.4412|2001| 10|23.73|  28.68|  19.22|               2.67|          1.49|          0.04|       3.85|    5200050|  False| Goiás|\n",
      "|Abadia de Goiás|-16.7573| -49.4412|2001| 11|21.46|  25.64|  17.72|               1.93|          1.07|          0.03|       4.05|    5200050|  False| Goiás|\n",
      "|Abadia de Goiás|-16.7573| -49.4412|2001| 12|22.58|  27.68|  17.29|               2.12|          1.09|          0.04|        6.4|    5200050|  False| Goiás|\n",
      "|Abadia de Goiás|-16.7573| -49.4412|2001| 13|23.26|  28.17|   18.1|               3.08|          1.66|          0.05|       2.55|    5200050|  False| Goiás|\n",
      "|Abadia de Goiás|-16.7573| -49.4412|2001| 14|23.03|  28.11|  18.37|               2.92|          1.59|          0.05|       1.48|    5200050|  False| Goiás|\n",
      "|Abadia de Goiás|-16.7573| -49.4412|2001| 15|22.61|  26.87|  18.45|               3.13|           1.7|          0.05|       0.26|    5200050|  False| Goiás|\n",
      "|Abadia de Goiás|-16.7573| -49.4412|2001| 16|22.85|  28.94|  16.76|               3.31|          1.78|          0.05|       0.03|    5200050|  False| Goiás|\n",
      "|Abadia de Goiás|-16.7573| -49.4412|2001| 17|21.73|  26.03|  16.62|               2.97|          1.59|          0.05|       6.85|    5200050|  False| Goiás|\n",
      "|Abadia de Goiás|-16.7573| -49.4412|2001| 18|23.08|  29.12|   17.4|               3.04|          1.61|          0.05|       0.01|    5200050|  False| Goiás|\n",
      "|Abadia de Goiás|-16.7573| -49.4412|2001| 19|23.72|  29.35|  17.92|               2.87|          1.45|          0.05|       0.43|    5200050|  False| Goiás|\n",
      "|Abadia de Goiás|-16.7573| -49.4412|2001| 20|24.27|  28.82|   19.7|               3.11|          1.65|          0.05|       2.01|    5200050|  False| Goiás|\n",
      "+---------------+--------+---------+----+---+-----+-------+-------+-------------------+--------------+--------------+-----------+-----------+-------+------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "25/06/27 09:17:17 INFO TaskSetManager: Finished task 0.0 in stage 7.0 (TID 45) in 159 ms on hal9000 (executor driver) (1/1)\n",
      "25/06/27 09:17:17 INFO TaskSchedulerImpl: Removed TaskSet 7.0, whose tasks have all completed, from pool \n",
      "25/06/27 09:17:17 INFO DAGScheduler: ResultStage 7 (showString at NativeMethodAccessorImpl.java:0) finished in 0.194 s\n",
      "25/06/27 09:17:17 INFO DAGScheduler: Job 5 is finished. Cancelling potential speculative or zombie tasks for this job\n",
      "25/06/27 09:17:17 INFO TaskSchedulerImpl: Killing all running tasks in stage 7: Stage finished\n",
      "25/06/27 09:17:17 INFO DAGScheduler: Job 5 finished: showString at NativeMethodAccessorImpl.java:0, took 0.212519 s\n",
      "25/06/27 09:17:17 INFO CodeGenerator: Code generated in 28.39563 ms\n"
     ]
    }
   ],
   "source": [
    "# Extração dos dados no datalake dentro do Minio com a Tipagem\n",
    "\n",
    "schema_clima = StructType([\n",
    "    StructField(\"cidade\", StringType(), True),\n",
    "    StructField(\"latitude\", DoubleType(), True),\n",
    "    StructField(\"longitude\", DoubleType(), True),\n",
    "    StructField(\"YEAR\", IntegerType(), True),\n",
    "    StructField(\"DOY\", IntegerType(), True),\n",
    "    StructField(\"T2M\", DoubleType(), True),\n",
    "    StructField(\"T2M_MAX\", DoubleType(), True),\n",
    "    StructField(\"T2M_MIN\", DoubleType(), True),\n",
    "    StructField(\"ALLSKY_SFC_UV_INDEX\", DoubleType(), True),\n",
    "    StructField(\"ALLSKY_SFC_UVA\", DoubleType(), True),\n",
    "    StructField(\"ALLSKY_SFC_UVB\", DoubleType(), True),\n",
    "    StructField(\"PRECTOTCORR\", DoubleType(), True),\n",
    "    StructField(\"codigo_ibge\", IntegerType(), True),\n",
    "    StructField(\"capital\", StringType(), True),\n",
    "    StructField(\"estado\", StringType(), True),\n",
    "])\n",
    "\n",
    "df_clima = spark.read.csv(\"s3a://datalake/climate.csv\", schema=schema_clima, header=True, inferSchema=True)\n",
    "\n",
    "print(\"Numero de Tuplas: \", df_clima.count())\n",
    "df_clima.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ab2a53f",
   "metadata": {},
   "source": [
    "## Transform"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "cde7c5bf",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "25/06/27 09:17:17 INFO BlockManagerInfo: Removed broadcast_11_piece0 on hal9000:34557 in memory (size: 9.0 KiB, free: 434.2 MiB)\n",
      "25/06/27 09:17:17 INFO BlockManagerInfo: Removed broadcast_9_piece0 on hal9000:34557 in memory (size: 5.8 KiB, free: 434.3 MiB)\n",
      "25/06/27 09:17:19 INFO FileSourceStrategy: Pushed Filters: \n",
      "25/06/27 09:17:19 INFO FileSourceStrategy: Post-Scan Filters: \n",
      "25/06/27 09:17:19 INFO HashAggregateExec: spark.sql.codegen.aggregate.map.twolevel.enabled is set to true, but current version of codegened fast hashmap does not support this aggregate.\n",
      "25/06/27 09:17:19 INFO CodeGenerator: Code generated in 151.304182 ms\n",
      "25/06/27 09:17:19 INFO MemoryStore: Block broadcast_12 stored as values in memory (estimated size 203.2 KiB, free 433.2 MiB)\n",
      "25/06/27 09:17:19 INFO MemoryStore: Block broadcast_12_piece0 stored as bytes in memory (estimated size 35.4 KiB, free 433.2 MiB)\n",
      "25/06/27 09:17:19 INFO BlockManagerInfo: Added broadcast_12_piece0 in memory on hal9000:34557 (size: 35.4 KiB, free: 434.2 MiB)\n",
      "25/06/27 09:17:19 INFO SparkContext: Created broadcast 12 from count at NativeMethodAccessorImpl.java:0\n",
      "25/06/27 09:17:19 INFO FileSourceScanExec: Planning scan with bin packing, max size: 134217728 bytes, open cost is considered as scanning 4194304 bytes.\n",
      "25/06/27 09:17:19 INFO DAGScheduler: Registering RDD 32 (count at NativeMethodAccessorImpl.java:0) as input to shuffle 2\n",
      "25/06/27 09:17:19 INFO DAGScheduler: Got map stage job 6 (count at NativeMethodAccessorImpl.java:0) with 33 output partitions\n",
      "25/06/27 09:17:19 INFO DAGScheduler: Final stage: ShuffleMapStage 8 (count at NativeMethodAccessorImpl.java:0)\n",
      "25/06/27 09:17:19 INFO DAGScheduler: Parents of final stage: List()\n",
      "25/06/27 09:17:19 INFO DAGScheduler: Missing parents: List()\n",
      "25/06/27 09:17:19 INFO DAGScheduler: Submitting ShuffleMapStage 8 (MapPartitionsRDD[32] at count at NativeMethodAccessorImpl.java:0), which has no missing parents\n",
      "25/06/27 09:17:19 INFO MemoryStore: Block broadcast_13 stored as values in memory (estimated size 41.3 KiB, free 433.2 MiB)\n",
      "25/06/27 09:17:19 INFO MemoryStore: Block broadcast_13_piece0 stored as bytes in memory (estimated size 19.0 KiB, free 433.2 MiB)\n",
      "25/06/27 09:17:19 INFO BlockManagerInfo: Added broadcast_13_piece0 in memory on hal9000:34557 (size: 19.0 KiB, free: 434.2 MiB)\n",
      "25/06/27 09:17:19 INFO SparkContext: Created broadcast 13 from broadcast at DAGScheduler.scala:1535\n",
      "25/06/27 09:17:19 INFO DAGScheduler: Submitting 33 missing tasks from ShuffleMapStage 8 (MapPartitionsRDD[32] at count at NativeMethodAccessorImpl.java:0) (first 15 tasks are for partitions Vector(0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14))\n",
      "25/06/27 09:17:19 INFO TaskSchedulerImpl: Adding task set 8.0 with 33 tasks resource profile 0\n",
      "25/06/27 09:17:19 INFO TaskSetManager: Starting task 0.0 in stage 8.0 (TID 46) (hal9000, executor driver, partition 0, PROCESS_LOCAL, 7895 bytes) \n",
      "25/06/27 09:17:19 INFO TaskSetManager: Starting task 1.0 in stage 8.0 (TID 47) (hal9000, executor driver, partition 1, PROCESS_LOCAL, 7895 bytes) \n",
      "25/06/27 09:17:19 INFO TaskSetManager: Starting task 2.0 in stage 8.0 (TID 48) (hal9000, executor driver, partition 2, PROCESS_LOCAL, 7895 bytes) \n",
      "25/06/27 09:17:19 INFO TaskSetManager: Starting task 3.0 in stage 8.0 (TID 49) (hal9000, executor driver, partition 3, PROCESS_LOCAL, 7895 bytes) \n",
      "25/06/27 09:17:19 INFO TaskSetManager: Starting task 4.0 in stage 8.0 (TID 50) (hal9000, executor driver, partition 4, PROCESS_LOCAL, 7895 bytes) \n",
      "25/06/27 09:17:19 INFO TaskSetManager: Starting task 5.0 in stage 8.0 (TID 51) (hal9000, executor driver, partition 5, PROCESS_LOCAL, 7895 bytes) \n",
      "25/06/27 09:17:19 INFO TaskSetManager: Starting task 6.0 in stage 8.0 (TID 52) (hal9000, executor driver, partition 6, PROCESS_LOCAL, 7895 bytes) \n",
      "25/06/27 09:17:19 INFO TaskSetManager: Starting task 7.0 in stage 8.0 (TID 53) (hal9000, executor driver, partition 7, PROCESS_LOCAL, 7895 bytes) \n",
      "25/06/27 09:17:19 INFO Executor: Running task 0.0 in stage 8.0 (TID 46)\n",
      "25/06/27 09:17:19 INFO Executor: Running task 1.0 in stage 8.0 (TID 47)\n",
      "25/06/27 09:17:19 INFO Executor: Running task 2.0 in stage 8.0 (TID 48)\n",
      "25/06/27 09:17:19 INFO Executor: Running task 4.0 in stage 8.0 (TID 50)\n",
      "25/06/27 09:17:19 INFO Executor: Running task 7.0 in stage 8.0 (TID 53)\n",
      "25/06/27 09:17:19 INFO Executor: Running task 5.0 in stage 8.0 (TID 51)\n",
      "25/06/27 09:17:19 INFO Executor: Running task 6.0 in stage 8.0 (TID 52)\n",
      "25/06/27 09:17:19 INFO Executor: Running task 3.0 in stage 8.0 (TID 49)\n",
      "25/06/27 09:17:20 INFO CodeGenerator: Code generated in 53.210684 ms\n",
      "25/06/27 09:17:20 INFO CodeGenerator: Code generated in 69.743727 ms\n",
      "25/06/27 09:17:20 INFO FileScanRDD: Reading File path: s3a://datalake/climate.csv, range: 268435456-402653184, partition values: [empty row]\n",
      "25/06/27 09:17:20 INFO FileScanRDD: Reading File path: s3a://datalake/climate.csv, range: 0-134217728, partition values: [empty row]\n",
      "25/06/27 09:17:20 INFO FileScanRDD: Reading File path: s3a://datalake/climate.csv, range: 671088640-805306368, partition values: [empty row]\n",
      "25/06/27 09:17:20 INFO FileScanRDD: Reading File path: s3a://datalake/climate.csv, range: 402653184-536870912, partition values: [empty row]\n",
      "25/06/27 09:17:20 INFO FileScanRDD: Reading File path: s3a://datalake/climate.csv, range: 536870912-671088640, partition values: [empty row]\n",
      "25/06/27 09:17:20 INFO FileScanRDD: Reading File path: s3a://datalake/climate.csv, range: 134217728-268435456, partition values: [empty row]\n",
      "25/06/27 09:17:20 INFO FileScanRDD: Reading File path: s3a://datalake/climate.csv, range: 805306368-939524096, partition values: [empty row]\n",
      "25/06/27 09:17:20 INFO FileScanRDD: Reading File path: s3a://datalake/climate.csv, range: 939524096-1073741824, partition values: [empty row]\n",
      "25/06/27 09:17:20 INFO CodeGenerator: Code generated in 20.646646 ms\n",
      "25/06/27 09:17:21 INFO BlockManagerInfo: Removed broadcast_10_piece0 on hal9000:34557 in memory (size: 35.4 KiB, free: 434.2 MiB)\n",
      "25/06/27 09:17:35 INFO Executor: Finished task 0.0 in stage 8.0 (TID 46). 2760 bytes result sent to driver\n",
      "25/06/27 09:17:35 INFO TaskSetManager: Starting task 8.0 in stage 8.0 (TID 54) (hal9000, executor driver, partition 8, PROCESS_LOCAL, 7895 bytes) \n",
      "25/06/27 09:17:35 INFO Executor: Running task 8.0 in stage 8.0 (TID 54)\n",
      "25/06/27 09:17:35 INFO TaskSetManager: Finished task 0.0 in stage 8.0 (TID 46) in 15268 ms on hal9000 (executor driver) (1/33)\n",
      "25/06/27 09:17:35 INFO Executor: Finished task 5.0 in stage 8.0 (TID 51). 2803 bytes result sent to driver\n",
      "25/06/27 09:17:35 INFO TaskSetManager: Starting task 9.0 in stage 8.0 (TID 55) (hal9000, executor driver, partition 9, PROCESS_LOCAL, 7895 bytes) \n",
      "25/06/27 09:17:35 INFO TaskSetManager: Finished task 5.0 in stage 8.0 (TID 51) in 15333 ms on hal9000 (executor driver) (2/33)\n",
      "25/06/27 09:17:35 INFO Executor: Running task 9.0 in stage 8.0 (TID 55)\n",
      "25/06/27 09:17:35 INFO Executor: Finished task 3.0 in stage 8.0 (TID 49). 2803 bytes result sent to driver\n",
      "25/06/27 09:17:35 INFO TaskSetManager: Starting task 10.0 in stage 8.0 (TID 56) (hal9000, executor driver, partition 10, PROCESS_LOCAL, 7895 bytes) \n",
      "25/06/27 09:17:35 INFO Executor: Running task 10.0 in stage 8.0 (TID 56)\n",
      "25/06/27 09:17:35 INFO FileScanRDD: Reading File path: s3a://datalake/climate.csv, range: 1073741824-1207959552, partition values: [empty row]\n",
      "25/06/27 09:17:35 INFO TaskSetManager: Finished task 3.0 in stage 8.0 (TID 49) in 15516 ms on hal9000 (executor driver) (3/33)\n",
      "25/06/27 09:17:35 INFO FileScanRDD: Reading File path: s3a://datalake/climate.csv, range: 1207959552-1342177280, partition values: [empty row]\n",
      "25/06/27 09:17:35 INFO FileScanRDD: Reading File path: s3a://datalake/climate.csv, range: 1342177280-1476395008, partition values: [empty row]\n",
      "25/06/27 09:17:35 INFO Executor: Finished task 1.0 in stage 8.0 (TID 47). 2760 bytes result sent to driver\n",
      "25/06/27 09:17:35 INFO TaskSetManager: Starting task 11.0 in stage 8.0 (TID 57) (hal9000, executor driver, partition 11, PROCESS_LOCAL, 7895 bytes) \n",
      "25/06/27 09:17:35 INFO Executor: Running task 11.0 in stage 8.0 (TID 57)\n",
      "25/06/27 09:17:35 INFO TaskSetManager: Finished task 1.0 in stage 8.0 (TID 47) in 15779 ms on hal9000 (executor driver) (4/33)\n",
      "25/06/27 09:17:35 INFO FileScanRDD: Reading File path: s3a://datalake/climate.csv, range: 1476395008-1610612736, partition values: [empty row]\n",
      "25/06/27 09:17:37 INFO Executor: Finished task 6.0 in stage 8.0 (TID 52). 2760 bytes result sent to driver\n",
      "25/06/27 09:17:37 INFO TaskSetManager: Starting task 12.0 in stage 8.0 (TID 58) (hal9000, executor driver, partition 12, PROCESS_LOCAL, 7895 bytes) \n",
      "25/06/27 09:17:37 INFO TaskSetManager: Finished task 6.0 in stage 8.0 (TID 52) in 17247 ms on hal9000 (executor driver) (5/33)\n",
      "25/06/27 09:17:37 INFO Executor: Running task 12.0 in stage 8.0 (TID 58)\n",
      "25/06/27 09:17:37 INFO FileScanRDD: Reading File path: s3a://datalake/climate.csv, range: 1610612736-1744830464, partition values: [empty row]\n",
      "25/06/27 09:17:38 INFO Executor: Finished task 4.0 in stage 8.0 (TID 50). 2760 bytes result sent to driver\n",
      "25/06/27 09:17:38 INFO TaskSetManager: Starting task 13.0 in stage 8.0 (TID 59) (hal9000, executor driver, partition 13, PROCESS_LOCAL, 7895 bytes) \n",
      "25/06/27 09:17:38 INFO Executor: Running task 13.0 in stage 8.0 (TID 59)\n",
      "25/06/27 09:17:38 INFO TaskSetManager: Finished task 4.0 in stage 8.0 (TID 50) in 18206 ms on hal9000 (executor driver) (6/33)\n",
      "25/06/27 09:17:38 INFO Executor: Finished task 7.0 in stage 8.0 (TID 53). 2803 bytes result sent to driver\n",
      "25/06/27 09:17:38 INFO FileScanRDD: Reading File path: s3a://datalake/climate.csv, range: 1744830464-1879048192, partition values: [empty row]\n",
      "25/06/27 09:17:38 INFO TaskSetManager: Starting task 14.0 in stage 8.0 (TID 60) (hal9000, executor driver, partition 14, PROCESS_LOCAL, 7895 bytes) \n",
      "25/06/27 09:17:38 INFO TaskSetManager: Finished task 7.0 in stage 8.0 (TID 53) in 18387 ms on hal9000 (executor driver) (7/33)\n",
      "25/06/27 09:17:38 INFO Executor: Running task 14.0 in stage 8.0 (TID 60)\n",
      "25/06/27 09:17:38 INFO FileScanRDD: Reading File path: s3a://datalake/climate.csv, range: 1879048192-2013265920, partition values: [empty row]\n",
      "25/06/27 09:17:39 INFO Executor: Finished task 2.0 in stage 8.0 (TID 48). 2803 bytes result sent to driver\n",
      "25/06/27 09:17:39 INFO TaskSetManager: Starting task 15.0 in stage 8.0 (TID 61) (hal9000, executor driver, partition 15, PROCESS_LOCAL, 7895 bytes) \n",
      "25/06/27 09:17:39 INFO TaskSetManager: Finished task 2.0 in stage 8.0 (TID 48) in 19900 ms on hal9000 (executor driver) (8/33)\n",
      "25/06/27 09:17:39 INFO Executor: Running task 15.0 in stage 8.0 (TID 61)\n",
      "25/06/27 09:17:39 INFO FileScanRDD: Reading File path: s3a://datalake/climate.csv, range: 2013265920-2147483648, partition values: [empty row]\n",
      "25/06/27 09:17:54 INFO Executor: Finished task 9.0 in stage 8.0 (TID 55). 2803 bytes result sent to driver\n",
      "25/06/27 09:17:54 INFO TaskSetManager: Starting task 16.0 in stage 8.0 (TID 62) (hal9000, executor driver, partition 16, PROCESS_LOCAL, 7895 bytes) \n",
      "25/06/27 09:17:54 INFO TaskSetManager: Finished task 9.0 in stage 8.0 (TID 55) in 19310 ms on hal9000 (executor driver) (9/33)\n",
      "25/06/27 09:17:54 INFO Executor: Running task 16.0 in stage 8.0 (TID 62)\n",
      "25/06/27 09:17:54 INFO FileScanRDD: Reading File path: s3a://datalake/climate.csv, range: 2147483648-2281701376, partition values: [empty row]\n",
      "25/06/27 09:17:55 INFO Executor: Finished task 11.0 in stage 8.0 (TID 57). 2803 bytes result sent to driver\n",
      "25/06/27 09:17:55 INFO TaskSetManager: Starting task 17.0 in stage 8.0 (TID 63) (hal9000, executor driver, partition 17, PROCESS_LOCAL, 7895 bytes) \n",
      "25/06/27 09:17:55 INFO Executor: Running task 17.0 in stage 8.0 (TID 63)\n",
      "25/06/27 09:17:55 INFO TaskSetManager: Finished task 11.0 in stage 8.0 (TID 57) in 19350 ms on hal9000 (executor driver) (10/33)\n",
      "25/06/27 09:17:55 INFO FileScanRDD: Reading File path: s3a://datalake/climate.csv, range: 2281701376-2415919104, partition values: [empty row]\n",
      "25/06/27 09:17:57 INFO Executor: Finished task 10.0 in stage 8.0 (TID 56). 2760 bytes result sent to driver\n",
      "25/06/27 09:17:57 INFO TaskSetManager: Starting task 18.0 in stage 8.0 (TID 64) (hal9000, executor driver, partition 18, PROCESS_LOCAL, 7895 bytes) \n",
      "25/06/27 09:17:57 INFO Executor: Running task 18.0 in stage 8.0 (TID 64)\n",
      "25/06/27 09:17:57 INFO TaskSetManager: Finished task 10.0 in stage 8.0 (TID 56) in 22187 ms on hal9000 (executor driver) (11/33)\n",
      "25/06/27 09:17:57 INFO FileScanRDD: Reading File path: s3a://datalake/climate.csv, range: 2415919104-2550136832, partition values: [empty row]\n",
      "25/06/27 09:17:57 INFO Executor: Finished task 8.0 in stage 8.0 (TID 54). 2803 bytes result sent to driver\n",
      "25/06/27 09:17:57 INFO TaskSetManager: Starting task 19.0 in stage 8.0 (TID 65) (hal9000, executor driver, partition 19, PROCESS_LOCAL, 7895 bytes) \n",
      "25/06/27 09:17:57 INFO TaskSetManager: Finished task 8.0 in stage 8.0 (TID 54) in 22718 ms on hal9000 (executor driver) (12/33)\n",
      "25/06/27 09:17:57 INFO Executor: Running task 19.0 in stage 8.0 (TID 65)\n",
      "25/06/27 09:17:58 INFO FileScanRDD: Reading File path: s3a://datalake/climate.csv, range: 2550136832-2684354560, partition values: [empty row]\n",
      "25/06/27 09:17:58 INFO Executor: Finished task 12.0 in stage 8.0 (TID 58). 2803 bytes result sent to driver\n",
      "25/06/27 09:17:58 INFO TaskSetManager: Starting task 20.0 in stage 8.0 (TID 66) (hal9000, executor driver, partition 20, PROCESS_LOCAL, 7895 bytes) \n",
      "25/06/27 09:17:58 INFO TaskSetManager: Finished task 12.0 in stage 8.0 (TID 58) in 20856 ms on hal9000 (executor driver) (13/33)\n",
      "25/06/27 09:17:58 INFO Executor: Running task 20.0 in stage 8.0 (TID 66)\n",
      "25/06/27 09:17:58 INFO FileScanRDD: Reading File path: s3a://datalake/climate.csv, range: 2684354560-2818572288, partition values: [empty row]\n",
      "25/06/27 09:17:58 INFO Executor: Finished task 13.0 in stage 8.0 (TID 59). 2760 bytes result sent to driver\n",
      "25/06/27 09:17:58 INFO TaskSetManager: Starting task 21.0 in stage 8.0 (TID 67) (hal9000, executor driver, partition 21, PROCESS_LOCAL, 7895 bytes) \n",
      "25/06/27 09:17:58 INFO TaskSetManager: Finished task 13.0 in stage 8.0 (TID 59) in 20800 ms on hal9000 (executor driver) (14/33)\n",
      "25/06/27 09:17:58 INFO Executor: Running task 21.0 in stage 8.0 (TID 67)\n",
      "25/06/27 09:17:59 INFO FileScanRDD: Reading File path: s3a://datalake/climate.csv, range: 2818572288-2952790016, partition values: [empty row]\n",
      "25/06/27 09:17:59 INFO Executor: Finished task 15.0 in stage 8.0 (TID 61). 2760 bytes result sent to driver\n",
      "25/06/27 09:17:59 INFO TaskSetManager: Starting task 22.0 in stage 8.0 (TID 68) (hal9000, executor driver, partition 22, PROCESS_LOCAL, 7895 bytes) \n",
      "25/06/27 09:17:59 INFO TaskSetManager: Finished task 15.0 in stage 8.0 (TID 61) in 19228 ms on hal9000 (executor driver) (15/33)\n",
      "25/06/27 09:17:59 INFO Executor: Running task 22.0 in stage 8.0 (TID 68)\n",
      "25/06/27 09:17:59 INFO FileScanRDD: Reading File path: s3a://datalake/climate.csv, range: 2952790016-3087007744, partition values: [empty row]\n",
      "25/06/27 09:18:03 INFO Executor: Finished task 14.0 in stage 8.0 (TID 60). 2760 bytes result sent to driver\n",
      "25/06/27 09:18:03 INFO TaskSetManager: Starting task 23.0 in stage 8.0 (TID 69) (hal9000, executor driver, partition 23, PROCESS_LOCAL, 7895 bytes) \n",
      "25/06/27 09:18:03 INFO Executor: Running task 23.0 in stage 8.0 (TID 69)\n",
      "25/06/27 09:18:03 INFO TaskSetManager: Finished task 14.0 in stage 8.0 (TID 60) in 25319 ms on hal9000 (executor driver) (16/33)\n",
      "25/06/27 09:18:03 INFO FileScanRDD: Reading File path: s3a://datalake/climate.csv, range: 3087007744-3221225472, partition values: [empty row]\n",
      "25/06/27 09:18:12 INFO Executor: Finished task 16.0 in stage 8.0 (TID 62). 2803 bytes result sent to driver\n",
      "25/06/27 09:18:12 INFO TaskSetManager: Starting task 24.0 in stage 8.0 (TID 70) (hal9000, executor driver, partition 24, PROCESS_LOCAL, 7895 bytes) \n",
      "25/06/27 09:18:12 INFO TaskSetManager: Finished task 16.0 in stage 8.0 (TID 62) in 17769 ms on hal9000 (executor driver) (17/33)\n",
      "25/06/27 09:18:12 INFO Executor: Running task 24.0 in stage 8.0 (TID 70)\n",
      "25/06/27 09:18:12 INFO FileScanRDD: Reading File path: s3a://datalake/climate.csv, range: 3221225472-3355443200, partition values: [empty row]\n",
      "25/06/27 09:18:13 INFO Executor: Finished task 17.0 in stage 8.0 (TID 63). 2803 bytes result sent to driver\n",
      "25/06/27 09:18:13 INFO TaskSetManager: Starting task 25.0 in stage 8.0 (TID 71) (hal9000, executor driver, partition 25, PROCESS_LOCAL, 7895 bytes) \n",
      "25/06/27 09:18:13 INFO TaskSetManager: Finished task 17.0 in stage 8.0 (TID 63) in 18483 ms on hal9000 (executor driver) (18/33)\n",
      "25/06/27 09:18:13 INFO Executor: Running task 25.0 in stage 8.0 (TID 71)\n",
      "25/06/27 09:18:13 INFO Executor: Finished task 22.0 in stage 8.0 (TID 68). 2803 bytes result sent to driver\n",
      "25/06/27 09:18:13 INFO TaskSetManager: Starting task 26.0 in stage 8.0 (TID 72) (hal9000, executor driver, partition 26, PROCESS_LOCAL, 7895 bytes) \n",
      "25/06/27 09:18:13 INFO TaskSetManager: Finished task 22.0 in stage 8.0 (TID 68) in 14603 ms on hal9000 (executor driver) (19/33)\n",
      "25/06/27 09:18:13 INFO Executor: Running task 26.0 in stage 8.0 (TID 72)\n",
      "25/06/27 09:18:13 INFO FileScanRDD: Reading File path: s3a://datalake/climate.csv, range: 3355443200-3489660928, partition values: [empty row]\n",
      "25/06/27 09:18:13 INFO FileScanRDD: Reading File path: s3a://datalake/climate.csv, range: 3489660928-3623878656, partition values: [empty row]\n",
      "25/06/27 09:18:15 INFO Executor: Finished task 19.0 in stage 8.0 (TID 65). 2803 bytes result sent to driver\n",
      "25/06/27 09:18:15 INFO TaskSetManager: Starting task 27.0 in stage 8.0 (TID 73) (hal9000, executor driver, partition 27, PROCESS_LOCAL, 7895 bytes) \n",
      "25/06/27 09:18:15 INFO Executor: Running task 27.0 in stage 8.0 (TID 73)\n",
      "25/06/27 09:18:15 INFO TaskSetManager: Finished task 19.0 in stage 8.0 (TID 65) in 17586 ms on hal9000 (executor driver) (20/33)\n",
      "25/06/27 09:18:15 INFO FileScanRDD: Reading File path: s3a://datalake/climate.csv, range: 3623878656-3758096384, partition values: [empty row]\n",
      "25/06/27 09:18:15 INFO Executor: Finished task 21.0 in stage 8.0 (TID 67). 2760 bytes result sent to driver\n",
      "25/06/27 09:18:15 INFO TaskSetManager: Starting task 28.0 in stage 8.0 (TID 74) (hal9000, executor driver, partition 28, PROCESS_LOCAL, 7895 bytes) \n",
      "25/06/27 09:18:15 INFO Executor: Running task 28.0 in stage 8.0 (TID 74)\n",
      "25/06/27 09:18:15 INFO TaskSetManager: Finished task 21.0 in stage 8.0 (TID 67) in 16992 ms on hal9000 (executor driver) (21/33)\n",
      "25/06/27 09:18:15 INFO FileScanRDD: Reading File path: s3a://datalake/climate.csv, range: 3758096384-3892314112, partition values: [empty row]\n",
      "25/06/27 09:18:16 INFO Executor: Finished task 20.0 in stage 8.0 (TID 66). 2760 bytes result sent to driver\n",
      "25/06/27 09:18:16 INFO TaskSetManager: Starting task 29.0 in stage 8.0 (TID 75) (hal9000, executor driver, partition 29, PROCESS_LOCAL, 7895 bytes) \n",
      "25/06/27 09:18:16 INFO TaskSetManager: Finished task 20.0 in stage 8.0 (TID 66) in 18632 ms on hal9000 (executor driver) (22/33)\n",
      "25/06/27 09:18:16 INFO Executor: Running task 29.0 in stage 8.0 (TID 75)\n",
      "25/06/27 09:18:16 INFO FileScanRDD: Reading File path: s3a://datalake/climate.csv, range: 3892314112-4026531840, partition values: [empty row]\n",
      "25/06/27 09:18:17 INFO Executor: Finished task 18.0 in stage 8.0 (TID 64). 2803 bytes result sent to driver\n",
      "25/06/27 09:18:17 INFO TaskSetManager: Starting task 30.0 in stage 8.0 (TID 76) (hal9000, executor driver, partition 30, PROCESS_LOCAL, 7895 bytes) \n",
      "25/06/27 09:18:17 INFO Executor: Running task 30.0 in stage 8.0 (TID 76)\n",
      "25/06/27 09:18:17 INFO TaskSetManager: Finished task 18.0 in stage 8.0 (TID 64) in 19379 ms on hal9000 (executor driver) (23/33)\n",
      "25/06/27 09:18:17 INFO FileScanRDD: Reading File path: s3a://datalake/climate.csv, range: 4026531840-4160749568, partition values: [empty row]\n",
      "25/06/27 09:18:18 INFO Executor: Finished task 23.0 in stage 8.0 (TID 69). 2760 bytes result sent to driver\n",
      "25/06/27 09:18:18 INFO TaskSetManager: Starting task 31.0 in stage 8.0 (TID 77) (hal9000, executor driver, partition 31, PROCESS_LOCAL, 7895 bytes) \n",
      "25/06/27 09:18:18 INFO Executor: Running task 31.0 in stage 8.0 (TID 77)\n",
      "25/06/27 09:18:18 INFO TaskSetManager: Finished task 23.0 in stage 8.0 (TID 69) in 15329 ms on hal9000 (executor driver) (24/33)\n",
      "25/06/27 09:18:19 INFO FileScanRDD: Reading File path: s3a://datalake/climate.csv, range: 4160749568-4294967296, partition values: [empty row]\n",
      "25/06/27 09:18:26 INFO Executor: Finished task 24.0 in stage 8.0 (TID 70). 2760 bytes result sent to driver\n",
      "25/06/27 09:18:26 INFO TaskSetManager: Starting task 32.0 in stage 8.0 (TID 78) (hal9000, executor driver, partition 32, PROCESS_LOCAL, 7895 bytes) \n",
      "25/06/27 09:18:26 INFO TaskSetManager: Finished task 24.0 in stage 8.0 (TID 70) in 13972 ms on hal9000 (executor driver) (25/33)\n",
      "25/06/27 09:18:26 INFO Executor: Running task 32.0 in stage 8.0 (TID 78)\n",
      "25/06/27 09:18:26 INFO FileScanRDD: Reading File path: s3a://datalake/climate.csv, range: 4294967296-4356534577, partition values: [empty row]\n",
      "25/06/27 09:18:26 INFO Executor: Finished task 25.0 in stage 8.0 (TID 71). 2760 bytes result sent to driver\n",
      "25/06/27 09:18:26 INFO TaskSetManager: Finished task 25.0 in stage 8.0 (TID 71) in 13090 ms on hal9000 (executor driver) (26/33)\n",
      "25/06/27 09:18:26 INFO Executor: Finished task 26.0 in stage 8.0 (TID 72). 2760 bytes result sent to driver\n",
      "25/06/27 09:18:26 INFO TaskSetManager: Finished task 26.0 in stage 8.0 (TID 72) in 13199 ms on hal9000 (executor driver) (27/33)\n",
      "25/06/27 09:18:28 INFO Executor: Finished task 30.0 in stage 8.0 (TID 76). 2760 bytes result sent to driver\n",
      "25/06/27 09:18:28 INFO TaskSetManager: Finished task 30.0 in stage 8.0 (TID 76) in 11269 ms on hal9000 (executor driver) (28/33)\n",
      "25/06/27 09:18:28 INFO Executor: Finished task 29.0 in stage 8.0 (TID 75). 2760 bytes result sent to driver\n",
      "25/06/27 09:18:28 INFO TaskSetManager: Finished task 29.0 in stage 8.0 (TID 75) in 11926 ms on hal9000 (executor driver) (29/33)\n",
      "25/06/27 09:18:28 INFO Executor: Finished task 28.0 in stage 8.0 (TID 74). 2760 bytes result sent to driver\n",
      "25/06/27 09:18:28 INFO TaskSetManager: Finished task 28.0 in stage 8.0 (TID 74) in 12847 ms on hal9000 (executor driver) (30/33)\n",
      "25/06/27 09:18:28 INFO Executor: Finished task 27.0 in stage 8.0 (TID 73). 2760 bytes result sent to driver\n",
      "25/06/27 09:18:28 INFO TaskSetManager: Finished task 27.0 in stage 8.0 (TID 73) in 13199 ms on hal9000 (executor driver) (31/33)\n",
      "25/06/27 09:18:29 INFO Executor: Finished task 31.0 in stage 8.0 (TID 77). 2760 bytes result sent to driver\n",
      "25/06/27 09:18:29 INFO TaskSetManager: Finished task 31.0 in stage 8.0 (TID 77) in 10137 ms on hal9000 (executor driver) (32/33)\n",
      "25/06/27 09:18:29 INFO Executor: Finished task 32.0 in stage 8.0 (TID 78). 2760 bytes result sent to driver\n",
      "25/06/27 09:18:29 INFO TaskSetManager: Finished task 32.0 in stage 8.0 (TID 78) in 3451 ms on hal9000 (executor driver) (33/33)\n",
      "25/06/27 09:18:29 INFO TaskSchedulerImpl: Removed TaskSet 8.0, whose tasks have all completed, from pool \n",
      "25/06/27 09:18:29 INFO DAGScheduler: ShuffleMapStage 8 (count at NativeMethodAccessorImpl.java:0) finished in 69.832 s\n",
      "25/06/27 09:18:29 INFO DAGScheduler: looking for newly runnable stages\n",
      "25/06/27 09:18:29 INFO DAGScheduler: running: Set()\n",
      "25/06/27 09:18:29 INFO DAGScheduler: waiting: Set()\n",
      "25/06/27 09:18:29 INFO DAGScheduler: failed: Set()\n",
      "25/06/27 09:18:29 INFO ShufflePartitionsUtil: For shuffle(2), advisory target size: 67108864, actual target size 1048576, minimum partition size: 1048576\n",
      "25/06/27 09:18:30 INFO HashAggregateExec: spark.sql.codegen.aggregate.map.twolevel.enabled is set to true, but current version of codegened fast hashmap does not support this aggregate.\n",
      "25/06/27 09:18:30 INFO CodeGenerator: Code generated in 99.056913 ms\n",
      "25/06/27 09:18:30 INFO DAGScheduler: Registering RDD 35 (count at NativeMethodAccessorImpl.java:0) as input to shuffle 3\n",
      "25/06/27 09:18:30 INFO DAGScheduler: Got map stage job 7 (count at NativeMethodAccessorImpl.java:0) with 4 output partitions\n",
      "25/06/27 09:18:30 INFO DAGScheduler: Final stage: ShuffleMapStage 10 (count at NativeMethodAccessorImpl.java:0)\n",
      "25/06/27 09:18:30 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 9)\n",
      "25/06/27 09:18:30 INFO DAGScheduler: Missing parents: List()\n",
      "25/06/27 09:18:30 INFO DAGScheduler: Submitting ShuffleMapStage 10 (MapPartitionsRDD[35] at count at NativeMethodAccessorImpl.java:0), which has no missing parents\n",
      "25/06/27 09:18:30 INFO MemoryStore: Block broadcast_14 stored as values in memory (estimated size 48.6 KiB, free 433.3 MiB)\n",
      "25/06/27 09:18:30 INFO MemoryStore: Block broadcast_14_piece0 stored as bytes in memory (estimated size 22.0 KiB, free 433.3 MiB)\n",
      "25/06/27 09:18:30 INFO BlockManagerInfo: Added broadcast_14_piece0 in memory on hal9000:34557 (size: 22.0 KiB, free: 434.2 MiB)\n",
      "25/06/27 09:18:30 INFO SparkContext: Created broadcast 14 from broadcast at DAGScheduler.scala:1535\n",
      "25/06/27 09:18:30 INFO DAGScheduler: Submitting 4 missing tasks from ShuffleMapStage 10 (MapPartitionsRDD[35] at count at NativeMethodAccessorImpl.java:0) (first 15 tasks are for partitions Vector(0, 1, 2, 3))\n",
      "25/06/27 09:18:30 INFO TaskSchedulerImpl: Adding task set 10.0 with 4 tasks resource profile 0\n",
      "25/06/27 09:18:30 INFO TaskSetManager: Starting task 0.0 in stage 10.0 (TID 79) (hal9000, executor driver, partition 0, NODE_LOCAL, 7352 bytes) \n",
      "25/06/27 09:18:30 INFO TaskSetManager: Starting task 1.0 in stage 10.0 (TID 80) (hal9000, executor driver, partition 1, NODE_LOCAL, 7352 bytes) \n",
      "25/06/27 09:18:30 INFO TaskSetManager: Starting task 2.0 in stage 10.0 (TID 81) (hal9000, executor driver, partition 2, NODE_LOCAL, 7352 bytes) \n",
      "25/06/27 09:18:30 INFO TaskSetManager: Starting task 3.0 in stage 10.0 (TID 82) (hal9000, executor driver, partition 3, NODE_LOCAL, 7352 bytes) \n",
      "25/06/27 09:18:30 INFO Executor: Running task 0.0 in stage 10.0 (TID 79)\n",
      "25/06/27 09:18:30 INFO Executor: Running task 1.0 in stage 10.0 (TID 80)\n",
      "25/06/27 09:18:30 INFO Executor: Running task 2.0 in stage 10.0 (TID 81)\n",
      "25/06/27 09:18:30 INFO Executor: Running task 3.0 in stage 10.0 (TID 82)\n",
      "25/06/27 09:18:30 INFO ShuffleBlockFetcherIterator: Getting 33 (1040.9 KiB) non-empty blocks including 33 (1040.9 KiB) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks\n",
      "25/06/27 09:18:30 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 11 ms\n",
      "25/06/27 09:18:30 INFO ShuffleBlockFetcherIterator: Getting 33 (1033.1 KiB) non-empty blocks including 33 (1033.1 KiB) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks\n",
      "25/06/27 09:18:30 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 12 ms\n",
      "25/06/27 09:18:30 INFO ShuffleBlockFetcherIterator: Getting 33 (1493.6 KiB) non-empty blocks including 33 (1493.6 KiB) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks\n",
      "25/06/27 09:18:30 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 19 ms\n",
      "25/06/27 09:18:30 INFO ShuffleBlockFetcherIterator: Getting 33 (1040.6 KiB) non-empty blocks including 33 (1040.6 KiB) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks\n",
      "25/06/27 09:18:30 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 28 ms\n",
      "25/06/27 09:18:30 INFO Executor: Finished task 1.0 in stage 10.0 (TID 80). 5633 bytes result sent to driver\n",
      "25/06/27 09:18:30 INFO TaskSetManager: Finished task 1.0 in stage 10.0 (TID 80) in 228 ms on hal9000 (executor driver) (1/4)\n",
      "25/06/27 09:18:30 INFO Executor: Finished task 0.0 in stage 10.0 (TID 79). 5633 bytes result sent to driver\n",
      "25/06/27 09:18:30 INFO TaskSetManager: Finished task 0.0 in stage 10.0 (TID 79) in 237 ms on hal9000 (executor driver) (2/4)\n",
      "25/06/27 09:18:30 INFO Executor: Finished task 3.0 in stage 10.0 (TID 82). 5633 bytes result sent to driver\n",
      "25/06/27 09:18:30 INFO TaskSetManager: Finished task 3.0 in stage 10.0 (TID 82) in 302 ms on hal9000 (executor driver) (3/4)\n",
      "25/06/27 09:18:30 INFO Executor: Finished task 2.0 in stage 10.0 (TID 81). 5633 bytes result sent to driver\n",
      "25/06/27 09:18:30 INFO TaskSetManager: Finished task 2.0 in stage 10.0 (TID 81) in 315 ms on hal9000 (executor driver) (4/4)\n",
      "25/06/27 09:18:30 INFO TaskSchedulerImpl: Removed TaskSet 10.0, whose tasks have all completed, from pool \n",
      "25/06/27 09:18:30 INFO DAGScheduler: ShuffleMapStage 10 (count at NativeMethodAccessorImpl.java:0) finished in 0.357 s\n",
      "25/06/27 09:18:30 INFO DAGScheduler: looking for newly runnable stages\n",
      "25/06/27 09:18:30 INFO DAGScheduler: running: Set()\n",
      "25/06/27 09:18:30 INFO DAGScheduler: waiting: Set()\n",
      "25/06/27 09:18:30 INFO DAGScheduler: failed: Set()\n",
      "25/06/27 09:18:30 INFO CodeGenerator: Code generated in 14.728178 ms\n",
      "25/06/27 09:18:30 INFO SparkContext: Starting job: count at NativeMethodAccessorImpl.java:0\n",
      "25/06/27 09:18:30 INFO DAGScheduler: Got job 8 (count at NativeMethodAccessorImpl.java:0) with 1 output partitions\n",
      "25/06/27 09:18:30 INFO DAGScheduler: Final stage: ResultStage 13 (count at NativeMethodAccessorImpl.java:0)\n",
      "25/06/27 09:18:30 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 12)\n",
      "25/06/27 09:18:30 INFO DAGScheduler: Missing parents: List()\n",
      "25/06/27 09:18:30 INFO DAGScheduler: Submitting ResultStage 13 (MapPartitionsRDD[38] at count at NativeMethodAccessorImpl.java:0), which has no missing parents\n",
      "25/06/27 09:18:30 INFO MemoryStore: Block broadcast_15 stored as values in memory (estimated size 12.1 KiB, free 433.3 MiB)\n",
      "25/06/27 09:18:30 INFO MemoryStore: Block broadcast_15_piece0 stored as bytes in memory (estimated size 5.8 KiB, free 433.3 MiB)\n",
      "25/06/27 09:18:30 INFO BlockManagerInfo: Added broadcast_15_piece0 in memory on hal9000:34557 (size: 5.8 KiB, free: 434.2 MiB)\n",
      "25/06/27 09:18:30 INFO SparkContext: Created broadcast 15 from broadcast at DAGScheduler.scala:1535\n",
      "25/06/27 09:18:30 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 13 (MapPartitionsRDD[38] at count at NativeMethodAccessorImpl.java:0) (first 15 tasks are for partitions Vector(0))\n",
      "25/06/27 09:18:30 INFO TaskSchedulerImpl: Adding task set 13.0 with 1 tasks resource profile 0\n",
      "25/06/27 09:18:30 INFO TaskSetManager: Starting task 0.0 in stage 13.0 (TID 83) (hal9000, executor driver, partition 0, NODE_LOCAL, 7363 bytes) \n",
      "25/06/27 09:18:30 INFO Executor: Running task 0.0 in stage 13.0 (TID 83)\n",
      "25/06/27 09:18:30 INFO ShuffleBlockFetcherIterator: Getting 4 (240.0 B) non-empty blocks including 4 (240.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks\n",
      "25/06/27 09:18:30 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 4 ms\n",
      "25/06/27 09:18:30 INFO Executor: Finished task 0.0 in stage 13.0 (TID 83). 4038 bytes result sent to driver\n",
      "25/06/27 09:18:30 INFO TaskSetManager: Finished task 0.0 in stage 13.0 (TID 83) in 21 ms on hal9000 (executor driver) (1/1)\n",
      "25/06/27 09:18:30 INFO TaskSchedulerImpl: Removed TaskSet 13.0, whose tasks have all completed, from pool \n",
      "25/06/27 09:18:30 INFO DAGScheduler: ResultStage 13 (count at NativeMethodAccessorImpl.java:0) finished in 0.069 s\n",
      "25/06/27 09:18:30 INFO DAGScheduler: Job 8 is finished. Cancelling potential speculative or zombie tasks for this job\n",
      "25/06/27 09:18:30 INFO TaskSchedulerImpl: Killing all running tasks in stage 13: Stage finished\n",
      "25/06/27 09:18:30 INFO DAGScheduler: Job 8 finished: count at NativeMethodAccessorImpl.java:0, took 0.075984 s\n",
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Numero de Tuplas:  7670\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "25/06/27 09:18:31 INFO FileSourceStrategy: Pushed Filters: \n",
      "25/06/27 09:18:31 INFO FileSourceStrategy: Post-Scan Filters: \n",
      "25/06/27 09:18:31 WARN WindowExec: No Partition Defined for Window operation! Moving all data to a single partition, this can cause serious performance degradation.\n",
      "25/06/27 09:18:31 WARN WindowExec: No Partition Defined for Window operation! Moving all data to a single partition, this can cause serious performance degradation.\n",
      "25/06/27 09:18:31 WARN WindowExec: No Partition Defined for Window operation! Moving all data to a single partition, this can cause serious performance degradation.\n",
      "25/06/27 09:18:31 INFO HashAggregateExec: spark.sql.codegen.aggregate.map.twolevel.enabled is set to true, but current version of codegened fast hashmap does not support this aggregate.\n",
      "25/06/27 09:18:31 INFO MemoryStore: Block broadcast_16 stored as values in memory (estimated size 203.2 KiB, free 433.1 MiB)\n",
      "25/06/27 09:18:31 INFO MemoryStore: Block broadcast_16_piece0 stored as bytes in memory (estimated size 35.4 KiB, free 433.1 MiB)\n",
      "25/06/27 09:18:31 INFO BlockManagerInfo: Added broadcast_16_piece0 in memory on hal9000:34557 (size: 35.4 KiB, free: 434.2 MiB)\n",
      "25/06/27 09:18:31 INFO SparkContext: Created broadcast 16 from showString at NativeMethodAccessorImpl.java:0\n",
      "25/06/27 09:18:31 INFO FileSourceScanExec: Planning scan with bin packing, max size: 134217728 bytes, open cost is considered as scanning 4194304 bytes.\n",
      "25/06/27 09:18:31 INFO DAGScheduler: Registering RDD 42 (showString at NativeMethodAccessorImpl.java:0) as input to shuffle 4\n",
      "25/06/27 09:18:31 INFO DAGScheduler: Got map stage job 9 (showString at NativeMethodAccessorImpl.java:0) with 33 output partitions\n",
      "25/06/27 09:18:31 INFO DAGScheduler: Final stage: ShuffleMapStage 14 (showString at NativeMethodAccessorImpl.java:0)\n",
      "25/06/27 09:18:31 INFO DAGScheduler: Parents of final stage: List()\n",
      "25/06/27 09:18:31 INFO DAGScheduler: Missing parents: List()\n",
      "25/06/27 09:18:31 INFO DAGScheduler: Submitting ShuffleMapStage 14 (MapPartitionsRDD[42] at showString at NativeMethodAccessorImpl.java:0), which has no missing parents\n",
      "25/06/27 09:18:31 INFO MemoryStore: Block broadcast_17 stored as values in memory (estimated size 41.3 KiB, free 433.0 MiB)\n",
      "25/06/27 09:18:31 INFO MemoryStore: Block broadcast_17_piece0 stored as bytes in memory (estimated size 19.0 KiB, free 433.0 MiB)\n",
      "25/06/27 09:18:31 INFO BlockManagerInfo: Added broadcast_17_piece0 in memory on hal9000:34557 (size: 19.0 KiB, free: 434.2 MiB)\n",
      "25/06/27 09:18:31 INFO SparkContext: Created broadcast 17 from broadcast at DAGScheduler.scala:1535\n",
      "25/06/27 09:18:31 INFO DAGScheduler: Submitting 33 missing tasks from ShuffleMapStage 14 (MapPartitionsRDD[42] at showString at NativeMethodAccessorImpl.java:0) (first 15 tasks are for partitions Vector(0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14))\n",
      "25/06/27 09:18:31 INFO TaskSchedulerImpl: Adding task set 14.0 with 33 tasks resource profile 0\n",
      "25/06/27 09:18:31 INFO TaskSetManager: Starting task 0.0 in stage 14.0 (TID 84) (hal9000, executor driver, partition 0, PROCESS_LOCAL, 7895 bytes) \n",
      "25/06/27 09:18:31 INFO TaskSetManager: Starting task 1.0 in stage 14.0 (TID 85) (hal9000, executor driver, partition 1, PROCESS_LOCAL, 7895 bytes) \n",
      "25/06/27 09:18:31 INFO TaskSetManager: Starting task 2.0 in stage 14.0 (TID 86) (hal9000, executor driver, partition 2, PROCESS_LOCAL, 7895 bytes) \n",
      "25/06/27 09:18:31 INFO TaskSetManager: Starting task 3.0 in stage 14.0 (TID 87) (hal9000, executor driver, partition 3, PROCESS_LOCAL, 7895 bytes) \n",
      "25/06/27 09:18:31 INFO TaskSetManager: Starting task 4.0 in stage 14.0 (TID 88) (hal9000, executor driver, partition 4, PROCESS_LOCAL, 7895 bytes) \n",
      "25/06/27 09:18:31 INFO TaskSetManager: Starting task 5.0 in stage 14.0 (TID 89) (hal9000, executor driver, partition 5, PROCESS_LOCAL, 7895 bytes) \n",
      "25/06/27 09:18:31 INFO TaskSetManager: Starting task 6.0 in stage 14.0 (TID 90) (hal9000, executor driver, partition 6, PROCESS_LOCAL, 7895 bytes) \n",
      "25/06/27 09:18:31 INFO TaskSetManager: Starting task 7.0 in stage 14.0 (TID 91) (hal9000, executor driver, partition 7, PROCESS_LOCAL, 7895 bytes) \n",
      "25/06/27 09:18:31 INFO Executor: Running task 5.0 in stage 14.0 (TID 89)\n",
      "25/06/27 09:18:31 INFO Executor: Running task 4.0 in stage 14.0 (TID 88)\n",
      "25/06/27 09:18:31 INFO Executor: Running task 6.0 in stage 14.0 (TID 90)\n",
      "25/06/27 09:18:31 INFO Executor: Running task 1.0 in stage 14.0 (TID 85)\n",
      "25/06/27 09:18:31 INFO Executor: Running task 2.0 in stage 14.0 (TID 86)\n",
      "25/06/27 09:18:31 INFO Executor: Running task 0.0 in stage 14.0 (TID 84)\n",
      "25/06/27 09:18:31 INFO Executor: Running task 3.0 in stage 14.0 (TID 87)\n",
      "25/06/27 09:18:31 INFO Executor: Running task 7.0 in stage 14.0 (TID 91)\n",
      "25/06/27 09:18:31 INFO FileScanRDD: Reading File path: s3a://datalake/climate.csv, range: 671088640-805306368, partition values: [empty row]\n",
      "25/06/27 09:18:31 INFO FileScanRDD: Reading File path: s3a://datalake/climate.csv, range: 0-134217728, partition values: [empty row]\n",
      "25/06/27 09:18:31 INFO FileScanRDD: Reading File path: s3a://datalake/climate.csv, range: 134217728-268435456, partition values: [empty row]\n",
      "25/06/27 09:18:31 INFO FileScanRDD: Reading File path: s3a://datalake/climate.csv, range: 805306368-939524096, partition values: [empty row]\n",
      "25/06/27 09:18:31 INFO FileScanRDD: Reading File path: s3a://datalake/climate.csv, range: 268435456-402653184, partition values: [empty row]\n",
      "25/06/27 09:18:31 INFO FileScanRDD: Reading File path: s3a://datalake/climate.csv, range: 536870912-671088640, partition values: [empty row]\n",
      "25/06/27 09:18:31 INFO FileScanRDD: Reading File path: s3a://datalake/climate.csv, range: 402653184-536870912, partition values: [empty row]\n",
      "25/06/27 09:18:31 INFO FileScanRDD: Reading File path: s3a://datalake/climate.csv, range: 939524096-1073741824, partition values: [empty row]\n",
      "25/06/27 09:18:31 INFO BlockManagerInfo: Removed broadcast_15_piece0 on hal9000:34557 in memory (size: 5.8 KiB, free: 434.2 MiB)\n",
      "25/06/27 09:18:31 INFO BlockManagerInfo: Removed broadcast_14_piece0 on hal9000:34557 in memory (size: 22.0 KiB, free: 434.2 MiB)\n",
      "25/06/27 09:18:43 INFO Executor: Finished task 6.0 in stage 14.0 (TID 90). 2760 bytes result sent to driver\n",
      "25/06/27 09:18:43 INFO TaskSetManager: Starting task 8.0 in stage 14.0 (TID 92) (hal9000, executor driver, partition 8, PROCESS_LOCAL, 7895 bytes) \n",
      "25/06/27 09:18:43 INFO TaskSetManager: Finished task 6.0 in stage 14.0 (TID 90) in 11828 ms on hal9000 (executor driver) (1/33)\n",
      "25/06/27 09:18:43 INFO Executor: Running task 8.0 in stage 14.0 (TID 92)\n",
      "25/06/27 09:18:43 INFO FileScanRDD: Reading File path: s3a://datalake/climate.csv, range: 1073741824-1207959552, partition values: [empty row]\n",
      "25/06/27 09:18:45 INFO Executor: Finished task 5.0 in stage 14.0 (TID 89). 2760 bytes result sent to driver\n",
      "25/06/27 09:18:45 INFO TaskSetManager: Starting task 9.0 in stage 14.0 (TID 93) (hal9000, executor driver, partition 9, PROCESS_LOCAL, 7895 bytes) \n",
      "25/06/27 09:18:45 INFO TaskSetManager: Finished task 5.0 in stage 14.0 (TID 89) in 14189 ms on hal9000 (executor driver) (2/33)\n",
      "25/06/27 09:18:45 INFO Executor: Running task 9.0 in stage 14.0 (TID 93)\n",
      "25/06/27 09:18:45 INFO FileScanRDD: Reading File path: s3a://datalake/climate.csv, range: 1207959552-1342177280, partition values: [empty row]\n",
      "25/06/27 09:18:45 INFO Executor: Finished task 7.0 in stage 14.0 (TID 91). 2803 bytes result sent to driver\n",
      "25/06/27 09:18:45 INFO TaskSetManager: Starting task 10.0 in stage 14.0 (TID 94) (hal9000, executor driver, partition 10, PROCESS_LOCAL, 7895 bytes) \n",
      "25/06/27 09:18:45 INFO TaskSetManager: Finished task 7.0 in stage 14.0 (TID 91) in 14567 ms on hal9000 (executor driver) (3/33)\n",
      "25/06/27 09:18:45 INFO Executor: Running task 10.0 in stage 14.0 (TID 94)\n",
      "25/06/27 09:18:46 INFO FileScanRDD: Reading File path: s3a://datalake/climate.csv, range: 1342177280-1476395008, partition values: [empty row]\n",
      "25/06/27 09:18:46 INFO Executor: Finished task 3.0 in stage 14.0 (TID 87). 2760 bytes result sent to driver\n",
      "25/06/27 09:18:46 INFO TaskSetManager: Starting task 11.0 in stage 14.0 (TID 95) (hal9000, executor driver, partition 11, PROCESS_LOCAL, 7895 bytes) \n",
      "25/06/27 09:18:46 INFO TaskSetManager: Finished task 3.0 in stage 14.0 (TID 87) in 15463 ms on hal9000 (executor driver) (4/33)\n",
      "25/06/27 09:18:46 INFO Executor: Running task 11.0 in stage 14.0 (TID 95)\n",
      "25/06/27 09:18:46 INFO FileScanRDD: Reading File path: s3a://datalake/climate.csv, range: 1476395008-1610612736, partition values: [empty row]\n",
      "25/06/27 09:18:48 INFO Executor: Finished task 2.0 in stage 14.0 (TID 86). 2803 bytes result sent to driver\n",
      "25/06/27 09:18:48 INFO TaskSetManager: Starting task 12.0 in stage 14.0 (TID 96) (hal9000, executor driver, partition 12, PROCESS_LOCAL, 7895 bytes) \n",
      "25/06/27 09:18:48 INFO TaskSetManager: Finished task 2.0 in stage 14.0 (TID 86) in 16682 ms on hal9000 (executor driver) (5/33)\n",
      "25/06/27 09:18:48 INFO Executor: Running task 12.0 in stage 14.0 (TID 96)\n",
      "25/06/27 09:18:48 INFO Executor: Finished task 1.0 in stage 14.0 (TID 85). 2760 bytes result sent to driver\n",
      "25/06/27 09:18:48 INFO TaskSetManager: Starting task 13.0 in stage 14.0 (TID 97) (hal9000, executor driver, partition 13, PROCESS_LOCAL, 7895 bytes) \n",
      "25/06/27 09:18:48 INFO TaskSetManager: Finished task 1.0 in stage 14.0 (TID 85) in 16807 ms on hal9000 (executor driver) (6/33)\n",
      "25/06/27 09:18:48 INFO Executor: Running task 13.0 in stage 14.0 (TID 97)\n",
      "25/06/27 09:18:48 INFO FileScanRDD: Reading File path: s3a://datalake/climate.csv, range: 1610612736-1744830464, partition values: [empty row]\n",
      "25/06/27 09:18:48 INFO Executor: Finished task 0.0 in stage 14.0 (TID 84). 2803 bytes result sent to driver\n",
      "25/06/27 09:18:48 INFO TaskSetManager: Finished task 0.0 in stage 14.0 (TID 84) in 16891 ms on hal9000 (executor driver) (7/33)\n",
      "25/06/27 09:18:48 INFO TaskSetManager: Starting task 14.0 in stage 14.0 (TID 98) (hal9000, executor driver, partition 14, PROCESS_LOCAL, 7895 bytes) \n",
      "25/06/27 09:18:48 INFO Executor: Running task 14.0 in stage 14.0 (TID 98)\n",
      "25/06/27 09:18:48 INFO FileScanRDD: Reading File path: s3a://datalake/climate.csv, range: 1879048192-2013265920, partition values: [empty row]\n",
      "25/06/27 09:18:48 INFO FileScanRDD: Reading File path: s3a://datalake/climate.csv, range: 1744830464-1879048192, partition values: [empty row]\n",
      "25/06/27 09:18:51 INFO Executor: Finished task 4.0 in stage 14.0 (TID 88). 2760 bytes result sent to driver\n",
      "25/06/27 09:18:51 INFO TaskSetManager: Starting task 15.0 in stage 14.0 (TID 99) (hal9000, executor driver, partition 15, PROCESS_LOCAL, 7895 bytes) \n",
      "25/06/27 09:18:51 INFO TaskSetManager: Finished task 4.0 in stage 14.0 (TID 88) in 19672 ms on hal9000 (executor driver) (8/33)\n",
      "25/06/27 09:18:51 INFO Executor: Running task 15.0 in stage 14.0 (TID 99)\n",
      "25/06/27 09:18:51 INFO FileScanRDD: Reading File path: s3a://datalake/climate.csv, range: 2013265920-2147483648, partition values: [empty row]\n",
      "25/06/27 09:19:05 INFO Executor: Finished task 11.0 in stage 14.0 (TID 95). 2803 bytes result sent to driver\n",
      "25/06/27 09:19:05 INFO TaskSetManager: Starting task 16.0 in stage 14.0 (TID 100) (hal9000, executor driver, partition 16, PROCESS_LOCAL, 7895 bytes) \n",
      "25/06/27 09:19:05 INFO TaskSetManager: Finished task 11.0 in stage 14.0 (TID 95) in 18229 ms on hal9000 (executor driver) (9/33)\n",
      "25/06/27 09:19:05 INFO Executor: Running task 16.0 in stage 14.0 (TID 100)\n",
      "25/06/27 09:19:05 INFO FileScanRDD: Reading File path: s3a://datalake/climate.csv, range: 2147483648-2281701376, partition values: [empty row]\n",
      "25/06/27 09:19:07 INFO Executor: Finished task 15.0 in stage 14.0 (TID 99). 2760 bytes result sent to driver\n",
      "25/06/27 09:19:07 INFO TaskSetManager: Starting task 17.0 in stage 14.0 (TID 101) (hal9000, executor driver, partition 17, PROCESS_LOCAL, 7895 bytes) \n",
      "25/06/27 09:19:07 INFO TaskSetManager: Finished task 15.0 in stage 14.0 (TID 99) in 16257 ms on hal9000 (executor driver) (10/33)\n",
      "25/06/27 09:19:07 INFO Executor: Running task 17.0 in stage 14.0 (TID 101)\n",
      "25/06/27 09:19:07 INFO FileScanRDD: Reading File path: s3a://datalake/climate.csv, range: 2281701376-2415919104, partition values: [empty row]\n",
      "25/06/27 09:19:07 INFO Executor: Finished task 9.0 in stage 14.0 (TID 93). 2803 bytes result sent to driver\n",
      "25/06/27 09:19:07 INFO TaskSetManager: Starting task 18.0 in stage 14.0 (TID 102) (hal9000, executor driver, partition 18, PROCESS_LOCAL, 7895 bytes) \n",
      "25/06/27 09:19:07 INFO TaskSetManager: Finished task 9.0 in stage 14.0 (TID 93) in 22083 ms on hal9000 (executor driver) (11/33)\n",
      "25/06/27 09:19:07 INFO Executor: Running task 18.0 in stage 14.0 (TID 102)\n",
      "25/06/27 09:19:07 INFO FileScanRDD: Reading File path: s3a://datalake/climate.csv, range: 2415919104-2550136832, partition values: [empty row]\n",
      "25/06/27 09:19:08 INFO Executor: Finished task 10.0 in stage 14.0 (TID 94). 2760 bytes result sent to driver\n",
      "25/06/27 09:19:08 INFO TaskSetManager: Starting task 19.0 in stage 14.0 (TID 103) (hal9000, executor driver, partition 19, PROCESS_LOCAL, 7895 bytes) \n",
      "25/06/27 09:19:08 INFO Executor: Running task 19.0 in stage 14.0 (TID 103)\n",
      "25/06/27 09:19:08 INFO TaskSetManager: Finished task 10.0 in stage 14.0 (TID 94) in 22379 ms on hal9000 (executor driver) (12/33)\n",
      "25/06/27 09:19:08 INFO FileScanRDD: Reading File path: s3a://datalake/climate.csv, range: 2550136832-2684354560, partition values: [empty row]\n",
      "25/06/27 09:19:09 INFO Executor: Finished task 12.0 in stage 14.0 (TID 96). 2760 bytes result sent to driver\n",
      "25/06/27 09:19:09 INFO TaskSetManager: Starting task 20.0 in stage 14.0 (TID 104) (hal9000, executor driver, partition 20, PROCESS_LOCAL, 7895 bytes) \n",
      "25/06/27 09:19:09 INFO Executor: Running task 20.0 in stage 14.0 (TID 104)\n",
      "25/06/27 09:19:09 INFO TaskSetManager: Finished task 12.0 in stage 14.0 (TID 96) in 20953 ms on hal9000 (executor driver) (13/33)\n",
      "25/06/27 09:19:09 INFO FileScanRDD: Reading File path: s3a://datalake/climate.csv, range: 2684354560-2818572288, partition values: [empty row]\n",
      "25/06/27 09:19:09 INFO Executor: Finished task 13.0 in stage 14.0 (TID 97). 2760 bytes result sent to driver\n",
      "25/06/27 09:19:09 INFO TaskSetManager: Starting task 21.0 in stage 14.0 (TID 105) (hal9000, executor driver, partition 21, PROCESS_LOCAL, 7895 bytes) \n",
      "25/06/27 09:19:09 INFO TaskSetManager: Finished task 13.0 in stage 14.0 (TID 97) in 21092 ms on hal9000 (executor driver) (14/33)\n",
      "25/06/27 09:19:09 INFO Executor: Running task 21.0 in stage 14.0 (TID 105)\n",
      "25/06/27 09:19:09 INFO FileScanRDD: Reading File path: s3a://datalake/climate.csv, range: 2818572288-2952790016, partition values: [empty row]\n",
      "25/06/27 09:19:09 INFO Executor: Finished task 8.0 in stage 14.0 (TID 92). 2803 bytes result sent to driver\n",
      "25/06/27 09:19:09 INFO TaskSetManager: Starting task 22.0 in stage 14.0 (TID 106) (hal9000, executor driver, partition 22, PROCESS_LOCAL, 7895 bytes) \n",
      "25/06/27 09:19:09 INFO Executor: Running task 22.0 in stage 14.0 (TID 106)\n",
      "25/06/27 09:19:09 INFO TaskSetManager: Finished task 8.0 in stage 14.0 (TID 92) in 26168 ms on hal9000 (executor driver) (15/33)\n",
      "25/06/27 09:19:09 INFO FileScanRDD: Reading File path: s3a://datalake/climate.csv, range: 2952790016-3087007744, partition values: [empty row]\n",
      "25/06/27 09:19:13 INFO Executor: Finished task 14.0 in stage 14.0 (TID 98). 2760 bytes result sent to driver\n",
      "25/06/27 09:19:13 INFO TaskSetManager: Starting task 23.0 in stage 14.0 (TID 107) (hal9000, executor driver, partition 23, PROCESS_LOCAL, 7895 bytes) \n",
      "25/06/27 09:19:13 INFO Executor: Running task 23.0 in stage 14.0 (TID 107)\n",
      "25/06/27 09:19:13 INFO TaskSetManager: Finished task 14.0 in stage 14.0 (TID 98) in 25078 ms on hal9000 (executor driver) (16/33)\n",
      "25/06/27 09:19:13 INFO FileScanRDD: Reading File path: s3a://datalake/climate.csv, range: 3087007744-3221225472, partition values: [empty row]\n",
      "25/06/27 09:19:20 INFO BlockManagerInfo: Removed broadcast_7_piece0 on hal9000:34557 in memory (size: 35.4 KiB, free: 434.2 MiB)\n",
      "25/06/27 09:19:20 INFO BlockManagerInfo: Removed broadcast_12_piece0 on hal9000:34557 in memory (size: 35.4 KiB, free: 434.3 MiB)\n",
      "25/06/27 09:19:20 INFO BlockManagerInfo: Removed broadcast_13_piece0 on hal9000:34557 in memory (size: 19.0 KiB, free: 434.3 MiB)\n",
      "25/06/27 09:19:20 INFO BlockManagerInfo: Removed broadcast_0_piece0 on hal9000:34557 in memory (size: 35.4 KiB, free: 434.3 MiB)\n",
      "25/06/27 09:19:20 INFO BlockManagerInfo: Removed broadcast_8_piece0 on hal9000:34557 in memory (size: 8.7 KiB, free: 434.3 MiB)\n",
      "25/06/27 09:19:20 INFO BlockManagerInfo: Removed broadcast_1_piece0 on hal9000:34557 in memory (size: 35.4 KiB, free: 434.3 MiB)\n",
      "25/06/27 09:19:24 INFO Executor: Finished task 16.0 in stage 14.0 (TID 100). 2803 bytes result sent to driver\n",
      "25/06/27 09:19:24 INFO TaskSetManager: Starting task 24.0 in stage 14.0 (TID 108) (hal9000, executor driver, partition 24, PROCESS_LOCAL, 7895 bytes) \n",
      "25/06/27 09:19:24 INFO Executor: Running task 24.0 in stage 14.0 (TID 108)\n",
      "25/06/27 09:19:24 INFO TaskSetManager: Finished task 16.0 in stage 14.0 (TID 100) in 19837 ms on hal9000 (executor driver) (17/33)\n",
      "25/06/27 09:19:25 INFO FileScanRDD: Reading File path: s3a://datalake/climate.csv, range: 3221225472-3355443200, partition values: [empty row]\n",
      "25/06/27 09:19:26 INFO Executor: Finished task 18.0 in stage 14.0 (TID 102). 2803 bytes result sent to driver\n",
      "25/06/27 09:19:26 INFO TaskSetManager: Starting task 25.0 in stage 14.0 (TID 109) (hal9000, executor driver, partition 25, PROCESS_LOCAL, 7895 bytes) \n",
      "25/06/27 09:19:26 INFO TaskSetManager: Finished task 18.0 in stage 14.0 (TID 102) in 19169 ms on hal9000 (executor driver) (18/33)\n",
      "25/06/27 09:19:26 INFO Executor: Running task 25.0 in stage 14.0 (TID 109)\n",
      "25/06/27 09:19:26 INFO FileScanRDD: Reading File path: s3a://datalake/climate.csv, range: 3355443200-3489660928, partition values: [empty row]\n",
      "25/06/27 09:19:28 INFO Executor: Finished task 20.0 in stage 14.0 (TID 104). 2760 bytes result sent to driver\n",
      "25/06/27 09:19:28 INFO TaskSetManager: Starting task 26.0 in stage 14.0 (TID 110) (hal9000, executor driver, partition 26, PROCESS_LOCAL, 7895 bytes) \n",
      "25/06/27 09:19:28 INFO TaskSetManager: Finished task 20.0 in stage 14.0 (TID 104) in 18968 ms on hal9000 (executor driver) (19/33)\n",
      "25/06/27 09:19:28 INFO Executor: Running task 26.0 in stage 14.0 (TID 110) / 33]\n",
      "25/06/27 09:19:28 INFO FileScanRDD: Reading File path: s3a://datalake/climate.csv, range: 3489660928-3623878656, partition values: [empty row]\n",
      "25/06/27 09:19:28 INFO Executor: Finished task 17.0 in stage 14.0 (TID 101). 2803 bytes result sent to driver\n",
      "25/06/27 09:19:28 INFO TaskSetManager: Starting task 27.0 in stage 14.0 (TID 111) (hal9000, executor driver, partition 27, PROCESS_LOCAL, 7895 bytes) \n",
      "25/06/27 09:19:28 INFO Executor: Running task 27.0 in stage 14.0 (TID 111)\n",
      "25/06/27 09:19:28 INFO TaskSetManager: Finished task 17.0 in stage 14.0 (TID 101) in 21323 ms on hal9000 (executor driver) (20/33)\n",
      "25/06/27 09:19:28 INFO FileScanRDD: Reading File path: s3a://datalake/climate.csv, range: 3623878656-3758096384, partition values: [empty row]\n",
      "25/06/27 09:19:30 INFO Executor: Finished task 21.0 in stage 14.0 (TID 105). 2760 bytes result sent to driver\n",
      "25/06/27 09:19:30 INFO TaskSetManager: Starting task 28.0 in stage 14.0 (TID 112) (hal9000, executor driver, partition 28, PROCESS_LOCAL, 7895 bytes) \n",
      "25/06/27 09:19:30 INFO TaskSetManager: Finished task 21.0 in stage 14.0 (TID 105) in 20834 ms on hal9000 (executor driver) (21/33)\n",
      "25/06/27 09:19:30 INFO Executor: Running task 28.0 in stage 14.0 (TID 112)\n",
      "25/06/27 09:19:30 INFO FileScanRDD: Reading File path: s3a://datalake/climate.csv, range: 3758096384-3892314112, partition values: [empty row]\n",
      "25/06/27 09:19:31 INFO Executor: Finished task 23.0 in stage 14.0 (TID 107). 2760 bytes result sent to driver\n",
      "25/06/27 09:19:31 INFO TaskSetManager: Starting task 29.0 in stage 14.0 (TID 113) (hal9000, executor driver, partition 29, PROCESS_LOCAL, 7895 bytes) \n",
      "25/06/27 09:19:31 INFO TaskSetManager: Finished task 23.0 in stage 14.0 (TID 107) in 18169 ms on hal9000 (executor driver) (22/33)\n",
      "25/06/27 09:19:31 INFO Executor: Running task 29.0 in stage 14.0 (TID 113)\n",
      "25/06/27 09:19:31 INFO FileScanRDD: Reading File path: s3a://datalake/climate.csv, range: 3892314112-4026531840, partition values: [empty row]\n",
      "25/06/27 09:19:32 INFO Executor: Finished task 22.0 in stage 14.0 (TID 106). 2760 bytes result sent to driver\n",
      "25/06/27 09:19:32 INFO TaskSetManager: Starting task 30.0 in stage 14.0 (TID 114) (hal9000, executor driver, partition 30, PROCESS_LOCAL, 7895 bytes) \n",
      "25/06/27 09:19:32 INFO TaskSetManager: Finished task 22.0 in stage 14.0 (TID 106) in 23194 ms on hal9000 (executor driver) (23/33)\n",
      "25/06/27 09:19:32 INFO Executor: Running task 30.0 in stage 14.0 (TID 114)\n",
      "25/06/27 09:19:32 INFO FileScanRDD: Reading File path: s3a://datalake/climate.csv, range: 4026531840-4160749568, partition values: [empty row]\n",
      "25/06/27 09:19:33 INFO Executor: Finished task 19.0 in stage 14.0 (TID 103). 2760 bytes result sent to driver\n",
      "25/06/27 09:19:33 INFO TaskSetManager: Starting task 31.0 in stage 14.0 (TID 115) (hal9000, executor driver, partition 31, PROCESS_LOCAL, 7895 bytes) \n",
      "25/06/27 09:19:33 INFO TaskSetManager: Finished task 19.0 in stage 14.0 (TID 103) in 25349 ms on hal9000 (executor driver) (24/33)\n",
      "25/06/27 09:19:33 INFO Executor: Running task 31.0 in stage 14.0 (TID 115)\n",
      "25/06/27 09:19:33 INFO FileScanRDD: Reading File path: s3a://datalake/climate.csv, range: 4160749568-4294967296, partition values: [empty row]\n",
      "25/06/27 09:19:39 INFO Executor: Finished task 25.0 in stage 14.0 (TID 109). 2760 bytes result sent to driver\n",
      "25/06/27 09:19:39 INFO TaskSetManager: Starting task 32.0 in stage 14.0 (TID 116) (hal9000, executor driver, partition 32, PROCESS_LOCAL, 7895 bytes) \n",
      "25/06/27 09:19:39 INFO TaskSetManager: Finished task 25.0 in stage 14.0 (TID 109) in 12561 ms on hal9000 (executor driver) (25/33)\n",
      "25/06/27 09:19:39 INFO Executor: Running task 32.0 in stage 14.0 (TID 116)\n",
      "25/06/27 09:19:39 INFO FileScanRDD: Reading File path: s3a://datalake/climate.csv, range: 4294967296-4356534577, partition values: [empty row]\n",
      "25/06/27 09:19:41 INFO Executor: Finished task 24.0 in stage 14.0 (TID 108). 2803 bytes result sent to driver\n",
      "25/06/27 09:19:41 INFO TaskSetManager: Finished task 24.0 in stage 14.0 (TID 108) in 16866 ms on hal9000 (executor driver) (26/33)\n",
      "25/06/27 09:19:44 INFO Executor: Finished task 29.0 in stage 14.0 (TID 113). 2760 bytes result sent to driver\n",
      "25/06/27 09:19:44 INFO TaskSetManager: Finished task 29.0 in stage 14.0 (TID 113) in 13326 ms on hal9000 (executor driver) (27/33)\n",
      "25/06/27 09:19:45 INFO Executor: Finished task 26.0 in stage 14.0 (TID 110). 2760 bytes result sent to driver\n",
      "25/06/27 09:19:45 INFO TaskSetManager: Finished task 26.0 in stage 14.0 (TID 110) in 17206 ms on hal9000 (executor driver) (28/33)\n",
      "25/06/27 09:19:45 INFO Executor: Finished task 27.0 in stage 14.0 (TID 111). 2760 bytes result sent to driver\n",
      "25/06/27 09:19:45 INFO TaskSetManager: Finished task 27.0 in stage 14.0 (TID 111) in 17081 ms on hal9000 (executor driver) (29/33)\n",
      "25/06/27 09:19:45 INFO Executor: Finished task 32.0 in stage 14.0 (TID 116). 2803 bytes result sent to driver\n",
      "25/06/27 09:19:45 INFO TaskSetManager: Finished task 32.0 in stage 14.0 (TID 116) in 6373 ms on hal9000 (executor driver) (30/33)\n",
      "25/06/27 09:19:46 INFO Executor: Finished task 28.0 in stage 14.0 (TID 112). 2803 bytes result sent to driver\n",
      "25/06/27 09:19:46 INFO TaskSetManager: Finished task 28.0 in stage 14.0 (TID 112) in 16124 ms on hal9000 (executor driver) (31/33)\n",
      "25/06/27 09:19:47 INFO Executor: Finished task 30.0 in stage 14.0 (TID 114). 2803 bytes result sent to driver\n",
      "25/06/27 09:19:47 INFO TaskSetManager: Finished task 30.0 in stage 14.0 (TID 114) in 14448 ms on hal9000 (executor driver) (32/33)\n",
      "25/06/27 09:19:47 INFO Executor: Finished task 31.0 in stage 14.0 (TID 115). 2803 bytes result sent to driver\n",
      "25/06/27 09:19:47 INFO TaskSetManager: Finished task 31.0 in stage 14.0 (TID 115) in 13465 ms on hal9000 (executor driver) (33/33)\n",
      "25/06/27 09:19:47 INFO DAGScheduler: ShuffleMapStage 14 (showString at NativeMethodAccessorImpl.java:0) finished in 75.721 s\n",
      "25/06/27 09:19:47 INFO DAGScheduler: looking for newly runnable stages\n",
      "25/06/27 09:19:47 INFO DAGScheduler: running: Set()\n",
      "25/06/27 09:19:47 INFO DAGScheduler: waiting: Set()\n",
      "25/06/27 09:19:47 INFO DAGScheduler: failed: Set()\n",
      "25/06/27 09:19:47 INFO TaskSchedulerImpl: Removed TaskSet 14.0, whose tasks have all completed, from pool \n",
      "25/06/27 09:19:47 WARN WindowExec: No Partition Defined for Window operation! Moving all data to a single partition, this can cause serious performance degradation.\n",
      "25/06/27 09:19:47 WARN WindowExec: No Partition Defined for Window operation! Moving all data to a single partition, this can cause serious performance degradation.\n",
      "25/06/27 09:19:47 INFO ShufflePartitionsUtil: For shuffle(4), advisory target size: 67108864, actual target size 1048576, minimum partition size: 1048576\n",
      "25/06/27 09:19:47 WARN WindowExec: No Partition Defined for Window operation! Moving all data to a single partition, this can cause serious performance degradation.\n",
      "25/06/27 09:19:47 INFO CodeGenerator: Code generated in 88.168551 ms\n",
      "25/06/27 09:19:47 INFO CodeGenerator: Code generated in 33.0846 ms\n",
      "25/06/27 09:19:47 INFO HashAggregateExec: spark.sql.codegen.aggregate.map.twolevel.enabled is set to true, but current version of codegened fast hashmap does not support this aggregate.\n",
      "25/06/27 09:19:47 INFO CodeGenerator: Code generated in 35.973272 ms\n",
      "25/06/27 09:19:47 INFO SparkContext: Starting job: showString at NativeMethodAccessorImpl.java:0\n",
      "25/06/27 09:19:47 INFO DAGScheduler: Registering RDD 46 (showString at NativeMethodAccessorImpl.java:0) as input to shuffle 5\n",
      "25/06/27 09:19:47 INFO DAGScheduler: Got job 10 (showString at NativeMethodAccessorImpl.java:0) with 1 output partitions\n",
      "25/06/27 09:19:47 INFO DAGScheduler: Final stage: ResultStage 17 (showString at NativeMethodAccessorImpl.java:0)\n",
      "25/06/27 09:19:47 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 16)\n",
      "25/06/27 09:19:47 INFO DAGScheduler: Missing parents: List(ShuffleMapStage 16)\n",
      "25/06/27 09:19:47 INFO DAGScheduler: Submitting ShuffleMapStage 16 (MapPartitionsRDD[46] at showString at NativeMethodAccessorImpl.java:0), which has no missing parents\n",
      "25/06/27 09:19:47 INFO MemoryStore: Block broadcast_18 stored as values in memory (estimated size 49.8 KiB, free 434.1 MiB)\n",
      "25/06/27 09:19:47 INFO MemoryStore: Block broadcast_18_piece0 stored as bytes in memory (estimated size 22.2 KiB, free 434.0 MiB)\n",
      "25/06/27 09:19:47 INFO BlockManagerInfo: Added broadcast_18_piece0 in memory on hal9000:34557 (size: 22.2 KiB, free: 434.3 MiB)\n",
      "25/06/27 09:19:47 INFO SparkContext: Created broadcast 18 from broadcast at DAGScheduler.scala:1535\n",
      "25/06/27 09:19:47 INFO DAGScheduler: Submitting 4 missing tasks from ShuffleMapStage 16 (MapPartitionsRDD[46] at showString at NativeMethodAccessorImpl.java:0) (first 15 tasks are for partitions Vector(0, 1, 2, 3))\n",
      "25/06/27 09:19:47 INFO TaskSchedulerImpl: Adding task set 16.0 with 4 tasks resource profile 0\n",
      "25/06/27 09:19:47 INFO TaskSetManager: Starting task 0.0 in stage 16.0 (TID 117) (hal9000, executor driver, partition 0, NODE_LOCAL, 7352 bytes) \n",
      "25/06/27 09:19:47 INFO TaskSetManager: Starting task 1.0 in stage 16.0 (TID 118) (hal9000, executor driver, partition 1, NODE_LOCAL, 7352 bytes) \n",
      "25/06/27 09:19:47 INFO TaskSetManager: Starting task 2.0 in stage 16.0 (TID 119) (hal9000, executor driver, partition 2, NODE_LOCAL, 7352 bytes) \n",
      "25/06/27 09:19:47 INFO TaskSetManager: Starting task 3.0 in stage 16.0 (TID 120) (hal9000, executor driver, partition 3, NODE_LOCAL, 7352 bytes) \n",
      "25/06/27 09:19:47 INFO Executor: Running task 2.0 in stage 16.0 (TID 119)\n",
      "25/06/27 09:19:47 INFO Executor: Running task 0.0 in stage 16.0 (TID 117)\n",
      "25/06/27 09:19:47 INFO Executor: Running task 1.0 in stage 16.0 (TID 118)\n",
      "25/06/27 09:19:47 INFO Executor: Running task 3.0 in stage 16.0 (TID 120)\n",
      "25/06/27 09:19:47 INFO ShuffleBlockFetcherIterator: Getting 33 (1040.9 KiB) non-empty blocks including 33 (1040.9 KiB) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks\n",
      "25/06/27 09:19:47 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 2 ms\n",
      "25/06/27 09:19:47 INFO ShuffleBlockFetcherIterator: Getting 33 (1033.1 KiB) non-empty blocks including 33 (1033.1 KiB) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks\n",
      "25/06/27 09:19:47 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 1 ms\n",
      "25/06/27 09:19:47 INFO ShuffleBlockFetcherIterator: Getting 33 (1040.6 KiB) non-empty blocks including 33 (1040.6 KiB) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks\n",
      "25/06/27 09:19:47 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 18 ms\n",
      "25/06/27 09:19:47 INFO ShuffleBlockFetcherIterator: Getting 33 (1493.6 KiB) non-empty blocks including 33 (1493.6 KiB) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks\n",
      "25/06/27 09:19:47 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 18 ms\n",
      "25/06/27 09:19:47 INFO Executor: Finished task 2.0 in stage 16.0 (TID 119). 6193 bytes result sent to driver\n",
      "25/06/27 09:19:47 INFO TaskSetManager: Finished task 2.0 in stage 16.0 (TID 119) in 352 ms on hal9000 (executor driver) (1/4)\n",
      "25/06/27 09:19:48 INFO Executor: Finished task 0.0 in stage 16.0 (TID 117). 6193 bytes result sent to driver\n",
      "25/06/27 09:19:48 INFO TaskSetManager: Finished task 0.0 in stage 16.0 (TID 117) in 370 ms on hal9000 (executor driver) (2/4)\n",
      "25/06/27 09:19:48 INFO Executor: Finished task 1.0 in stage 16.0 (TID 118). 6193 bytes result sent to driver\n",
      "25/06/27 09:19:48 INFO TaskSetManager: Finished task 1.0 in stage 16.0 (TID 118) in 389 ms on hal9000 (executor driver) (3/4)\n",
      "25/06/27 09:19:48 INFO Executor: Finished task 3.0 in stage 16.0 (TID 120). 6193 bytes result sent to driver\n",
      "25/06/27 09:19:48 INFO TaskSetManager: Finished task 3.0 in stage 16.0 (TID 120) in 437 ms on hal9000 (executor driver) (4/4)\n",
      "25/06/27 09:19:48 INFO TaskSchedulerImpl: Removed TaskSet 16.0, whose tasks have all completed, from pool \n",
      "25/06/27 09:19:48 INFO DAGScheduler: ShuffleMapStage 16 (showString at NativeMethodAccessorImpl.java:0) finished in 0.469 s\n",
      "25/06/27 09:19:48 INFO DAGScheduler: looking for newly runnable stages\n",
      "25/06/27 09:19:48 INFO DAGScheduler: running: Set()\n",
      "25/06/27 09:19:48 INFO DAGScheduler: waiting: Set(ResultStage 17)\n",
      "25/06/27 09:19:48 INFO DAGScheduler: failed: Set()\n",
      "25/06/27 09:19:48 INFO DAGScheduler: Submitting ResultStage 17 (MapPartitionsRDD[51] at showString at NativeMethodAccessorImpl.java:0), which has no missing parents\n",
      "25/06/27 09:19:48 INFO MemoryStore: Block broadcast_19 stored as values in memory (estimated size 51.5 KiB, free 434.0 MiB)\n",
      "25/06/27 09:19:48 INFO MemoryStore: Block broadcast_19_piece0 stored as bytes in memory (estimated size 22.7 KiB, free 434.0 MiB)\n",
      "25/06/27 09:19:48 INFO BlockManagerInfo: Added broadcast_19_piece0 in memory on hal9000:34557 (size: 22.7 KiB, free: 434.3 MiB)\n",
      "25/06/27 09:19:48 INFO SparkContext: Created broadcast 19 from broadcast at DAGScheduler.scala:1535\n",
      "25/06/27 09:19:48 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 17 (MapPartitionsRDD[51] at showString at NativeMethodAccessorImpl.java:0) (first 15 tasks are for partitions Vector(0))\n",
      "25/06/27 09:19:48 INFO TaskSchedulerImpl: Adding task set 17.0 with 1 tasks resource profile 0\n",
      "25/06/27 09:19:48 INFO TaskSetManager: Starting task 0.0 in stage 17.0 (TID 121) (hal9000, executor driver, partition 0, NODE_LOCAL, 7363 bytes) \n",
      "25/06/27 09:19:48 INFO Executor: Running task 0.0 in stage 17.0 (TID 121)\n",
      "25/06/27 09:19:48 INFO ShuffleBlockFetcherIterator: Getting 4 (1276.0 B) non-empty blocks including 4 (1276.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks\n",
      "25/06/27 09:19:48 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+-------------+--------+--------+-------------+--------+-----------+\n",
      "|data_pk|data_completa|data_dia|data_mes|data_semestre|data_ano|data_decada|\n",
      "+-------+-------------+--------+--------+-------------+--------+-----------+\n",
      "|      1|   2001-01-01|       1|       1|            0|    2001|       2000|\n",
      "|      2|   2001-01-02|       2|       1|            0|    2001|       2000|\n",
      "|      3|   2001-01-03|       3|       1|            0|    2001|       2000|\n",
      "|      4|   2001-01-04|       4|       1|            0|    2001|       2000|\n",
      "|      5|   2001-01-05|       5|       1|            0|    2001|       2000|\n",
      "|      6|   2001-01-06|       6|       1|            0|    2001|       2000|\n",
      "|      7|   2001-01-07|       7|       1|            0|    2001|       2000|\n",
      "|      8|   2001-01-08|       8|       1|            0|    2001|       2000|\n",
      "|      9|   2001-01-09|       9|       1|            0|    2001|       2000|\n",
      "|     10|   2001-01-10|      10|       1|            0|    2001|       2000|\n",
      "|     11|   2001-01-11|      11|       1|            0|    2001|       2000|\n",
      "|     12|   2001-01-12|      12|       1|            0|    2001|       2000|\n",
      "|     13|   2001-01-13|      13|       1|            0|    2001|       2000|\n",
      "|     14|   2001-01-14|      14|       1|            0|    2001|       2000|\n",
      "|     15|   2001-01-15|      15|       1|            0|    2001|       2000|\n",
      "|     16|   2001-01-16|      16|       1|            0|    2001|       2000|\n",
      "|     17|   2001-01-17|      17|       1|            0|    2001|       2000|\n",
      "|     18|   2001-01-18|      18|       1|            0|    2001|       2000|\n",
      "|     19|   2001-01-19|      19|       1|            0|    2001|       2000|\n",
      "|     20|   2001-01-20|      20|       1|            0|    2001|       2000|\n",
      "+-------+-------------+--------+--------+-------------+--------+-----------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "25/06/27 09:19:48 INFO CodeGenerator: Code generated in 20.404103 ms\n",
      "25/06/27 09:19:48 INFO CodeGenerator: Code generated in 15.753689 ms\n",
      "25/06/27 09:19:48 INFO CodeGenerator: Code generated in 17.31529 ms\n",
      "25/06/27 09:19:48 INFO CodeGenerator: Code generated in 15.335579 ms\n",
      "25/06/27 09:19:48 INFO Executor: Finished task 0.0 in stage 17.0 (TID 121). 6836 bytes result sent to driver\n",
      "25/06/27 09:19:48 INFO TaskSetManager: Finished task 0.0 in stage 17.0 (TID 121) in 224 ms on hal9000 (executor driver) (1/1)\n",
      "25/06/27 09:19:48 INFO TaskSchedulerImpl: Removed TaskSet 17.0, whose tasks have all completed, from pool \n",
      "25/06/27 09:19:48 INFO DAGScheduler: ResultStage 17 (showString at NativeMethodAccessorImpl.java:0) finished in 0.257 s\n",
      "25/06/27 09:19:48 INFO DAGScheduler: Job 10 is finished. Cancelling potential speculative or zombie tasks for this job\n",
      "25/06/27 09:19:48 INFO TaskSchedulerImpl: Killing all running tasks in stage 17: Stage finished\n",
      "25/06/27 09:19:48 INFO DAGScheduler: Job 10 finished: showString at NativeMethodAccessorImpl.java:0, took 0.763798 s\n",
      "25/06/27 09:19:48 INFO CodeGenerator: Code generated in 34.63003 ms             \n"
     ]
    }
   ],
   "source": [
    "# Transformção da data, os campos 'data_completa', 'mes', 'semestre' são derivados do DOY por funções do Spark\n",
    "\n",
    "df_data = df_clima.withColumn(\n",
    "    \"data_completa\",\n",
    "    F.expr(\"date_add(to_date(concat(YEAR, '-01-01')), DOY - 1)\")\n",
    ").select(\n",
    "    \"data_completa\",\n",
    "    F.dayofmonth(\"data_completa\").alias(\"data_dia\"),\n",
    "    F.month(\"data_completa\").alias(\"data_mes\"),\n",
    "    ((F.month(\"data_completa\")-1)/6).cast(\"int\").alias(\"data_semestre\"),\n",
    "    F.year(\"data_completa\").alias(\"data_ano\")\n",
    ").distinct()\n",
    "\n",
    "windowSpec = Window.orderBy(\"data_completa\")\n",
    "\n",
    "df_data = df_data.withColumn(\n",
    "    \"data_pk\",\n",
    "    F.row_number().over(windowSpec)\n",
    ")\n",
    "\n",
    "df_data = df_data.withColumn(\n",
    "    \"data_decada\",\n",
    "    (F.floor(F.col(\"data_ano\") / 10) * 10).cast(\"int\")\n",
    ")\n",
    "\n",
    "df_data = df_data.select(\"data_pk\", \"data_completa\", \"data_dia\", \"data_mes\", \"data_semestre\", \"data_ano\", \"data_decada\")\n",
    "\n",
    "print(\"Numero de Tuplas: \", df_data.count())\n",
    "df_data.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "cc003b84",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/rodrigo/.local/lib/python3.11/site-packages/pyspark/sql/column.py:458: FutureWarning: A column as 'key' in getItem is deprecated as of Spark 3.0, and will not be supported in the future release. Use `column[key]` or `column.key` syntax instead.\n",
      "  warnings.warn(\n",
      "25/06/27 09:19:49 INFO FileSourceStrategy: Pushed Filters: \n",
      "25/06/27 09:19:49 INFO FileSourceStrategy: Post-Scan Filters: \n",
      "25/06/27 09:19:49 WARN WindowExec: No Partition Defined for Window operation! Moving all data to a single partition, this can cause serious performance degradation.\n",
      "25/06/27 09:19:49 WARN WindowExec: No Partition Defined for Window operation! Moving all data to a single partition, this can cause serious performance degradation.\n",
      "25/06/27 09:19:49 WARN WindowExec: No Partition Defined for Window operation! Moving all data to a single partition, this can cause serious performance degradation.\n",
      "25/06/27 09:19:49 INFO HashAggregateExec: spark.sql.codegen.aggregate.map.twolevel.enabled is set to true, but current version of codegened fast hashmap does not support this aggregate.\n",
      "25/06/27 09:19:49 INFO CodeGenerator: Code generated in 54.180044 ms\n",
      "25/06/27 09:19:49 INFO MemoryStore: Block broadcast_20 stored as values in memory (estimated size 203.2 KiB, free 433.8 MiB)\n",
      "25/06/27 09:19:49 INFO MemoryStore: Block broadcast_20_piece0 stored as bytes in memory (estimated size 35.4 KiB, free 433.7 MiB)\n",
      "25/06/27 09:19:49 INFO BlockManagerInfo: Added broadcast_20_piece0 in memory on hal9000:34557 (size: 35.4 KiB, free: 434.3 MiB)\n",
      "25/06/27 09:19:49 INFO SparkContext: Created broadcast 20 from showString at NativeMethodAccessorImpl.java:0\n",
      "25/06/27 09:19:49 INFO FileSourceScanExec: Planning scan with bin packing, max size: 134217728 bytes, open cost is considered as scanning 4194304 bytes.\n",
      "25/06/27 09:19:49 INFO DAGScheduler: Registering RDD 55 (showString at NativeMethodAccessorImpl.java:0) as input to shuffle 6\n",
      "25/06/27 09:19:49 INFO DAGScheduler: Got map stage job 11 (showString at NativeMethodAccessorImpl.java:0) with 33 output partitions\n",
      "25/06/27 09:19:49 INFO DAGScheduler: Final stage: ShuffleMapStage 18 (showString at NativeMethodAccessorImpl.java:0)\n",
      "25/06/27 09:19:49 INFO DAGScheduler: Parents of final stage: List()\n",
      "25/06/27 09:19:49 INFO DAGScheduler: Missing parents: List()\n",
      "25/06/27 09:19:49 INFO DAGScheduler: Submitting ShuffleMapStage 18 (MapPartitionsRDD[55] at showString at NativeMethodAccessorImpl.java:0), which has no missing parents\n",
      "25/06/27 09:19:49 INFO MemoryStore: Block broadcast_21 stored as values in memory (estimated size 34.4 KiB, free 433.7 MiB)\n",
      "25/06/27 09:19:49 INFO MemoryStore: Block broadcast_21_piece0 stored as bytes in memory (estimated size 16.2 KiB, free 433.7 MiB)\n",
      "25/06/27 09:19:49 INFO BlockManagerInfo: Added broadcast_21_piece0 in memory on hal9000:34557 (size: 16.2 KiB, free: 434.3 MiB)\n",
      "25/06/27 09:19:49 INFO SparkContext: Created broadcast 21 from broadcast at DAGScheduler.scala:1535\n",
      "25/06/27 09:19:49 INFO DAGScheduler: Submitting 33 missing tasks from ShuffleMapStage 18 (MapPartitionsRDD[55] at showString at NativeMethodAccessorImpl.java:0) (first 15 tasks are for partitions Vector(0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14))\n",
      "25/06/27 09:19:49 INFO TaskSchedulerImpl: Adding task set 18.0 with 33 tasks resource profile 0\n",
      "25/06/27 09:19:49 INFO TaskSetManager: Starting task 0.0 in stage 18.0 (TID 122) (hal9000, executor driver, partition 0, PROCESS_LOCAL, 7895 bytes) \n",
      "25/06/27 09:19:49 INFO TaskSetManager: Starting task 1.0 in stage 18.0 (TID 123) (hal9000, executor driver, partition 1, PROCESS_LOCAL, 7895 bytes) \n",
      "25/06/27 09:19:49 INFO TaskSetManager: Starting task 2.0 in stage 18.0 (TID 124) (hal9000, executor driver, partition 2, PROCESS_LOCAL, 7895 bytes) \n",
      "25/06/27 09:19:49 INFO TaskSetManager: Starting task 3.0 in stage 18.0 (TID 125) (hal9000, executor driver, partition 3, PROCESS_LOCAL, 7895 bytes) \n",
      "25/06/27 09:19:49 INFO TaskSetManager: Starting task 4.0 in stage 18.0 (TID 126) (hal9000, executor driver, partition 4, PROCESS_LOCAL, 7895 bytes) \n",
      "25/06/27 09:19:49 INFO TaskSetManager: Starting task 5.0 in stage 18.0 (TID 127) (hal9000, executor driver, partition 5, PROCESS_LOCAL, 7895 bytes) \n",
      "25/06/27 09:19:49 INFO TaskSetManager: Starting task 6.0 in stage 18.0 (TID 128) (hal9000, executor driver, partition 6, PROCESS_LOCAL, 7895 bytes) \n",
      "25/06/27 09:19:49 INFO TaskSetManager: Starting task 7.0 in stage 18.0 (TID 129) (hal9000, executor driver, partition 7, PROCESS_LOCAL, 7895 bytes) \n",
      "25/06/27 09:19:49 INFO Executor: Running task 1.0 in stage 18.0 (TID 123)\n",
      "25/06/27 09:19:49 INFO Executor: Running task 0.0 in stage 18.0 (TID 122)\n",
      "25/06/27 09:19:49 INFO Executor: Running task 4.0 in stage 18.0 (TID 126)\n",
      "25/06/27 09:19:49 INFO Executor: Running task 6.0 in stage 18.0 (TID 128)\n",
      "25/06/27 09:19:49 INFO Executor: Running task 2.0 in stage 18.0 (TID 124)\n",
      "25/06/27 09:19:49 INFO Executor: Running task 3.0 in stage 18.0 (TID 125)\n",
      "25/06/27 09:19:49 INFO Executor: Running task 5.0 in stage 18.0 (TID 127)\n",
      "25/06/27 09:19:49 INFO Executor: Running task 7.0 in stage 18.0 (TID 129)\n",
      "25/06/27 09:19:49 INFO CodeGenerator: Code generated in 41.321604 ms\n",
      "25/06/27 09:19:49 INFO CodeGenerator: Code generated in 29.594705 ms\n",
      "25/06/27 09:19:49 INFO FileScanRDD: Reading File path: s3a://datalake/climate.csv, range: 134217728-268435456, partition values: [empty row]\n",
      "25/06/27 09:19:49 INFO FileScanRDD: Reading File path: s3a://datalake/climate.csv, range: 402653184-536870912, partition values: [empty row]\n",
      "25/06/27 09:19:49 INFO FileScanRDD: Reading File path: s3a://datalake/climate.csv, range: 671088640-805306368, partition values: [empty row]\n",
      "25/06/27 09:19:49 INFO FileScanRDD: Reading File path: s3a://datalake/climate.csv, range: 268435456-402653184, partition values: [empty row]\n",
      "25/06/27 09:19:49 INFO FileScanRDD: Reading File path: s3a://datalake/climate.csv, range: 939524096-1073741824, partition values: [empty row]\n",
      "25/06/27 09:19:49 INFO FileScanRDD: Reading File path: s3a://datalake/climate.csv, range: 0-134217728, partition values: [empty row]\n",
      "25/06/27 09:19:49 INFO FileScanRDD: Reading File path: s3a://datalake/climate.csv, range: 805306368-939524096, partition values: [empty row]\n",
      "25/06/27 09:19:49 INFO FileScanRDD: Reading File path: s3a://datalake/climate.csv, range: 536870912-671088640, partition values: [empty row]\n",
      "25/06/27 09:19:49 INFO CodeGenerator: Code generated in 21.323027 ms\n",
      "25/06/27 09:19:49 INFO BlockManagerInfo: Removed broadcast_18_piece0 on hal9000:34557 in memory (size: 22.2 KiB, free: 434.3 MiB)\n",
      "25/06/27 09:19:49 INFO BlockManagerInfo: Removed broadcast_19_piece0 on hal9000:34557 in memory (size: 22.7 KiB, free: 434.3 MiB)\n",
      "25/06/27 09:20:03 INFO Executor: Finished task 6.0 in stage 18.0 (TID 128). 2803 bytes result sent to driver\n",
      "25/06/27 09:20:03 INFO TaskSetManager: Starting task 8.0 in stage 18.0 (TID 130) (hal9000, executor driver, partition 8, PROCESS_LOCAL, 7895 bytes) \n",
      "25/06/27 09:20:03 INFO TaskSetManager: Finished task 6.0 in stage 18.0 (TID 128) in 14549 ms on hal9000 (executor driver) (1/33)\n",
      "25/06/27 09:20:03 INFO Executor: Running task 8.0 in stage 18.0 (TID 130)\n",
      "25/06/27 09:20:04 INFO FileScanRDD: Reading File path: s3a://datalake/climate.csv, range: 1073741824-1207959552, partition values: [empty row]\n",
      "25/06/27 09:20:07 INFO Executor: Finished task 5.0 in stage 18.0 (TID 127). 2760 bytes result sent to driver\n",
      "25/06/27 09:20:07 INFO TaskSetManager: Starting task 9.0 in stage 18.0 (TID 131) (hal9000, executor driver, partition 9, PROCESS_LOCAL, 7895 bytes) \n",
      "25/06/27 09:20:07 INFO Executor: Running task 9.0 in stage 18.0 (TID 131)\n",
      "25/06/27 09:20:07 INFO TaskSetManager: Finished task 5.0 in stage 18.0 (TID 127) in 18319 ms on hal9000 (executor driver) (2/33)\n",
      "25/06/27 09:20:07 INFO FileScanRDD: Reading File path: s3a://datalake/climate.csv, range: 1207959552-1342177280, partition values: [empty row]\n",
      "25/06/27 09:20:09 INFO Executor: Finished task 0.0 in stage 18.0 (TID 122). 2760 bytes result sent to driver\n",
      "25/06/27 09:20:09 INFO TaskSetManager: Starting task 10.0 in stage 18.0 (TID 132) (hal9000, executor driver, partition 10, PROCESS_LOCAL, 7895 bytes) \n",
      "25/06/27 09:20:09 INFO TaskSetManager: Finished task 0.0 in stage 18.0 (TID 122) in 19841 ms on hal9000 (executor driver) (3/33)\n",
      "25/06/27 09:20:09 INFO Executor: Running task 10.0 in stage 18.0 (TID 132)\n",
      "25/06/27 09:20:09 INFO FileScanRDD: Reading File path: s3a://datalake/climate.csv, range: 1342177280-1476395008, partition values: [empty row]\n",
      "25/06/27 09:20:09 INFO Executor: Finished task 2.0 in stage 18.0 (TID 124). 2803 bytes result sent to driver\n",
      "25/06/27 09:20:09 INFO TaskSetManager: Starting task 11.0 in stage 18.0 (TID 133) (hal9000, executor driver, partition 11, PROCESS_LOCAL, 7895 bytes) \n",
      "25/06/27 09:20:09 INFO TaskSetManager: Finished task 2.0 in stage 18.0 (TID 124) in 20113 ms on hal9000 (executor driver) (4/33)\n",
      "25/06/27 09:20:09 INFO Executor: Running task 11.0 in stage 18.0 (TID 133)\n",
      "25/06/27 09:20:09 INFO FileScanRDD: Reading File path: s3a://datalake/climate.csv, range: 1476395008-1610612736, partition values: [empty row]\n",
      "25/06/27 09:20:10 INFO Executor: Finished task 7.0 in stage 18.0 (TID 129). 2760 bytes result sent to driver\n",
      "25/06/27 09:20:10 INFO TaskSetManager: Starting task 12.0 in stage 18.0 (TID 134) (hal9000, executor driver, partition 12, PROCESS_LOCAL, 7895 bytes) \n",
      "25/06/27 09:20:10 INFO Executor: Running task 12.0 in stage 18.0 (TID 134)\n",
      "25/06/27 09:20:10 INFO TaskSetManager: Finished task 7.0 in stage 18.0 (TID 129) in 20933 ms on hal9000 (executor driver) (5/33)\n",
      "25/06/27 09:20:10 INFO FileScanRDD: Reading File path: s3a://datalake/climate.csv, range: 1610612736-1744830464, partition values: [empty row]\n",
      "25/06/27 09:20:13 INFO Executor: Finished task 1.0 in stage 18.0 (TID 123). 2760 bytes result sent to driver\n",
      "25/06/27 09:20:13 INFO TaskSetManager: Starting task 13.0 in stage 18.0 (TID 135) (hal9000, executor driver, partition 13, PROCESS_LOCAL, 7895 bytes) \n",
      "25/06/27 09:20:13 INFO TaskSetManager: Finished task 1.0 in stage 18.0 (TID 123) in 24529 ms on hal9000 (executor driver) (6/33)\n",
      "25/06/27 09:20:13 INFO Executor: Running task 13.0 in stage 18.0 (TID 135)\n",
      "25/06/27 09:20:14 INFO FileScanRDD: Reading File path: s3a://datalake/climate.csv, range: 1744830464-1879048192, partition values: [empty row]\n",
      "25/06/27 09:20:14 INFO Executor: Finished task 4.0 in stage 18.0 (TID 126). 2760 bytes result sent to driver\n",
      "25/06/27 09:20:14 INFO TaskSetManager: Starting task 14.0 in stage 18.0 (TID 136) (hal9000, executor driver, partition 14, PROCESS_LOCAL, 7895 bytes) \n",
      "25/06/27 09:20:14 INFO TaskSetManager: Finished task 4.0 in stage 18.0 (TID 126) in 25354 ms on hal9000 (executor driver) (7/33)\n",
      "25/06/27 09:20:14 INFO Executor: Running task 14.0 in stage 18.0 (TID 136) / 33]\n",
      "25/06/27 09:20:14 INFO FileScanRDD: Reading File path: s3a://datalake/climate.csv, range: 1879048192-2013265920, partition values: [empty row]\n",
      "25/06/27 09:20:15 INFO Executor: Finished task 3.0 in stage 18.0 (TID 125). 2760 bytes result sent to driver\n",
      "25/06/27 09:20:15 INFO TaskSetManager: Starting task 15.0 in stage 18.0 (TID 137) (hal9000, executor driver, partition 15, PROCESS_LOCAL, 7895 bytes) \n",
      "25/06/27 09:20:15 INFO Executor: Running task 15.0 in stage 18.0 (TID 137)\n",
      "25/06/27 09:20:15 INFO TaskSetManager: Finished task 3.0 in stage 18.0 (TID 125) in 26248 ms on hal9000 (executor driver) (8/33)\n",
      "25/06/27 09:20:15 INFO FileScanRDD: Reading File path: s3a://datalake/climate.csv, range: 2013265920-2147483648, partition values: [empty row]\n",
      "25/06/27 09:20:28 INFO Executor: Finished task 8.0 in stage 18.0 (TID 130). 2760 bytes result sent to driver\n",
      "25/06/27 09:20:28 INFO TaskSetManager: Starting task 16.0 in stage 18.0 (TID 138) (hal9000, executor driver, partition 16, PROCESS_LOCAL, 7895 bytes) \n",
      "25/06/27 09:20:28 INFO Executor: Running task 16.0 in stage 18.0 (TID 138)\n",
      "25/06/27 09:20:28 INFO TaskSetManager: Finished task 8.0 in stage 18.0 (TID 130) in 24901 ms on hal9000 (executor driver) (9/33)\n",
      "25/06/27 09:20:28 INFO FileScanRDD: Reading File path: s3a://datalake/climate.csv, range: 2147483648-2281701376, partition values: [empty row]\n",
      "25/06/27 09:20:31 INFO Executor: Finished task 9.0 in stage 18.0 (TID 131). 2760 bytes result sent to driver\n",
      "25/06/27 09:20:31 INFO TaskSetManager: Starting task 17.0 in stage 18.0 (TID 139) (hal9000, executor driver, partition 17, PROCESS_LOCAL, 7895 bytes) \n",
      "25/06/27 09:20:31 INFO TaskSetManager: Finished task 9.0 in stage 18.0 (TID 131) in 23745 ms on hal9000 (executor driver) (10/33)\n",
      "25/06/27 09:20:31 INFO Executor: Running task 17.0 in stage 18.0 (TID 139)\n",
      "25/06/27 09:20:31 INFO FileScanRDD: Reading File path: s3a://datalake/climate.csv, range: 2281701376-2415919104, partition values: [empty row]\n",
      "25/06/27 09:20:33 INFO Executor: Finished task 14.0 in stage 18.0 (TID 136). 2803 bytes result sent to driver\n",
      "25/06/27 09:20:33 INFO TaskSetManager: Starting task 18.0 in stage 18.0 (TID 140) (hal9000, executor driver, partition 18, PROCESS_LOCAL, 7895 bytes) \n",
      "25/06/27 09:20:33 INFO Executor: Running task 18.0 in stage 18.0 (TID 140)\n",
      "25/06/27 09:20:33 INFO TaskSetManager: Finished task 14.0 in stage 18.0 (TID 136) in 18781 ms on hal9000 (executor driver) (11/33)\n",
      "25/06/27 09:20:33 INFO FileScanRDD: Reading File path: s3a://datalake/climate.csv, range: 2415919104-2550136832, partition values: [empty row]\n",
      "25/06/27 09:20:34 INFO Executor: Finished task 10.0 in stage 18.0 (TID 132). 2760 bytes result sent to driver\n",
      "25/06/27 09:20:34 INFO TaskSetManager: Starting task 19.0 in stage 18.0 (TID 141) (hal9000, executor driver, partition 19, PROCESS_LOCAL, 7895 bytes) \n",
      "25/06/27 09:20:34 INFO Executor: Running task 19.0 in stage 18.0 (TID 141)\n",
      "25/06/27 09:20:34 INFO TaskSetManager: Finished task 10.0 in stage 18.0 (TID 132) in 25394 ms on hal9000 (executor driver) (12/33)\n",
      "25/06/27 09:20:34 INFO FileScanRDD: Reading File path: s3a://datalake/climate.csv, range: 2550136832-2684354560, partition values: [empty row]\n",
      "25/06/27 09:20:35 INFO Executor: Finished task 12.0 in stage 18.0 (TID 134). 2760 bytes result sent to driver\n",
      "25/06/27 09:20:35 INFO TaskSetManager: Starting task 20.0 in stage 18.0 (TID 142) (hal9000, executor driver, partition 20, PROCESS_LOCAL, 7895 bytes) \n",
      "25/06/27 09:20:35 INFO Executor: Running task 20.0 in stage 18.0 (TID 142)\n",
      "25/06/27 09:20:35 INFO TaskSetManager: Finished task 12.0 in stage 18.0 (TID 134) in 24999 ms on hal9000 (executor driver) (13/33)\n",
      "25/06/27 09:20:35 INFO Executor: Finished task 11.0 in stage 18.0 (TID 133). 2760 bytes result sent to driver\n",
      "25/06/27 09:20:35 INFO TaskSetManager: Starting task 21.0 in stage 18.0 (TID 143) (hal9000, executor driver, partition 21, PROCESS_LOCAL, 7895 bytes) \n",
      "25/06/27 09:20:35 INFO TaskSetManager: Finished task 11.0 in stage 18.0 (TID 133) in 25883 ms on hal9000 (executor driver) (14/33)\n",
      "25/06/27 09:20:35 INFO Executor: Running task 21.0 in stage 18.0 (TID 143)\n",
      "25/06/27 09:20:35 INFO FileScanRDD: Reading File path: s3a://datalake/climate.csv, range: 2684354560-2818572288, partition values: [empty row]\n",
      "25/06/27 09:20:35 INFO FileScanRDD: Reading File path: s3a://datalake/climate.csv, range: 2818572288-2952790016, partition values: [empty row]\n",
      "25/06/27 09:20:37 INFO Executor: Finished task 15.0 in stage 18.0 (TID 137). 2760 bytes result sent to driver\n",
      "25/06/27 09:20:37 INFO TaskSetManager: Starting task 22.0 in stage 18.0 (TID 144) (hal9000, executor driver, partition 22, PROCESS_LOCAL, 7895 bytes) \n",
      "25/06/27 09:20:37 INFO Executor: Running task 22.0 in stage 18.0 (TID 144)\n",
      "25/06/27 09:20:37 INFO TaskSetManager: Finished task 15.0 in stage 18.0 (TID 137) in 21397 ms on hal9000 (executor driver) (15/33)\n",
      "25/06/27 09:20:37 INFO FileScanRDD: Reading File path: s3a://datalake/climate.csv, range: 2952790016-3087007744, partition values: [empty row]\n",
      "25/06/27 09:20:37 INFO Executor: Finished task 13.0 in stage 18.0 (TID 135). 2760 bytes result sent to driver\n",
      "25/06/27 09:20:38 INFO TaskSetManager: Starting task 23.0 in stage 18.0 (TID 145) (hal9000, executor driver, partition 23, PROCESS_LOCAL, 7895 bytes) \n",
      "25/06/27 09:20:38 INFO TaskSetManager: Finished task 13.0 in stage 18.0 (TID 135) in 24045 ms on hal9000 (executor driver) (16/33)\n",
      "25/06/27 09:20:38 INFO Executor: Running task 23.0 in stage 18.0 (TID 145)\n",
      "25/06/27 09:20:38 INFO FileScanRDD: Reading File path: s3a://datalake/climate.csv, range: 3087007744-3221225472, partition values: [empty row]\n",
      "25/06/27 09:20:50 INFO Executor: Finished task 16.0 in stage 18.0 (TID 138). 2760 bytes result sent to driver\n",
      "25/06/27 09:20:50 INFO TaskSetManager: Starting task 24.0 in stage 18.0 (TID 146) (hal9000, executor driver, partition 24, PROCESS_LOCAL, 7895 bytes) \n",
      "25/06/27 09:20:50 INFO TaskSetManager: Finished task 16.0 in stage 18.0 (TID 138) in 21271 ms on hal9000 (executor driver) (17/33)\n",
      "25/06/27 09:20:50 INFO Executor: Running task 24.0 in stage 18.0 (TID 146)\n",
      "25/06/27 09:20:50 INFO FileScanRDD: Reading File path: s3a://datalake/climate.csv, range: 3221225472-3355443200, partition values: [empty row]\n",
      "25/06/27 09:20:53 INFO Executor: Finished task 17.0 in stage 18.0 (TID 139). 2760 bytes result sent to driver\n",
      "25/06/27 09:20:53 INFO TaskSetManager: Starting task 25.0 in stage 18.0 (TID 147) (hal9000, executor driver, partition 25, PROCESS_LOCAL, 7895 bytes) \n",
      "25/06/27 09:20:53 INFO Executor: Running task 25.0 in stage 18.0 (TID 147)\n",
      "25/06/27 09:20:53 INFO TaskSetManager: Finished task 17.0 in stage 18.0 (TID 139) in 21658 ms on hal9000 (executor driver) (18/33)\n",
      "25/06/27 09:20:53 INFO FileScanRDD: Reading File path: s3a://datalake/climate.csv, range: 3355443200-3489660928, partition values: [empty row]\n",
      "25/06/27 09:20:54 INFO Executor: Finished task 19.0 in stage 18.0 (TID 141). 2760 bytes result sent to driver\n",
      "25/06/27 09:20:54 INFO TaskSetManager: Starting task 26.0 in stage 18.0 (TID 148) (hal9000, executor driver, partition 26, PROCESS_LOCAL, 7895 bytes) \n",
      "25/06/27 09:20:54 INFO TaskSetManager: Finished task 19.0 in stage 18.0 (TID 141) in 19984 ms on hal9000 (executor driver) (19/33)\n",
      "25/06/27 09:20:54 INFO Executor: Running task 26.0 in stage 18.0 (TID 148)\n",
      "25/06/27 09:20:54 INFO FileScanRDD: Reading File path: s3a://datalake/climate.csv, range: 3489660928-3623878656, partition values: [empty row]\n",
      "25/06/27 09:20:54 INFO Executor: Finished task 18.0 in stage 18.0 (TID 140). 2760 bytes result sent to driver\n",
      "25/06/27 09:20:54 INFO TaskSetManager: Starting task 27.0 in stage 18.0 (TID 149) (hal9000, executor driver, partition 27, PROCESS_LOCAL, 7895 bytes) \n",
      "25/06/27 09:20:54 INFO Executor: Running task 27.0 in stage 18.0 (TID 149)\n",
      "25/06/27 09:20:54 INFO TaskSetManager: Finished task 18.0 in stage 18.0 (TID 140) in 21418 ms on hal9000 (executor driver) (20/33)\n",
      "25/06/27 09:20:55 INFO FileScanRDD: Reading File path: s3a://datalake/climate.csv, range: 3623878656-3758096384, partition values: [empty row]\n",
      "25/06/27 09:20:56 INFO Executor: Finished task 21.0 in stage 18.0 (TID 143). 2760 bytes result sent to driver\n",
      "25/06/27 09:20:56 INFO TaskSetManager: Starting task 28.0 in stage 18.0 (TID 150) (hal9000, executor driver, partition 28, PROCESS_LOCAL, 7895 bytes) \n",
      "25/06/27 09:20:56 INFO TaskSetManager: Finished task 21.0 in stage 18.0 (TID 143) in 20890 ms on hal9000 (executor driver) (21/33)\n",
      "25/06/27 09:20:56 INFO Executor: Running task 28.0 in stage 18.0 (TID 150)\n",
      "25/06/27 09:20:56 INFO FileScanRDD: Reading File path: s3a://datalake/climate.csv, range: 3758096384-3892314112, partition values: [empty row]\n",
      "25/06/27 09:20:57 INFO Executor: Finished task 20.0 in stage 18.0 (TID 142). 2760 bytes result sent to driver\n",
      "25/06/27 09:20:57 INFO TaskSetManager: Starting task 29.0 in stage 18.0 (TID 151) (hal9000, executor driver, partition 29, PROCESS_LOCAL, 7895 bytes) \n",
      "25/06/27 09:20:57 INFO TaskSetManager: Finished task 20.0 in stage 18.0 (TID 142) in 22045 ms on hal9000 (executor driver) (22/33)\n",
      "25/06/27 09:20:57 INFO Executor: Running task 29.0 in stage 18.0 (TID 151)\n",
      "25/06/27 09:20:57 INFO Executor: Finished task 22.0 in stage 18.0 (TID 144). 2760 bytes result sent to driver\n",
      "25/06/27 09:20:57 INFO TaskSetManager: Starting task 30.0 in stage 18.0 (TID 152) (hal9000, executor driver, partition 30, PROCESS_LOCAL, 7895 bytes) \n",
      "25/06/27 09:20:57 INFO TaskSetManager: Finished task 22.0 in stage 18.0 (TID 144) in 20417 ms on hal9000 (executor driver) (23/33)\n",
      "25/06/27 09:20:57 INFO FileScanRDD: Reading File path: s3a://datalake/climate.csv, range: 3892314112-4026531840, partition values: [empty row]\n",
      "25/06/27 09:20:57 INFO Executor: Running task 30.0 in stage 18.0 (TID 152) / 33]\n",
      "25/06/27 09:20:57 INFO FileScanRDD: Reading File path: s3a://datalake/climate.csv, range: 4026531840-4160749568, partition values: [empty row]\n",
      "25/06/27 09:20:59 INFO Executor: Finished task 23.0 in stage 18.0 (TID 145). 2760 bytes result sent to driver\n",
      "25/06/27 09:20:59 INFO TaskSetManager: Starting task 31.0 in stage 18.0 (TID 153) (hal9000, executor driver, partition 31, PROCESS_LOCAL, 7895 bytes) \n",
      "25/06/27 09:20:59 INFO Executor: Running task 31.0 in stage 18.0 (TID 153)\n",
      "25/06/27 09:20:59 INFO TaskSetManager: Finished task 23.0 in stage 18.0 (TID 145) in 21895 ms on hal9000 (executor driver) (24/33)\n",
      "25/06/27 09:20:59 INFO FileScanRDD: Reading File path: s3a://datalake/climate.csv, range: 4160749568-4294967296, partition values: [empty row]\n",
      "25/06/27 09:21:09 INFO Executor: Finished task 24.0 in stage 18.0 (TID 146). 2760 bytes result sent to driver\n",
      "25/06/27 09:21:09 INFO TaskSetManager: Starting task 32.0 in stage 18.0 (TID 154) (hal9000, executor driver, partition 32, PROCESS_LOCAL, 7895 bytes) \n",
      "25/06/27 09:21:09 INFO Executor: Running task 32.0 in stage 18.0 (TID 154)\n",
      "25/06/27 09:21:09 INFO TaskSetManager: Finished task 24.0 in stage 18.0 (TID 146) in 19058 ms on hal9000 (executor driver) (25/33)\n",
      "25/06/27 09:21:09 INFO FileScanRDD: Reading File path: s3a://datalake/climate.csv, range: 4294967296-4356534577, partition values: [empty row]\n",
      "25/06/27 09:21:10 INFO Executor: Finished task 25.0 in stage 18.0 (TID 147). 2760 bytes result sent to driver\n",
      "25/06/27 09:21:10 INFO TaskSetManager: Finished task 25.0 in stage 18.0 (TID 147) in 17843 ms on hal9000 (executor driver) (26/33)\n",
      "25/06/27 09:21:11 INFO Executor: Finished task 28.0 in stage 18.0 (TID 150). 2760 bytes result sent to driver\n",
      "25/06/27 09:21:11 INFO TaskSetManager: Finished task 28.0 in stage 18.0 (TID 150) in 15029 ms on hal9000 (executor driver) (27/33)\n",
      "25/06/27 09:21:11 INFO Executor: Finished task 26.0 in stage 18.0 (TID 148). 2760 bytes result sent to driver\n",
      "25/06/27 09:21:11 INFO TaskSetManager: Finished task 26.0 in stage 18.0 (TID 148) in 17212 ms on hal9000 (executor driver) (28/33)\n",
      "25/06/27 09:21:12 INFO Executor: Finished task 27.0 in stage 18.0 (TID 149). 2760 bytes result sent to driver\n",
      "25/06/27 09:21:12 INFO TaskSetManager: Finished task 27.0 in stage 18.0 (TID 149) in 17106 ms on hal9000 (executor driver) (29/33)\n",
      "25/06/27 09:21:12 INFO Executor: Finished task 29.0 in stage 18.0 (TID 151). 2760 bytes result sent to driver\n",
      "25/06/27 09:21:12 INFO TaskSetManager: Finished task 29.0 in stage 18.0 (TID 151) in 15166 ms on hal9000 (executor driver) (30/33)\n",
      "25/06/27 09:21:12 INFO Executor: Finished task 30.0 in stage 18.0 (TID 152). 2760 bytes result sent to driver\n",
      "25/06/27 09:21:12 INFO TaskSetManager: Finished task 30.0 in stage 18.0 (TID 152) in 15298 ms on hal9000 (executor driver) (31/33)\n",
      "25/06/27 09:21:13 INFO Executor: Finished task 31.0 in stage 18.0 (TID 153). 2760 bytes result sent to driver\n",
      "25/06/27 09:21:13 INFO TaskSetManager: Finished task 31.0 in stage 18.0 (TID 153) in 13432 ms on hal9000 (executor driver) (32/33)\n",
      "25/06/27 09:21:14 INFO Executor: Finished task 32.0 in stage 18.0 (TID 154). 2760 bytes result sent to driver\n",
      "25/06/27 09:21:14 INFO TaskSetManager: Finished task 32.0 in stage 18.0 (TID 154) in 4810 ms on hal9000 (executor driver) (33/33)\n",
      "25/06/27 09:21:14 INFO TaskSchedulerImpl: Removed TaskSet 18.0, whose tasks have all completed, from pool \n",
      "25/06/27 09:21:14 INFO DAGScheduler: ShuffleMapStage 18 (showString at NativeMethodAccessorImpl.java:0) finished in 84.606 s\n",
      "25/06/27 09:21:14 INFO DAGScheduler: looking for newly runnable stages\n",
      "25/06/27 09:21:14 INFO DAGScheduler: running: Set()\n",
      "25/06/27 09:21:14 INFO DAGScheduler: waiting: Set()\n",
      "25/06/27 09:21:14 INFO DAGScheduler: failed: Set()\n",
      "25/06/27 09:21:14 WARN WindowExec: No Partition Defined for Window operation! Moving all data to a single partition, this can cause serious performance degradation.\n",
      "25/06/27 09:21:14 WARN WindowExec: No Partition Defined for Window operation! Moving all data to a single partition, this can cause serious performance degradation.\n",
      "25/06/27 09:21:14 INFO ShufflePartitionsUtil: For shuffle(6), advisory target size: 67108864, actual target size 1048576, minimum partition size: 1048576\n",
      "25/06/27 09:21:14 WARN WindowExec: No Partition Defined for Window operation! Moving all data to a single partition, this can cause serious performance degradation.\n",
      "25/06/27 09:21:14 INFO CodeGenerator: Code generated in 24.224045 ms\n",
      "25/06/27 09:21:14 INFO CodeGenerator: Code generated in 57.342356 ms\n",
      "25/06/27 09:21:14 INFO HashAggregateExec: spark.sql.codegen.aggregate.map.twolevel.enabled is set to true, but current version of codegened fast hashmap does not support this aggregate.\n",
      "25/06/27 09:21:14 INFO CodeGenerator: Code generated in 57.646629 ms\n",
      "25/06/27 09:21:14 INFO SparkContext: Starting job: showString at NativeMethodAccessorImpl.java:0\n",
      "25/06/27 09:21:14 INFO DAGScheduler: Got job 12 (showString at NativeMethodAccessorImpl.java:0) with 1 output partitions\n",
      "25/06/27 09:21:14 INFO DAGScheduler: Final stage: ResultStage 20 (showString at NativeMethodAccessorImpl.java:0)\n",
      "25/06/27 09:21:14 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 19)\n",
      "25/06/27 09:21:14 INFO DAGScheduler: Missing parents: List()\n",
      "25/06/27 09:21:14 INFO DAGScheduler: Submitting ResultStage 20 (MapPartitionsRDD[61] at showString at NativeMethodAccessorImpl.java:0), which has no missing parents\n",
      "25/06/27 09:21:14 INFO MemoryStore: Block broadcast_22 stored as values in memory (estimated size 56.6 KiB, free 433.8 MiB)\n",
      "25/06/27 09:21:14 INFO MemoryStore: Block broadcast_22_piece0 stored as bytes in memory (estimated size 24.9 KiB, free 433.7 MiB)\n",
      "25/06/27 09:21:14 INFO BlockManagerInfo: Added broadcast_22_piece0 in memory on hal9000:34557 (size: 24.9 KiB, free: 434.3 MiB)\n",
      "25/06/27 09:21:14 INFO SparkContext: Created broadcast 22 from broadcast at DAGScheduler.scala:1535\n",
      "25/06/27 09:21:14 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 20 (MapPartitionsRDD[61] at showString at NativeMethodAccessorImpl.java:0) (first 15 tasks are for partitions Vector(0))\n",
      "25/06/27 09:21:14 INFO TaskSchedulerImpl: Adding task set 20.0 with 1 tasks resource profile 0\n",
      "25/06/27 09:21:14 INFO TaskSetManager: Starting task 0.0 in stage 20.0 (TID 155) (hal9000, executor driver, partition 0, NODE_LOCAL, 7363 bytes) \n",
      "25/06/27 09:21:14 INFO Executor: Running task 0.0 in stage 20.0 (TID 155)\n",
      "25/06/27 09:21:14 INFO ShuffleBlockFetcherIterator: Getting 33 (536.7 KiB) non-empty blocks including 33 (536.7 KiB) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks\n",
      "25/06/27 09:21:14 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 4 ms\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------------+--------+---------+-------------------+-------------------+------------+------+\n",
      "|localidade_pk|latitude|longitude|cidade             |estado             |regiao      |pais  |\n",
      "+-------------+--------+---------+-------------------+-------------------+------------+------+\n",
      "|1            |-16.7573|-49.4412 |Abadia de Goiás    |Goiás              |Centro-Oeste|Brasil|\n",
      "|2            |-18.4831|-47.3916 |Abadia dos Dourados|Minas Gerais       |Sudeste     |Brasil|\n",
      "|3            |-16.197 |-48.7057 |Abadiânia          |Goiás              |Centro-Oeste|Brasil|\n",
      "|4            |-1.7218 |-48.8788 |Abaetetuba         |Pará               |Norte       |Brasil|\n",
      "|5            |-19.1551|-45.4444 |Abaeté             |Minas Gerais       |Sudeste     |Brasil|\n",
      "|6            |-7.3459 |-39.0416 |Abaiara            |Ceará              |Nordeste    |Brasil|\n",
      "|7            |-8.7207 |-39.1162 |Abaré              |Bahia              |Nordeste    |Brasil|\n",
      "|8            |-23.3049|-50.3133 |Abatiá             |Paraná             |Sul         |Brasil|\n",
      "|9            |-13.2488|-41.6619 |Abaíra             |Bahia              |Nordeste    |Brasil|\n",
      "|10           |-27.6126|-51.0233 |Abdon Batista      |Santa Catarina     |Sul         |Brasil|\n",
      "|11           |-4.9533 |-48.3933 |Abel Figueiredo    |Pará               |Norte       |Brasil|\n",
      "|12           |-26.5716|-52.3229 |Abelardo Luz       |Santa Catarina     |Sul         |Brasil|\n",
      "|13           |-20.2996|-42.4743 |Abre Campo         |Minas Gerais       |Sudeste     |Brasil|\n",
      "|14           |-7.9007 |-34.8984 |Abreu e Lima       |Pernambuco         |Nordeste    |Brasil|\n",
      "|15           |-9.621  |-49.1518 |Abreulândia        |Tocantins          |Norte       |Brasil|\n",
      "|16           |-20.359 |-43.1439 |Acaiaca            |Minas Gerais       |Sudeste     |Brasil|\n",
      "|17           |-11.6575|-38.0197 |Acajutiba          |Bahia              |Nordeste    |Brasil|\n",
      "|18           |-4.2208 |-38.7055 |Acarape            |Ceará              |Nordeste    |Brasil|\n",
      "|19           |-2.8877 |-40.1183 |Acaraú             |Ceará              |Nordeste    |Brasil|\n",
      "|20           |-6.4282 |-36.6347 |Acari              |Rio Grande do Norte|Nordeste    |Brasil|\n",
      "+-------------+--------+---------+-------------------+-------------------+------------+------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "25/06/27 09:21:14 INFO CodeGenerator: Code generated in 26.878986 ms\n",
      "25/06/27 09:21:14 INFO Executor: Finished task 0.0 in stage 20.0 (TID 155). 7737 bytes result sent to driver\n",
      "25/06/27 09:21:14 INFO TaskSetManager: Finished task 0.0 in stage 20.0 (TID 155) in 182 ms on hal9000 (executor driver) (1/1)\n",
      "25/06/27 09:21:14 INFO TaskSchedulerImpl: Removed TaskSet 20.0, whose tasks have all completed, from pool \n",
      "25/06/27 09:21:14 INFO DAGScheduler: ResultStage 20 (showString at NativeMethodAccessorImpl.java:0) finished in 0.197 s\n",
      "25/06/27 09:21:14 INFO DAGScheduler: Job 12 is finished. Cancelling potential speculative or zombie tasks for this job\n",
      "25/06/27 09:21:14 INFO TaskSchedulerImpl: Killing all running tasks in stage 20: Stage finished\n",
      "25/06/27 09:21:14 INFO DAGScheduler: Job 12 finished: showString at NativeMethodAccessorImpl.java:0, took 0.219012 s\n",
      "25/06/27 09:21:14 INFO CodeGenerator: Code generated in 19.394214 ms            \n"
     ]
    }
   ],
   "source": [
    "# Transformção da Localidade, os campos 'região', 'pais' são derivados do 'estado' pelo mapeamento a seguir\n",
    "\n",
    "estado_para_regiao = {\n",
    "    \"Acre\": \"Norte\",\n",
    "    \"Alagoas\": \"Nordeste\",\n",
    "    \"Amapá\": \"Norte\",\n",
    "    \"Amazonas\": \"Norte\",\n",
    "    \"Bahia\": \"Nordeste\",\n",
    "    \"Ceará\": \"Nordeste\",\n",
    "    \"Distrito Federal\": \"Centro-Oeste\",\n",
    "    \"Espírito Santo\": \"Sudeste\",\n",
    "    \"Goiás\": \"Centro-Oeste\",\n",
    "    \"Maranhão\": \"Nordeste\",\n",
    "    \"Mato Grosso\": \"Centro-Oeste\",\n",
    "    \"Mato Grosso do Sul\": \"Centro-Oeste\",\n",
    "    \"Minas Gerais\": \"Sudeste\",\n",
    "    \"Pará\": \"Norte\",\n",
    "    \"Paraíba\": \"Nordeste\",\n",
    "    \"Paraná\": \"Sul\",\n",
    "    \"Pernambuco\": \"Nordeste\",\n",
    "    \"Piauí\": \"Nordeste\",\n",
    "    \"Rio de Janeiro\": \"Sudeste\",\n",
    "    \"Rio Grande do Norte\": \"Nordeste\",\n",
    "    \"Rio Grande do Sul\": \"Sul\",\n",
    "    \"Rondônia\": \"Norte\",\n",
    "    \"Roraima\": \"Norte\",\n",
    "    \"Santa Catarina\": \"Sul\",\n",
    "    \"São Paulo\": \"Sudeste\",\n",
    "    \"Sergipe\": \"Nordeste\",\n",
    "    \"Tocantins\": \"Norte\"\n",
    "}\n",
    "\n",
    "# Cria um mapa de estado para região\n",
    "estado_regiao_map = F.create_map([F.lit(x) for kv in estado_para_regiao.items() for x in kv])\n",
    "\n",
    "df_localidade = (\n",
    "    df_clima.select(\"cidade\", \"estado\", \"latitude\", \"longitude\")\n",
    "            .distinct()\n",
    "            .withColumn(\"pais\", F.lit(\"Brasil\"))\n",
    "            .withColumn(\n",
    "                \"regiao\",\n",
    "                F.when(F.col(\"estado\").isNotNull(), estado_regiao_map.getItem(F.col(\"estado\")))\n",
    "            )\n",
    ")\n",
    "\n",
    "windowSpec = Window.orderBy(\"cidade\", \"estado\", \"latitude\", \"longitude\")\n",
    "df_localidade = (\n",
    "    df_localidade.withColumn(\"localidade_pk\", F.row_number().over(windowSpec))\n",
    "                 .select(\"localidade_pk\", \"latitude\", \"longitude\", \"cidade\", \"estado\", \"regiao\", \"pais\")\n",
    ")\n",
    "\n",
    "df_localidade.show(truncate=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "30ab8fb3",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "25/06/27 09:21:14 INFO FileSourceStrategy: Pushed Filters: \n",
      "25/06/27 09:21:14 INFO FileSourceStrategy: Post-Scan Filters: \n",
      "25/06/27 09:21:14 INFO FileSourceStrategy: Pushed Filters: \n",
      "25/06/27 09:21:14 INFO FileSourceStrategy: Post-Scan Filters: \n",
      "25/06/27 09:21:14 INFO HashAggregateExec: spark.sql.codegen.aggregate.map.twolevel.enabled is set to true, but current version of codegened fast hashmap does not support this aggregate.\n",
      "25/06/27 09:21:14 INFO CodeGenerator: Code generated in 28.54032 ms\n",
      "25/06/27 09:21:14 INFO CodeGenerator: Code generated in 11.558611 ms\n",
      "25/06/27 09:21:14 INFO MemoryStore: Block broadcast_23 stored as values in memory (estimated size 203.2 KiB, free 433.5 MiB)\n",
      "25/06/27 09:21:14 INFO MemoryStore: Block broadcast_23_piece0 stored as bytes in memory (estimated size 35.4 KiB, free 433.5 MiB)\n",
      "25/06/27 09:21:14 INFO BlockManagerInfo: Added broadcast_23_piece0 in memory on hal9000:34557 (size: 35.4 KiB, free: 434.2 MiB)\n",
      "25/06/27 09:21:14 INFO SparkContext: Created broadcast 23 from showString at NativeMethodAccessorImpl.java:0\n",
      "25/06/27 09:21:14 INFO FileSourceScanExec: Planning scan with bin packing, max size: 11024413 bytes, open cost is considered as scanning 4194304 bytes.\n",
      "25/06/27 09:21:14 INFO CodeGenerator: Code generated in 11.72924 ms\n",
      "25/06/27 09:21:14 INFO MemoryStore: Block broadcast_24 stored as values in memory (estimated size 203.2 KiB, free 433.3 MiB)\n",
      "25/06/27 09:21:15 INFO BlockManagerInfo: Removed broadcast_22_piece0 on hal9000:34557 in memory (size: 24.9 KiB, free: 434.3 MiB)\n",
      "25/06/27 09:21:15 INFO MemoryStore: Block broadcast_24_piece0 stored as bytes in memory (estimated size 35.4 KiB, free 433.4 MiB)\n",
      "25/06/27 09:21:15 INFO BlockManagerInfo: Added broadcast_24_piece0 in memory on hal9000:34557 (size: 35.4 KiB, free: 434.2 MiB)\n",
      "25/06/27 09:21:15 INFO SparkContext: Created broadcast 24 from showString at NativeMethodAccessorImpl.java:0\n",
      "25/06/27 09:21:15 INFO FileSourceScanExec: Planning scan with bin packing, max size: 4194304 bytes, open cost is considered as scanning 4194304 bytes.\n",
      "25/06/27 09:21:15 INFO DAGScheduler: Registering RDD 70 (showString at NativeMethodAccessorImpl.java:0) as input to shuffle 7\n",
      "25/06/27 09:21:15 INFO DAGScheduler: Got map stage job 13 (showString at NativeMethodAccessorImpl.java:0) with 9 output partitions\n",
      "25/06/27 09:21:15 INFO DAGScheduler: Final stage: ShuffleMapStage 21 (showString at NativeMethodAccessorImpl.java:0)\n",
      "25/06/27 09:21:15 INFO DAGScheduler: Parents of final stage: List()\n",
      "25/06/27 09:21:15 INFO DAGScheduler: Missing parents: List()\n",
      "25/06/27 09:21:15 INFO DAGScheduler: Submitting ShuffleMapStage 21 (MapPartitionsRDD[70] at showString at NativeMethodAccessorImpl.java:0), which has no missing parents\n",
      "25/06/27 09:21:15 INFO MemoryStore: Block broadcast_25 stored as values in memory (estimated size 37.9 KiB, free 433.3 MiB)\n",
      "25/06/27 09:21:15 INFO MemoryStore: Block broadcast_25_piece0 stored as bytes in memory (estimated size 17.0 KiB, free 433.3 MiB)\n",
      "25/06/27 09:21:15 INFO BlockManagerInfo: Added broadcast_25_piece0 in memory on hal9000:34557 (size: 17.0 KiB, free: 434.2 MiB)\n",
      "25/06/27 09:21:15 INFO SparkContext: Created broadcast 25 from broadcast at DAGScheduler.scala:1535\n",
      "25/06/27 09:21:15 INFO DAGScheduler: Submitting 9 missing tasks from ShuffleMapStage 21 (MapPartitionsRDD[70] at showString at NativeMethodAccessorImpl.java:0) (first 15 tasks are for partitions Vector(0, 1, 2, 3, 4, 5, 6, 7, 8))\n",
      "25/06/27 09:21:15 INFO TaskSchedulerImpl: Adding task set 21.0 with 9 tasks resource profile 0\n",
      "25/06/27 09:21:15 INFO TaskSetManager: Starting task 0.0 in stage 21.0 (TID 156) (hal9000, executor driver, partition 0, PROCESS_LOCAL, 8005 bytes) \n",
      "25/06/27 09:21:15 INFO TaskSetManager: Starting task 1.0 in stage 21.0 (TID 157) (hal9000, executor driver, partition 1, PROCESS_LOCAL, 8005 bytes) \n",
      "25/06/27 09:21:15 INFO TaskSetManager: Starting task 2.0 in stage 21.0 (TID 158) (hal9000, executor driver, partition 2, PROCESS_LOCAL, 8005 bytes) \n",
      "25/06/27 09:21:15 INFO TaskSetManager: Starting task 3.0 in stage 21.0 (TID 159) (hal9000, executor driver, partition 3, PROCESS_LOCAL, 8005 bytes) \n",
      "25/06/27 09:21:15 INFO TaskSetManager: Starting task 4.0 in stage 21.0 (TID 160) (hal9000, executor driver, partition 4, PROCESS_LOCAL, 8005 bytes) \n",
      "25/06/27 09:21:15 INFO TaskSetManager: Starting task 5.0 in stage 21.0 (TID 161) (hal9000, executor driver, partition 5, PROCESS_LOCAL, 8005 bytes) \n",
      "25/06/27 09:21:15 INFO TaskSetManager: Starting task 6.0 in stage 21.0 (TID 162) (hal9000, executor driver, partition 6, PROCESS_LOCAL, 8005 bytes) \n",
      "25/06/27 09:21:15 INFO TaskSetManager: Starting task 7.0 in stage 21.0 (TID 163) (hal9000, executor driver, partition 7, PROCESS_LOCAL, 8005 bytes) \n",
      "25/06/27 09:21:15 INFO Executor: Running task 5.0 in stage 21.0 (TID 161)\n",
      "25/06/27 09:21:15 INFO Executor: Running task 0.0 in stage 21.0 (TID 156)\n",
      "25/06/27 09:21:15 INFO Executor: Running task 4.0 in stage 21.0 (TID 160)\n",
      "25/06/27 09:21:15 INFO Executor: Running task 3.0 in stage 21.0 (TID 159)\n",
      "25/06/27 09:21:15 INFO Executor: Running task 7.0 in stage 21.0 (TID 163)\n",
      "25/06/27 09:21:15 INFO Executor: Running task 1.0 in stage 21.0 (TID 157)\n",
      "25/06/27 09:21:15 INFO Executor: Running task 6.0 in stage 21.0 (TID 162)\n",
      "25/06/27 09:21:15 INFO Executor: Running task 2.0 in stage 21.0 (TID 158)\n",
      "25/06/27 09:21:15 INFO CodeGenerator: Code generated in 26.708751 ms\n",
      "25/06/27 09:21:15 INFO CodeGenerator: Code generated in 19.171194 ms\n",
      "25/06/27 09:21:15 INFO FileScanRDD: Reading File path: s3a://datalake/cancer-1.csv, range: 11024413-22048826, partition values: [empty row]\n",
      "25/06/27 09:21:15 INFO FileScanRDD: Reading File path: s3a://datalake/cancer-1.csv, range: 55122065-66146478, partition values: [empty row]\n",
      "25/06/27 09:21:15 INFO FileScanRDD: Reading File path: s3a://datalake/cancer-1.csv, range: 0-11024413, partition values: [empty row]\n",
      "25/06/27 09:21:15 INFO FileScanRDD: Reading File path: s3a://datalake/cancer-1.csv, range: 66146478-77170891, partition values: [empty row]\n",
      "25/06/27 09:21:15 INFO FileScanRDD: Reading File path: s3a://datalake/cancer-1.csv, range: 44097652-55122065, partition values: [empty row]\n",
      "25/06/27 09:21:15 INFO FileScanRDD: Reading File path: s3a://datalake/cancer-1.csv, range: 22048826-33073239, partition values: [empty row]\n",
      "25/06/27 09:21:15 INFO FileScanRDD: Reading File path: s3a://datalake/cancer-1.csv, range: 33073239-44097652, partition values: [empty row]\n",
      "25/06/27 09:21:15 INFO FileScanRDD: Reading File path: s3a://datalake/cancer-1.csv, range: 77170891-84001007, partition values: [empty row]\n",
      "25/06/27 09:21:15 INFO BlockManagerInfo: Removed broadcast_21_piece0 on hal9000:34557 in memory (size: 16.2 KiB, free: 434.2 MiB)\n",
      "25/06/27 09:21:15 INFO BlockManagerInfo: Removed broadcast_17_piece0 on hal9000:34557 in memory (size: 19.0 KiB, free: 434.2 MiB)\n",
      "25/06/27 09:21:15 INFO BlockManagerInfo: Removed broadcast_16_piece0 on hal9000:34557 in memory (size: 35.4 KiB, free: 434.3 MiB)\n",
      "25/06/27 09:21:16 INFO Executor: Finished task 2.0 in stage 21.0 (TID 158). 3139 bytes result sent to driver\n",
      "25/06/27 09:21:16 INFO TaskSetManager: Starting task 8.0 in stage 21.0 (TID 164) (hal9000, executor driver, partition 8, PROCESS_LOCAL, 8005 bytes) \n",
      "25/06/27 09:21:16 INFO TaskSetManager: Finished task 2.0 in stage 21.0 (TID 158) in 1343 ms on hal9000 (executor driver) (1/9)\n",
      "25/06/27 09:21:16 INFO Executor: Running task 8.0 in stage 21.0 (TID 164)\n",
      "25/06/27 09:21:16 INFO FileScanRDD: Reading File path: s3a://datalake/cancer-2.csv, range: 0-3668986, partition values: [empty row]\n",
      "25/06/27 09:21:16 INFO Executor: Finished task 7.0 in stage 21.0 (TID 163). 3139 bytes result sent to driver\n",
      "25/06/27 09:21:16 INFO TaskSetManager: Finished task 7.0 in stage 21.0 (TID 163) in 1511 ms on hal9000 (executor driver) (2/9)\n",
      "25/06/27 09:21:16 INFO Executor: Finished task 4.0 in stage 21.0 (TID 160). 3139 bytes result sent to driver\n",
      "25/06/27 09:21:16 INFO TaskSetManager: Finished task 4.0 in stage 21.0 (TID 160) in 1521 ms on hal9000 (executor driver) (3/9)\n",
      "25/06/27 09:21:16 INFO Executor: Finished task 5.0 in stage 21.0 (TID 161). 3139 bytes result sent to driver\n",
      "25/06/27 09:21:16 INFO TaskSetManager: Finished task 5.0 in stage 21.0 (TID 161) in 1604 ms on hal9000 (executor driver) (4/9)\n",
      "25/06/27 09:21:16 INFO Executor: Finished task 0.0 in stage 21.0 (TID 156). 3096 bytes result sent to driver\n",
      "25/06/27 09:21:16 INFO TaskSetManager: Finished task 0.0 in stage 21.0 (TID 156) in 1631 ms on hal9000 (executor driver) (5/9)\n",
      "25/06/27 09:21:16 INFO Executor: Finished task 3.0 in stage 21.0 (TID 159). 3096 bytes result sent to driver\n",
      "25/06/27 09:21:16 INFO TaskSetManager: Finished task 3.0 in stage 21.0 (TID 159) in 1767 ms on hal9000 (executor driver) (6/9)\n",
      "25/06/27 09:21:16 INFO Executor: Finished task 6.0 in stage 21.0 (TID 162). 3096 bytes result sent to driver\n",
      "25/06/27 09:21:16 INFO TaskSetManager: Finished task 6.0 in stage 21.0 (TID 162) in 1772 ms on hal9000 (executor driver) (7/9)\n",
      "25/06/27 09:21:16 INFO Executor: Finished task 8.0 in stage 21.0 (TID 164). 3096 bytes result sent to driver\n",
      "25/06/27 09:21:16 INFO TaskSetManager: Finished task 8.0 in stage 21.0 (TID 164) in 452 ms on hal9000 (executor driver) (8/9)\n",
      "25/06/27 09:21:16 INFO Executor: Finished task 1.0 in stage 21.0 (TID 157). 3096 bytes result sent to driver\n",
      "25/06/27 09:21:16 INFO TaskSetManager: Finished task 1.0 in stage 21.0 (TID 157) in 1820 ms on hal9000 (executor driver) (9/9)\n",
      "25/06/27 09:21:16 INFO TaskSchedulerImpl: Removed TaskSet 21.0, whose tasks have all completed, from pool \n",
      "25/06/27 09:21:16 INFO DAGScheduler: ShuffleMapStage 21 (showString at NativeMethodAccessorImpl.java:0) finished in 1.846 s\n",
      "25/06/27 09:21:16 INFO DAGScheduler: looking for newly runnable stages\n",
      "25/06/27 09:21:16 INFO DAGScheduler: running: Set()\n",
      "25/06/27 09:21:16 INFO DAGScheduler: waiting: Set()\n",
      "25/06/27 09:21:16 INFO DAGScheduler: failed: Set()\n",
      "25/06/27 09:21:16 INFO ShufflePartitionsUtil: For shuffle(7), advisory target size: 67108864, actual target size 1048576, minimum partition size: 1048576\n",
      "25/06/27 09:21:16 INFO HashAggregateExec: spark.sql.codegen.aggregate.map.twolevel.enabled is set to true, but current version of codegened fast hashmap does not support this aggregate.\n",
      "25/06/27 09:21:17 INFO CodeGenerator: Code generated in 52.625313 ms\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------+-------+\n",
      "|     sexo|sexo_pk|\n",
      "+---------+-------+\n",
      "| Feminino|      0|\n",
      "|Masculino|      1|\n",
      "+---------+-------+\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "25/06/27 09:21:17 INFO SparkContext: Starting job: showString at NativeMethodAccessorImpl.java:0\n",
      "25/06/27 09:21:17 INFO DAGScheduler: Got job 14 (showString at NativeMethodAccessorImpl.java:0) with 1 output partitions\n",
      "25/06/27 09:21:17 INFO DAGScheduler: Final stage: ResultStage 23 (showString at NativeMethodAccessorImpl.java:0)\n",
      "25/06/27 09:21:17 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 22)\n",
      "25/06/27 09:21:17 INFO DAGScheduler: Missing parents: List()\n",
      "25/06/27 09:21:17 INFO DAGScheduler: Submitting ResultStage 23 (MapPartitionsRDD[73] at showString at NativeMethodAccessorImpl.java:0), which has no missing parents\n",
      "25/06/27 09:21:17 INFO MemoryStore: Block broadcast_26 stored as values in memory (estimated size 41.5 KiB, free 433.6 MiB)\n",
      "25/06/27 09:21:17 INFO MemoryStore: Block broadcast_26_piece0 stored as bytes in memory (estimated size 19.7 KiB, free 433.6 MiB)\n",
      "25/06/27 09:21:17 INFO BlockManagerInfo: Added broadcast_26_piece0 in memory on hal9000:34557 (size: 19.7 KiB, free: 434.3 MiB)\n",
      "25/06/27 09:21:17 INFO SparkContext: Created broadcast 26 from broadcast at DAGScheduler.scala:1535\n",
      "25/06/27 09:21:17 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 23 (MapPartitionsRDD[73] at showString at NativeMethodAccessorImpl.java:0) (first 15 tasks are for partitions Vector(0))\n",
      "25/06/27 09:21:17 INFO TaskSchedulerImpl: Adding task set 23.0 with 1 tasks resource profile 0\n",
      "25/06/27 09:21:17 INFO TaskSetManager: Starting task 0.0 in stage 23.0 (TID 165) (hal9000, executor driver, partition 0, NODE_LOCAL, 7363 bytes) \n",
      "25/06/27 09:21:17 INFO Executor: Running task 0.0 in stage 23.0 (TID 165)\n",
      "25/06/27 09:21:17 INFO ShuffleBlockFetcherIterator: Getting 9 (1368.0 B) non-empty blocks including 9 (1368.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks\n",
      "25/06/27 09:21:17 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 7 ms\n",
      "25/06/27 09:21:17 INFO Executor: Finished task 0.0 in stage 23.0 (TID 165). 5507 bytes result sent to driver\n",
      "25/06/27 09:21:17 INFO TaskSetManager: Finished task 0.0 in stage 23.0 (TID 165) in 39 ms on hal9000 (executor driver) (1/1)\n",
      "25/06/27 09:21:17 INFO TaskSchedulerImpl: Removed TaskSet 23.0, whose tasks have all completed, from pool \n",
      "25/06/27 09:21:17 INFO DAGScheduler: ResultStage 23 (showString at NativeMethodAccessorImpl.java:0) finished in 0.058 s\n",
      "25/06/27 09:21:17 INFO DAGScheduler: Job 14 is finished. Cancelling potential speculative or zombie tasks for this job\n",
      "25/06/27 09:21:17 INFO TaskSchedulerImpl: Killing all running tasks in stage 23: Stage finished\n",
      "25/06/27 09:21:17 INFO DAGScheduler: Job 14 finished: showString at NativeMethodAccessorImpl.java:0, took 0.066066 s\n",
      "25/06/27 09:21:17 INFO CodeGenerator: Code generated in 13.236387 ms            \n"
     ]
    }
   ],
   "source": [
    "# Tranformação da Dimensão Sexo\n",
    "\n",
    "df_sexo = df_cancer.select(\n",
    "    F.col(\"sex_name\").alias(\"sexo\")\n",
    ").distinct()\n",
    "\n",
    "df_sexo = df_sexo.withColumn(\"sexo_pk\", F.monotonically_increasing_id())\n",
    "\n",
    "df_sexo.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "846bd15d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "25/06/27 09:21:17 INFO FileSourceStrategy: Pushed Filters: IsNotNull(metric_name),EqualTo(metric_name,Número)\n",
      "25/06/27 09:21:17 INFO FileSourceStrategy: Post-Scan Filters: isnotnull(metric_name#11),(metric_name#11 = Número)\n",
      "25/06/27 09:21:17 INFO FileSourceStrategy: Pushed Filters: IsNotNull(metric_name),EqualTo(metric_name,Número)\n",
      "25/06/27 09:21:17 INFO FileSourceStrategy: Post-Scan Filters: isnotnull(metric_name#43),(metric_name#43 = Número)\n",
      "25/06/27 09:21:17 INFO CodeGenerator: Code generated in 15.772801 ms\n",
      "25/06/27 09:21:17 INFO CodeGenerator: Code generated in 12.455727 ms\n",
      "25/06/27 09:21:17 INFO MemoryStore: Block broadcast_27 stored as values in memory (estimated size 203.2 KiB, free 433.4 MiB)\n",
      "25/06/27 09:21:17 INFO MemoryStore: Block broadcast_27_piece0 stored as bytes in memory (estimated size 35.4 KiB, free 433.4 MiB)\n",
      "25/06/27 09:21:17 INFO BlockManagerInfo: Added broadcast_27_piece0 in memory on hal9000:34557 (size: 35.4 KiB, free: 434.2 MiB)\n",
      "25/06/27 09:21:17 INFO SparkContext: Created broadcast 27 from collect at /tmp/ipykernel_14560/3186139197.py:7\n",
      "25/06/27 09:21:17 INFO FileSourceScanExec: Planning scan with bin packing, max size: 11024413 bytes, open cost is considered as scanning 4194304 bytes.\n",
      "25/06/27 09:21:17 INFO CodeGenerator: Code generated in 6.064452 ms\n",
      "25/06/27 09:21:17 INFO MemoryStore: Block broadcast_28 stored as values in memory (estimated size 203.2 KiB, free 433.2 MiB)\n",
      "25/06/27 09:21:17 INFO MemoryStore: Block broadcast_28_piece0 stored as bytes in memory (estimated size 35.4 KiB, free 433.1 MiB)\n",
      "25/06/27 09:21:17 INFO BlockManagerInfo: Added broadcast_28_piece0 in memory on hal9000:34557 (size: 35.4 KiB, free: 434.2 MiB)\n",
      "25/06/27 09:21:17 INFO SparkContext: Created broadcast 28 from collect at /tmp/ipykernel_14560/3186139197.py:7\n",
      "25/06/27 09:21:17 INFO FileSourceScanExec: Planning scan with bin packing, max size: 4194304 bytes, open cost is considered as scanning 4194304 bytes.\n",
      "25/06/27 09:21:17 INFO DAGScheduler: Registering RDD 82 (collect at /tmp/ipykernel_14560/3186139197.py:7) as input to shuffle 8\n",
      "25/06/27 09:21:17 INFO DAGScheduler: Got map stage job 15 (collect at /tmp/ipykernel_14560/3186139197.py:7) with 9 output partitions\n",
      "25/06/27 09:21:17 INFO DAGScheduler: Final stage: ShuffleMapStage 24 (collect at /tmp/ipykernel_14560/3186139197.py:7)\n",
      "25/06/27 09:21:17 INFO DAGScheduler: Parents of final stage: List()\n",
      "25/06/27 09:21:17 INFO DAGScheduler: Missing parents: List()\n",
      "25/06/27 09:21:17 INFO DAGScheduler: Submitting ShuffleMapStage 24 (MapPartitionsRDD[82] at collect at /tmp/ipykernel_14560/3186139197.py:7), which has no missing parents\n",
      "25/06/27 09:21:17 INFO MemoryStore: Block broadcast_29 stored as values in memory (estimated size 26.4 KiB, free 433.1 MiB)\n",
      "25/06/27 09:21:17 INFO MemoryStore: Block broadcast_29_piece0 stored as bytes in memory (estimated size 11.0 KiB, free 433.1 MiB)\n",
      "25/06/27 09:21:17 INFO BlockManagerInfo: Added broadcast_29_piece0 in memory on hal9000:34557 (size: 11.0 KiB, free: 434.2 MiB)\n",
      "25/06/27 09:21:17 INFO SparkContext: Created broadcast 29 from broadcast at DAGScheduler.scala:1535\n",
      "25/06/27 09:21:17 INFO DAGScheduler: Submitting 9 missing tasks from ShuffleMapStage 24 (MapPartitionsRDD[82] at collect at /tmp/ipykernel_14560/3186139197.py:7) (first 15 tasks are for partitions Vector(0, 1, 2, 3, 4, 5, 6, 7, 8))\n",
      "25/06/27 09:21:17 INFO TaskSchedulerImpl: Adding task set 24.0 with 9 tasks resource profile 0\n",
      "25/06/27 09:21:17 INFO TaskSetManager: Starting task 0.0 in stage 24.0 (TID 166) (hal9000, executor driver, partition 0, PROCESS_LOCAL, 8005 bytes) \n",
      "25/06/27 09:21:17 INFO TaskSetManager: Starting task 1.0 in stage 24.0 (TID 167) (hal9000, executor driver, partition 1, PROCESS_LOCAL, 8005 bytes) \n",
      "25/06/27 09:21:17 INFO TaskSetManager: Starting task 2.0 in stage 24.0 (TID 168) (hal9000, executor driver, partition 2, PROCESS_LOCAL, 8005 bytes) \n",
      "25/06/27 09:21:17 INFO TaskSetManager: Starting task 3.0 in stage 24.0 (TID 169) (hal9000, executor driver, partition 3, PROCESS_LOCAL, 8005 bytes) \n",
      "25/06/27 09:21:17 INFO TaskSetManager: Starting task 4.0 in stage 24.0 (TID 170) (hal9000, executor driver, partition 4, PROCESS_LOCAL, 8005 bytes) \n",
      "25/06/27 09:21:17 INFO TaskSetManager: Starting task 5.0 in stage 24.0 (TID 171) (hal9000, executor driver, partition 5, PROCESS_LOCAL, 8005 bytes) \n",
      "25/06/27 09:21:17 INFO TaskSetManager: Starting task 6.0 in stage 24.0 (TID 172) (hal9000, executor driver, partition 6, PROCESS_LOCAL, 8005 bytes) \n",
      "25/06/27 09:21:17 INFO TaskSetManager: Starting task 7.0 in stage 24.0 (TID 173) (hal9000, executor driver, partition 7, PROCESS_LOCAL, 8005 bytes) \n",
      "25/06/27 09:21:17 INFO Executor: Running task 0.0 in stage 24.0 (TID 166)\n",
      "25/06/27 09:21:17 INFO Executor: Running task 5.0 in stage 24.0 (TID 171)\n",
      "25/06/27 09:21:17 INFO Executor: Running task 7.0 in stage 24.0 (TID 173)\n",
      "25/06/27 09:21:17 INFO Executor: Running task 3.0 in stage 24.0 (TID 169)\n",
      "25/06/27 09:21:17 INFO Executor: Running task 6.0 in stage 24.0 (TID 172)\n",
      "25/06/27 09:21:17 INFO Executor: Running task 4.0 in stage 24.0 (TID 170)\n",
      "25/06/27 09:21:17 INFO Executor: Running task 2.0 in stage 24.0 (TID 168)\n",
      "25/06/27 09:21:17 INFO Executor: Running task 1.0 in stage 24.0 (TID 167)\n",
      "25/06/27 09:21:17 INFO FileScanRDD: Reading File path: s3a://datalake/cancer-1.csv, range: 77170891-84001007, partition values: [empty row]\n",
      "25/06/27 09:21:17 INFO FileScanRDD: Reading File path: s3a://datalake/cancer-1.csv, range: 44097652-55122065, partition values: [empty row]\n",
      "25/06/27 09:21:17 INFO FileScanRDD: Reading File path: s3a://datalake/cancer-1.csv, range: 55122065-66146478, partition values: [empty row]\n",
      "25/06/27 09:21:17 INFO FileScanRDD: Reading File path: s3a://datalake/cancer-1.csv, range: 11024413-22048826, partition values: [empty row]\n",
      "25/06/27 09:21:17 INFO FileScanRDD: Reading File path: s3a://datalake/cancer-1.csv, range: 33073239-44097652, partition values: [empty row]\n",
      "25/06/27 09:21:17 INFO FileScanRDD: Reading File path: s3a://datalake/cancer-1.csv, range: 0-11024413, partition values: [empty row]\n",
      "25/06/27 09:21:17 INFO FileScanRDD: Reading File path: s3a://datalake/cancer-1.csv, range: 22048826-33073239, partition values: [empty row]\n",
      "25/06/27 09:21:17 INFO FileScanRDD: Reading File path: s3a://datalake/cancer-1.csv, range: 66146478-77170891, partition values: [empty row]\n",
      "25/06/27 09:21:17 INFO CodeGenerator: Code generated in 20.38661 ms\n",
      "25/06/27 09:21:17 INFO CodeGenerator: Code generated in 9.437014 ms\n",
      "25/06/27 09:21:18 INFO BlockManagerInfo: Removed broadcast_26_piece0 on hal9000:34557 in memory (size: 19.7 KiB, free: 434.2 MiB)\n",
      "25/06/27 09:21:18 INFO Executor: Finished task 6.0 in stage 24.0 (TID 172). 2246 bytes result sent to driver\n",
      "25/06/27 09:21:18 INFO TaskSetManager: Starting task 8.0 in stage 24.0 (TID 174) (hal9000, executor driver, partition 8, PROCESS_LOCAL, 8005 bytes) \n",
      "25/06/27 09:21:18 INFO Executor: Running task 8.0 in stage 24.0 (TID 174)\n",
      "25/06/27 09:21:18 INFO TaskSetManager: Finished task 6.0 in stage 24.0 (TID 172) in 1083 ms on hal9000 (executor driver) (1/9)\n",
      "25/06/27 09:21:18 INFO FileScanRDD: Reading File path: s3a://datalake/cancer-2.csv, range: 0-3668986, partition values: [empty row]\n",
      "25/06/27 09:21:18 INFO Executor: Finished task 5.0 in stage 24.0 (TID 171). 2246 bytes result sent to driver\n",
      "25/06/27 09:21:18 INFO TaskSetManager: Finished task 5.0 in stage 24.0 (TID 171) in 1162 ms on hal9000 (executor driver) (2/9)\n",
      "25/06/27 09:21:19 INFO Executor: Finished task 7.0 in stage 24.0 (TID 173). 2289 bytes result sent to driver\n",
      "25/06/27 09:21:19 INFO TaskSetManager: Finished task 7.0 in stage 24.0 (TID 173) in 1265 ms on hal9000 (executor driver) (3/9)\n",
      "25/06/27 09:21:19 INFO Executor: Finished task 3.0 in stage 24.0 (TID 169). 2246 bytes result sent to driver\n",
      "25/06/27 09:21:19 INFO TaskSetManager: Finished task 3.0 in stage 24.0 (TID 169) in 1302 ms on hal9000 (executor driver) (4/9)\n",
      "25/06/27 09:21:19 INFO Executor: Finished task 2.0 in stage 24.0 (TID 168). 2246 bytes result sent to driver\n",
      "25/06/27 09:21:19 INFO TaskSetManager: Finished task 2.0 in stage 24.0 (TID 168) in 1352 ms on hal9000 (executor driver) (5/9)\n",
      "25/06/27 09:21:19 INFO Executor: Finished task 8.0 in stage 24.0 (TID 174). 2203 bytes result sent to driver\n",
      "25/06/27 09:21:19 INFO TaskSetManager: Finished task 8.0 in stage 24.0 (TID 174) in 394 ms on hal9000 (executor driver) (6/9)\n",
      "25/06/27 09:21:19 INFO Executor: Finished task 4.0 in stage 24.0 (TID 170). 2246 bytes result sent to driver\n",
      "25/06/27 09:21:19 INFO TaskSetManager: Finished task 4.0 in stage 24.0 (TID 170) in 1491 ms on hal9000 (executor driver) (7/9)\n",
      "25/06/27 09:21:19 INFO Executor: Finished task 0.0 in stage 24.0 (TID 166). 2246 bytes result sent to driver\n",
      "25/06/27 09:21:19 INFO TaskSetManager: Finished task 0.0 in stage 24.0 (TID 166) in 1619 ms on hal9000 (executor driver) (8/9)\n",
      "25/06/27 09:21:19 INFO Executor: Finished task 1.0 in stage 24.0 (TID 167). 2246 bytes result sent to driver\n",
      "25/06/27 09:21:19 INFO TaskSetManager: Finished task 1.0 in stage 24.0 (TID 167) in 1622 ms on hal9000 (executor driver) (9/9)\n",
      "25/06/27 09:21:19 INFO TaskSchedulerImpl: Removed TaskSet 24.0, whose tasks have all completed, from pool \n",
      "25/06/27 09:21:19 INFO DAGScheduler: ShuffleMapStage 24 (collect at /tmp/ipykernel_14560/3186139197.py:7) finished in 1.662 s\n",
      "25/06/27 09:21:19 INFO DAGScheduler: looking for newly runnable stages\n",
      "25/06/27 09:21:19 INFO DAGScheduler: running: Set()\n",
      "25/06/27 09:21:19 INFO DAGScheduler: waiting: Set()\n",
      "25/06/27 09:21:19 INFO DAGScheduler: failed: Set()\n",
      "25/06/27 09:21:19 INFO CodeGenerator: Code generated in 24.018461 ms\n",
      "25/06/27 09:21:19 INFO SparkContext: Starting job: collect at /tmp/ipykernel_14560/3186139197.py:7\n",
      "25/06/27 09:21:19 INFO DAGScheduler: Got job 16 (collect at /tmp/ipykernel_14560/3186139197.py:7) with 1 output partitions\n",
      "25/06/27 09:21:19 INFO DAGScheduler: Final stage: ResultStage 26 (collect at /tmp/ipykernel_14560/3186139197.py:7)\n",
      "25/06/27 09:21:19 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 25)\n",
      "25/06/27 09:21:19 INFO DAGScheduler: Missing parents: List()\n",
      "25/06/27 09:21:19 INFO DAGScheduler: Submitting ResultStage 26 (MapPartitionsRDD[85] at collect at /tmp/ipykernel_14560/3186139197.py:7), which has no missing parents\n",
      "25/06/27 09:21:19 INFO MemoryStore: Block broadcast_30 stored as values in memory (estimated size 13.4 KiB, free 433.1 MiB)\n",
      "25/06/27 09:21:19 INFO MemoryStore: Block broadcast_30_piece0 stored as bytes in memory (estimated size 6.3 KiB, free 433.1 MiB)\n",
      "25/06/27 09:21:19 INFO BlockManagerInfo: Added broadcast_30_piece0 in memory on hal9000:34557 (size: 6.3 KiB, free: 434.2 MiB)\n",
      "25/06/27 09:21:19 INFO SparkContext: Created broadcast 30 from broadcast at DAGScheduler.scala:1535\n",
      "25/06/27 09:21:19 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 26 (MapPartitionsRDD[85] at collect at /tmp/ipykernel_14560/3186139197.py:7) (first 15 tasks are for partitions Vector(0))\n",
      "25/06/27 09:21:19 INFO TaskSchedulerImpl: Adding task set 26.0 with 1 tasks resource profile 0\n",
      "25/06/27 09:21:19 INFO TaskSetManager: Starting task 0.0 in stage 26.0 (TID 175) (hal9000, executor driver, partition 0, NODE_LOCAL, 7363 bytes) \n",
      "25/06/27 09:21:19 INFO Executor: Running task 0.0 in stage 26.0 (TID 175)\n",
      "25/06/27 09:21:19 INFO ShuffleBlockFetcherIterator: Getting 9 (540.0 B) non-empty blocks including 9 (540.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks\n",
      "25/06/27 09:21:19 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms\n",
      "25/06/27 09:21:19 INFO Executor: Finished task 0.0 in stage 26.0 (TID 175). 3995 bytes result sent to driver\n",
      "25/06/27 09:21:19 INFO TaskSetManager: Finished task 0.0 in stage 26.0 (TID 175) in 18 ms on hal9000 (executor driver) (1/1)\n",
      "25/06/27 09:21:19 INFO TaskSchedulerImpl: Removed TaskSet 26.0, whose tasks have all completed, from pool \n",
      "25/06/27 09:21:19 INFO DAGScheduler: ResultStage 26 (collect at /tmp/ipykernel_14560/3186139197.py:7) finished in 0.028 s\n",
      "25/06/27 09:21:19 INFO DAGScheduler: Job 16 is finished. Cancelling potential speculative or zombie tasks for this job\n",
      "25/06/27 09:21:19 INFO TaskSchedulerImpl: Killing all running tasks in stage 26: Stage finished\n",
      "25/06/27 09:21:19 INFO DAGScheduler: Job 16 finished: collect at /tmp/ipykernel_14560/3186139197.py:7, took 0.032647 s\n",
      "25/06/27 09:21:20 INFO FileSourceStrategy: Pushed Filters: IsNotNull(metric_name),EqualTo(metric_name,Número)\n",
      "25/06/27 09:21:20 INFO FileSourceStrategy: Post-Scan Filters: isnotnull(metric_name#11),(metric_name#11 = Número)\n",
      "25/06/27 09:21:20 INFO FileSourceStrategy: Pushed Filters: IsNotNull(metric_name),EqualTo(metric_name,Número)\n",
      "25/06/27 09:21:20 INFO FileSourceStrategy: Post-Scan Filters: isnotnull(metric_name#43),(metric_name#43 = Número)\n",
      "25/06/27 09:21:20 INFO CodeGenerator: Code generated in 108.557281 ms\n",
      "25/06/27 09:21:20 INFO CodeGenerator: Code generated in 12.05161 ms\n",
      "25/06/27 09:21:20 INFO MemoryStore: Block broadcast_31 stored as values in memory (estimated size 203.2 KiB, free 432.9 MiB)\n",
      "25/06/27 09:21:20 INFO MemoryStore: Block broadcast_31_piece0 stored as bytes in memory (estimated size 35.4 KiB, free 432.9 MiB)\n",
      "25/06/27 09:21:20 INFO BlockManagerInfo: Added broadcast_31_piece0 in memory on hal9000:34557 (size: 35.4 KiB, free: 434.2 MiB)\n",
      "25/06/27 09:21:20 INFO SparkContext: Created broadcast 31 from showString at NativeMethodAccessorImpl.java:0\n",
      "25/06/27 09:21:20 INFO FileSourceScanExec: Planning scan with bin packing, max size: 11024413 bytes, open cost is considered as scanning 4194304 bytes.\n",
      "25/06/27 09:21:20 INFO CodeGenerator: Code generated in 7.803363 ms\n",
      "25/06/27 09:21:20 INFO MemoryStore: Block broadcast_32 stored as values in memory (estimated size 203.2 KiB, free 432.7 MiB)\n",
      "25/06/27 09:21:20 INFO MemoryStore: Block broadcast_32_piece0 stored as bytes in memory (estimated size 35.4 KiB, free 432.7 MiB)\n",
      "25/06/27 09:21:20 INFO BlockManagerInfo: Added broadcast_32_piece0 in memory on hal9000:34557 (size: 35.4 KiB, free: 434.1 MiB)\n",
      "25/06/27 09:21:20 INFO SparkContext: Created broadcast 32 from showString at NativeMethodAccessorImpl.java:0\n",
      "25/06/27 09:21:20 INFO FileSourceScanExec: Planning scan with bin packing, max size: 4194304 bytes, open cost is considered as scanning 4194304 bytes.\n",
      "25/06/27 09:21:20 INFO DAGScheduler: Registering RDD 94 (showString at NativeMethodAccessorImpl.java:0) as input to shuffle 9\n",
      "25/06/27 09:21:20 INFO DAGScheduler: Got map stage job 17 (showString at NativeMethodAccessorImpl.java:0) with 9 output partitions\n",
      "25/06/27 09:21:20 INFO DAGScheduler: Final stage: ShuffleMapStage 27 (showString at NativeMethodAccessorImpl.java:0)\n",
      "25/06/27 09:21:20 INFO DAGScheduler: Parents of final stage: List()\n",
      "25/06/27 09:21:20 INFO DAGScheduler: Missing parents: List()\n",
      "25/06/27 09:21:20 INFO DAGScheduler: Submitting ShuffleMapStage 27 (MapPartitionsRDD[94] at showString at NativeMethodAccessorImpl.java:0), which has no missing parents\n",
      "25/06/27 09:21:20 INFO MemoryStore: Block broadcast_33 stored as values in memory (estimated size 56.3 KiB, free 432.6 MiB)\n",
      "25/06/27 09:21:20 INFO MemoryStore: Block broadcast_33_piece0 stored as bytes in memory (estimated size 23.5 KiB, free 432.6 MiB)\n",
      "25/06/27 09:21:20 INFO BlockManagerInfo: Added broadcast_33_piece0 in memory on hal9000:34557 (size: 23.5 KiB, free: 434.1 MiB)\n",
      "25/06/27 09:21:20 INFO SparkContext: Created broadcast 33 from broadcast at DAGScheduler.scala:1535\n",
      "25/06/27 09:21:20 INFO DAGScheduler: Submitting 9 missing tasks from ShuffleMapStage 27 (MapPartitionsRDD[94] at showString at NativeMethodAccessorImpl.java:0) (first 15 tasks are for partitions Vector(0, 1, 2, 3, 4, 5, 6, 7, 8))\n",
      "25/06/27 09:21:20 INFO TaskSchedulerImpl: Adding task set 27.0 with 9 tasks resource profile 0\n",
      "25/06/27 09:21:20 INFO TaskSetManager: Starting task 0.0 in stage 27.0 (TID 176) (hal9000, executor driver, partition 0, PROCESS_LOCAL, 8005 bytes) \n",
      "25/06/27 09:21:20 INFO TaskSetManager: Starting task 1.0 in stage 27.0 (TID 177) (hal9000, executor driver, partition 1, PROCESS_LOCAL, 8005 bytes) \n",
      "25/06/27 09:21:20 INFO TaskSetManager: Starting task 2.0 in stage 27.0 (TID 178) (hal9000, executor driver, partition 2, PROCESS_LOCAL, 8005 bytes) \n",
      "25/06/27 09:21:20 INFO TaskSetManager: Starting task 3.0 in stage 27.0 (TID 179) (hal9000, executor driver, partition 3, PROCESS_LOCAL, 8005 bytes) \n",
      "25/06/27 09:21:20 INFO TaskSetManager: Starting task 4.0 in stage 27.0 (TID 180) (hal9000, executor driver, partition 4, PROCESS_LOCAL, 8005 bytes) \n",
      "25/06/27 09:21:20 INFO TaskSetManager: Starting task 5.0 in stage 27.0 (TID 181) (hal9000, executor driver, partition 5, PROCESS_LOCAL, 8005 bytes) \n",
      "25/06/27 09:21:20 INFO TaskSetManager: Starting task 6.0 in stage 27.0 (TID 182) (hal9000, executor driver, partition 6, PROCESS_LOCAL, 8005 bytes) \n",
      "25/06/27 09:21:20 INFO TaskSetManager: Starting task 7.0 in stage 27.0 (TID 183) (hal9000, executor driver, partition 7, PROCESS_LOCAL, 8005 bytes) \n",
      "25/06/27 09:21:20 INFO Executor: Running task 2.0 in stage 27.0 (TID 178)\n",
      "25/06/27 09:21:20 INFO Executor: Running task 3.0 in stage 27.0 (TID 179)\n",
      "25/06/27 09:21:20 INFO Executor: Running task 0.0 in stage 27.0 (TID 176)\n",
      "25/06/27 09:21:20 INFO Executor: Running task 1.0 in stage 27.0 (TID 177)\n",
      "25/06/27 09:21:20 INFO Executor: Running task 4.0 in stage 27.0 (TID 180)\n",
      "25/06/27 09:21:20 INFO Executor: Running task 6.0 in stage 27.0 (TID 182)\n",
      "25/06/27 09:21:20 INFO Executor: Running task 5.0 in stage 27.0 (TID 181)\n",
      "25/06/27 09:21:20 INFO Executor: Running task 7.0 in stage 27.0 (TID 183)\n",
      "25/06/27 09:21:20 INFO CodeGenerator: Code generated in 27.66729 ms\n",
      "25/06/27 09:21:20 INFO CodeGenerator: Code generated in 28.964821 ms\n",
      "25/06/27 09:21:20 INFO FileScanRDD: Reading File path: s3a://datalake/cancer-1.csv, range: 44097652-55122065, partition values: [empty row]\n",
      "25/06/27 09:21:20 INFO FileScanRDD: Reading File path: s3a://datalake/cancer-1.csv, range: 55122065-66146478, partition values: [empty row]\n",
      "25/06/27 09:21:20 INFO FileScanRDD: Reading File path: s3a://datalake/cancer-1.csv, range: 33073239-44097652, partition values: [empty row]\n",
      "25/06/27 09:21:20 INFO FileScanRDD: Reading File path: s3a://datalake/cancer-1.csv, range: 11024413-22048826, partition values: [empty row]\n",
      "25/06/27 09:21:20 INFO FileScanRDD: Reading File path: s3a://datalake/cancer-1.csv, range: 22048826-33073239, partition values: [empty row]\n",
      "25/06/27 09:21:20 INFO FileScanRDD: Reading File path: s3a://datalake/cancer-1.csv, range: 66146478-77170891, partition values: [empty row]\n",
      "25/06/27 09:21:20 INFO FileScanRDD: Reading File path: s3a://datalake/cancer-1.csv, range: 77170891-84001007, partition values: [empty row]\n",
      "25/06/27 09:21:20 INFO FileScanRDD: Reading File path: s3a://datalake/cancer-1.csv, range: 0-11024413, partition values: [empty row]\n",
      "25/06/27 09:21:20 INFO CodeGenerator: Code generated in 20.56873 ms\n",
      "25/06/27 09:21:20 INFO CodeGenerator: Code generated in 12.809316 ms\n",
      "25/06/27 09:21:21 INFO BlockManagerInfo: Removed broadcast_30_piece0 on hal9000:34557 in memory (size: 6.3 KiB, free: 434.1 MiB)\n",
      "25/06/27 09:21:21 INFO BlockManagerInfo: Removed broadcast_27_piece0 on hal9000:34557 in memory (size: 35.4 KiB, free: 434.1 MiB)\n",
      "25/06/27 09:21:21 INFO BlockManagerInfo: Removed broadcast_28_piece0 on hal9000:34557 in memory (size: 35.4 KiB, free: 434.2 MiB)\n",
      "25/06/27 09:21:21 INFO BlockManagerInfo: Removed broadcast_29_piece0 on hal9000:34557 in memory (size: 11.0 KiB, free: 434.2 MiB)\n",
      "25/06/27 09:21:21 INFO Executor: Finished task 7.0 in stage 27.0 (TID 183). 3208 bytes result sent to driver\n",
      "25/06/27 09:21:21 INFO TaskSetManager: Starting task 8.0 in stage 27.0 (TID 184) (hal9000, executor driver, partition 8, PROCESS_LOCAL, 8005 bytes) \n",
      "25/06/27 09:21:21 INFO TaskSetManager: Finished task 7.0 in stage 27.0 (TID 183) in 912 ms on hal9000 (executor driver) (1/9)\n",
      "25/06/27 09:21:21 INFO Executor: Running task 8.0 in stage 27.0 (TID 184)\n",
      "25/06/27 09:21:21 INFO FileScanRDD: Reading File path: s3a://datalake/cancer-2.csv, range: 0-3668986, partition values: [empty row]\n",
      "25/06/27 09:21:21 INFO Executor: Finished task 0.0 in stage 27.0 (TID 176). 3208 bytes result sent to driver\n",
      "25/06/27 09:21:21 INFO TaskSetManager: Finished task 0.0 in stage 27.0 (TID 176) in 1121 ms on hal9000 (executor driver) (2/9)\n",
      "25/06/27 09:21:21 INFO Executor: Finished task 8.0 in stage 27.0 (TID 184). 3208 bytes result sent to driver\n",
      "25/06/27 09:21:21 INFO TaskSetManager: Finished task 8.0 in stage 27.0 (TID 184) in 587 ms on hal9000 (executor driver) (3/9)\n",
      "25/06/27 09:21:21 INFO Executor: Finished task 1.0 in stage 27.0 (TID 177). 3208 bytes result sent to driver\n",
      "25/06/27 09:21:21 INFO TaskSetManager: Finished task 1.0 in stage 27.0 (TID 177) in 1546 ms on hal9000 (executor driver) (4/9)\n",
      "25/06/27 09:21:22 INFO Executor: Finished task 4.0 in stage 27.0 (TID 180). 3208 bytes result sent to driver\n",
      "25/06/27 09:21:22 INFO TaskSetManager: Finished task 4.0 in stage 27.0 (TID 180) in 1701 ms on hal9000 (executor driver) (5/9)\n",
      "25/06/27 09:21:22 INFO Executor: Finished task 6.0 in stage 27.0 (TID 182). 3208 bytes result sent to driver\n",
      "25/06/27 09:21:22 INFO TaskSetManager: Finished task 6.0 in stage 27.0 (TID 182) in 1743 ms on hal9000 (executor driver) (6/9)\n",
      "25/06/27 09:21:22 INFO Executor: Finished task 5.0 in stage 27.0 (TID 181). 3208 bytes result sent to driver\n",
      "25/06/27 09:21:22 INFO TaskSetManager: Finished task 5.0 in stage 27.0 (TID 181) in 1772 ms on hal9000 (executor driver) (7/9)\n",
      "25/06/27 09:21:22 INFO Executor: Finished task 3.0 in stage 27.0 (TID 179). 3208 bytes result sent to driver\n",
      "25/06/27 09:21:22 INFO TaskSetManager: Finished task 3.0 in stage 27.0 (TID 179) in 1846 ms on hal9000 (executor driver) (8/9)\n",
      "25/06/27 09:21:22 INFO Executor: Finished task 2.0 in stage 27.0 (TID 178). 3208 bytes result sent to driver\n",
      "25/06/27 09:21:22 INFO TaskSetManager: Finished task 2.0 in stage 27.0 (TID 178) in 1855 ms on hal9000 (executor driver) (9/9)\n",
      "25/06/27 09:21:22 INFO TaskSchedulerImpl: Removed TaskSet 27.0, whose tasks have all completed, from pool \n",
      "25/06/27 09:21:22 INFO DAGScheduler: ShuffleMapStage 27 (showString at NativeMethodAccessorImpl.java:0) finished in 1.870 s\n",
      "25/06/27 09:21:22 INFO DAGScheduler: looking for newly runnable stages\n",
      "25/06/27 09:21:22 INFO DAGScheduler: running: Set()\n",
      "25/06/27 09:21:22 INFO DAGScheduler: waiting: Set()\n",
      "25/06/27 09:21:22 INFO DAGScheduler: failed: Set()\n",
      "25/06/27 09:21:22 INFO ShufflePartitionsUtil: For shuffle(9), advisory target size: 67108864, actual target size 1048576, minimum partition size: 1048576\n",
      "25/06/27 09:21:22 INFO HashAggregateExec: spark.sql.codegen.aggregate.map.twolevel.enabled is set to true, but current version of codegened fast hashmap does not support this aggregate.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------+------------------------------------------------------------+-----------+---------------------+\n",
      "|tipo_cancer_pk|tipo_cancer                                                 |mortalidade|taxa_incidencia_total|\n",
      "+--------------+------------------------------------------------------------+-----------+---------------------+\n",
      "|0             |Melanoma maligno da pele                                    |10.89      |9.49                 |\n",
      "|1             |Câncer de pele não melanoma (carcinoma de células escamosas)|14.89      |7.76                 |\n",
      "|2             |Câncer de pele não melanoma (carcinoma basocelular)         |0.0        |80.57                |\n",
      "+--------------+------------------------------------------------------------+-----------+---------------------+\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "25/06/27 09:21:22 INFO CodeGenerator: Code generated in 69.01351 ms\n",
      "25/06/27 09:21:22 INFO SparkContext: Starting job: showString at NativeMethodAccessorImpl.java:0\n",
      "25/06/27 09:21:22 INFO DAGScheduler: Got job 18 (showString at NativeMethodAccessorImpl.java:0) with 1 output partitions\n",
      "25/06/27 09:21:22 INFO DAGScheduler: Final stage: ResultStage 29 (showString at NativeMethodAccessorImpl.java:0)\n",
      "25/06/27 09:21:22 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 28)\n",
      "25/06/27 09:21:22 INFO DAGScheduler: Missing parents: List()\n",
      "25/06/27 09:21:22 INFO DAGScheduler: Submitting ResultStage 29 (MapPartitionsRDD[97] at showString at NativeMethodAccessorImpl.java:0), which has no missing parents\n",
      "25/06/27 09:21:22 INFO MemoryStore: Block broadcast_34 stored as values in memory (estimated size 59.8 KiB, free 433.0 MiB)\n",
      "25/06/27 09:21:22 INFO MemoryStore: Block broadcast_34_piece0 stored as bytes in memory (estimated size 26.1 KiB, free 433.0 MiB)\n",
      "25/06/27 09:21:22 INFO BlockManagerInfo: Added broadcast_34_piece0 in memory on hal9000:34557 (size: 26.1 KiB, free: 434.2 MiB)\n",
      "25/06/27 09:21:22 INFO SparkContext: Created broadcast 34 from broadcast at DAGScheduler.scala:1535\n",
      "25/06/27 09:21:22 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 29 (MapPartitionsRDD[97] at showString at NativeMethodAccessorImpl.java:0) (first 15 tasks are for partitions Vector(0))\n",
      "25/06/27 09:21:22 INFO TaskSchedulerImpl: Adding task set 29.0 with 1 tasks resource profile 0\n",
      "25/06/27 09:21:22 INFO TaskSetManager: Starting task 0.0 in stage 29.0 (TID 185) (hal9000, executor driver, partition 0, NODE_LOCAL, 7363 bytes) \n",
      "25/06/27 09:21:22 INFO Executor: Running task 0.0 in stage 29.0 (TID 185)\n",
      "25/06/27 09:21:22 INFO ShuffleBlockFetcherIterator: Getting 9 (3.0 KiB) non-empty blocks including 9 (3.0 KiB) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks\n",
      "25/06/27 09:21:22 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms\n",
      "25/06/27 09:21:22 INFO Executor: Finished task 0.0 in stage 29.0 (TID 185). 5760 bytes result sent to driver\n",
      "25/06/27 09:21:22 INFO TaskSetManager: Finished task 0.0 in stage 29.0 (TID 185) in 58 ms on hal9000 (executor driver) (1/1)\n",
      "25/06/27 09:21:22 INFO TaskSchedulerImpl: Removed TaskSet 29.0, whose tasks have all completed, from pool \n",
      "25/06/27 09:21:22 INFO DAGScheduler: ResultStage 29 (showString at NativeMethodAccessorImpl.java:0) finished in 0.080 s\n",
      "25/06/27 09:21:22 INFO DAGScheduler: Job 18 is finished. Cancelling potential speculative or zombie tasks for this job\n",
      "25/06/27 09:21:22 INFO TaskSchedulerImpl: Killing all running tasks in stage 29: Stage finished\n",
      "25/06/27 09:21:22 INFO DAGScheduler: Job 18 finished: showString at NativeMethodAccessorImpl.java:0, took 0.089053 s\n",
      "25/06/27 09:21:22 INFO CodeGenerator: Code generated in 28.778438 ms            \n"
     ]
    }
   ],
   "source": [
    "# Transformção da Dimensão Tipo de Cancer\n",
    "\n",
    "# Os campos 'mortalidade' e 'taxa_incidencia_total' são derivados dos proprios dados \n",
    "\n",
    "total_casos = df_cancer.filter(F.col(\"metric_name\") == \"Número\") \\\n",
    "    .agg(F.sum(\"val\").alias(\"total_casos_geral\")) \\\n",
    "    .collect()[0][\"total_casos_geral\"]\n",
    "\n",
    "df_tipo_cancer = (\n",
    "    df_cancer.filter(F.col(\"metric_name\") == \"Número\") \n",
    "            .groupBy(\"cause_name\")\n",
    "            .agg(\n",
    "                F.sum(F.when(F.col(\"measure_name\") == \"Óbitos\", F.col(\"val\")).otherwise(0)).alias(\"total_obitos\"),\n",
    "                F.sum(F.when(F.col(\"measure_name\") != \"Óbitos\", F.col(\"val\")).otherwise(0)).alias(\"total_casos\")\n",
    "            ) \n",
    "            .withColumn(\n",
    "                \"mortalidade\",\n",
    "                F.round(F.when(F.col(\"total_casos\") > 0, (F.col(\"total_obitos\") / F.col(\"total_casos\")) * 100).otherwise(0),2)\n",
    "            ) \n",
    "            .withColumn(\n",
    "                \"taxa_incidencia_total\",\n",
    "                F.round((F.col(\"total_casos\") / F.lit(total_casos)) * 100, 2)\n",
    "            ) \n",
    "            .withColumn(\n",
    "                \"tipo_cancer_pk\",\n",
    "                F.monotonically_increasing_id()\n",
    "            ) \n",
    "            .select(\n",
    "                \"tipo_cancer_pk\",\n",
    "                F.col(\"cause_name\").alias(\"tipo_cancer\"),\n",
    "                \"mortalidade\",\n",
    "                \"taxa_incidencia_total\"\n",
    "            )\n",
    ")\n",
    "\n",
    "df_tipo_cancer.show(truncate=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "4bfd1a24",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "25/06/27 09:21:22 INFO FileSourceStrategy: Pushed Filters: \n",
      "25/06/27 09:21:22 INFO FileSourceStrategy: Post-Scan Filters: \n",
      "25/06/27 09:21:22 INFO FileSourceStrategy: Pushed Filters: \n",
      "25/06/27 09:21:22 INFO FileSourceStrategy: Post-Scan Filters: \n",
      "25/06/27 09:21:23 INFO HashAggregateExec: spark.sql.codegen.aggregate.map.twolevel.enabled is set to true, but current version of codegened fast hashmap does not support this aggregate.\n",
      "25/06/27 09:21:23 INFO CodeGenerator: Code generated in 14.387454 ms\n",
      "25/06/27 09:21:23 INFO CodeGenerator: Code generated in 24.999153 ms\n",
      "25/06/27 09:21:23 INFO MemoryStore: Block broadcast_35 stored as values in memory (estimated size 203.2 KiB, free 432.8 MiB)\n",
      "25/06/27 09:21:23 INFO MemoryStore: Block broadcast_35_piece0 stored as bytes in memory (estimated size 35.4 KiB, free 432.8 MiB)\n",
      "25/06/27 09:21:23 INFO BlockManagerInfo: Added broadcast_35_piece0 in memory on hal9000:34557 (size: 35.4 KiB, free: 434.1 MiB)\n",
      "25/06/27 09:21:23 INFO SparkContext: Created broadcast 35 from showString at NativeMethodAccessorImpl.java:0\n",
      "25/06/27 09:21:23 INFO FileSourceScanExec: Planning scan with bin packing, max size: 11024413 bytes, open cost is considered as scanning 4194304 bytes.\n",
      "25/06/27 09:21:23 INFO CodeGenerator: Code generated in 31.662475 ms\n",
      "25/06/27 09:21:23 INFO MemoryStore: Block broadcast_36 stored as values in memory (estimated size 203.2 KiB, free 432.6 MiB)\n",
      "25/06/27 09:21:23 INFO MemoryStore: Block broadcast_36_piece0 stored as bytes in memory (estimated size 35.4 KiB, free 432.6 MiB)\n",
      "25/06/27 09:21:23 INFO BlockManagerInfo: Added broadcast_36_piece0 in memory on hal9000:34557 (size: 35.4 KiB, free: 434.1 MiB)\n",
      "25/06/27 09:21:23 INFO SparkContext: Created broadcast 36 from showString at NativeMethodAccessorImpl.java:0\n",
      "25/06/27 09:21:23 INFO FileSourceScanExec: Planning scan with bin packing, max size: 4194304 bytes, open cost is considered as scanning 4194304 bytes.\n",
      "25/06/27 09:21:23 INFO DAGScheduler: Registering RDD 106 (showString at NativeMethodAccessorImpl.java:0) as input to shuffle 10\n",
      "25/06/27 09:21:23 INFO DAGScheduler: Got map stage job 19 (showString at NativeMethodAccessorImpl.java:0) with 9 output partitions\n",
      "25/06/27 09:21:23 INFO DAGScheduler: Final stage: ShuffleMapStage 30 (showString at NativeMethodAccessorImpl.java:0)\n",
      "25/06/27 09:21:23 INFO DAGScheduler: Parents of final stage: List()\n",
      "25/06/27 09:21:23 INFO DAGScheduler: Missing parents: List()\n",
      "25/06/27 09:21:23 INFO DAGScheduler: Submitting ShuffleMapStage 30 (MapPartitionsRDD[106] at showString at NativeMethodAccessorImpl.java:0), which has no missing parents\n",
      "25/06/27 09:21:23 INFO MemoryStore: Block broadcast_37 stored as values in memory (estimated size 39.8 KiB, free 432.5 MiB)\n",
      "25/06/27 09:21:23 INFO MemoryStore: Block broadcast_37_piece0 stored as bytes in memory (estimated size 17.6 KiB, free 432.5 MiB)\n",
      "25/06/27 09:21:23 INFO BlockManagerInfo: Added broadcast_37_piece0 in memory on hal9000:34557 (size: 17.6 KiB, free: 434.1 MiB)\n",
      "25/06/27 09:21:23 INFO SparkContext: Created broadcast 37 from broadcast at DAGScheduler.scala:1535\n",
      "25/06/27 09:21:23 INFO DAGScheduler: Submitting 9 missing tasks from ShuffleMapStage 30 (MapPartitionsRDD[106] at showString at NativeMethodAccessorImpl.java:0) (first 15 tasks are for partitions Vector(0, 1, 2, 3, 4, 5, 6, 7, 8))\n",
      "25/06/27 09:21:23 INFO TaskSchedulerImpl: Adding task set 30.0 with 9 tasks resource profile 0\n",
      "25/06/27 09:21:23 INFO TaskSetManager: Starting task 0.0 in stage 30.0 (TID 186) (hal9000, executor driver, partition 0, PROCESS_LOCAL, 8005 bytes) \n",
      "25/06/27 09:21:23 INFO TaskSetManager: Starting task 1.0 in stage 30.0 (TID 187) (hal9000, executor driver, partition 1, PROCESS_LOCAL, 8005 bytes) \n",
      "25/06/27 09:21:23 INFO TaskSetManager: Starting task 2.0 in stage 30.0 (TID 188) (hal9000, executor driver, partition 2, PROCESS_LOCAL, 8005 bytes) \n",
      "25/06/27 09:21:23 INFO TaskSetManager: Starting task 3.0 in stage 30.0 (TID 189) (hal9000, executor driver, partition 3, PROCESS_LOCAL, 8005 bytes) \n",
      "25/06/27 09:21:23 INFO TaskSetManager: Starting task 4.0 in stage 30.0 (TID 190) (hal9000, executor driver, partition 4, PROCESS_LOCAL, 8005 bytes) \n",
      "25/06/27 09:21:23 INFO TaskSetManager: Starting task 5.0 in stage 30.0 (TID 191) (hal9000, executor driver, partition 5, PROCESS_LOCAL, 8005 bytes) \n",
      "25/06/27 09:21:23 INFO TaskSetManager: Starting task 6.0 in stage 30.0 (TID 192) (hal9000, executor driver, partition 6, PROCESS_LOCAL, 8005 bytes) \n",
      "25/06/27 09:21:23 INFO TaskSetManager: Starting task 7.0 in stage 30.0 (TID 193) (hal9000, executor driver, partition 7, PROCESS_LOCAL, 8005 bytes) \n",
      "25/06/27 09:21:23 INFO Executor: Running task 5.0 in stage 30.0 (TID 191)\n",
      "25/06/27 09:21:23 INFO Executor: Running task 7.0 in stage 30.0 (TID 193)\n",
      "25/06/27 09:21:23 INFO Executor: Running task 2.0 in stage 30.0 (TID 188)\n",
      "25/06/27 09:21:23 INFO Executor: Running task 4.0 in stage 30.0 (TID 190)\n",
      "25/06/27 09:21:23 INFO Executor: Running task 0.0 in stage 30.0 (TID 186)\n",
      "25/06/27 09:21:23 INFO Executor: Running task 1.0 in stage 30.0 (TID 187)\n",
      "25/06/27 09:21:23 INFO Executor: Running task 3.0 in stage 30.0 (TID 189)\n",
      "25/06/27 09:21:23 INFO Executor: Running task 6.0 in stage 30.0 (TID 192)\n",
      "25/06/27 09:21:23 INFO CodeGenerator: Code generated in 28.493342 ms\n",
      "25/06/27 09:21:23 INFO CodeGenerator: Code generated in 6.812553 ms\n",
      "25/06/27 09:21:23 INFO FileScanRDD: Reading File path: s3a://datalake/cancer-1.csv, range: 33073239-44097652, partition values: [empty row]\n",
      "25/06/27 09:21:23 INFO FileScanRDD: Reading File path: s3a://datalake/cancer-1.csv, range: 66146478-77170891, partition values: [empty row]\n",
      "25/06/27 09:21:23 INFO FileScanRDD: Reading File path: s3a://datalake/cancer-1.csv, range: 0-11024413, partition values: [empty row]\n",
      "25/06/27 09:21:23 INFO FileScanRDD: Reading File path: s3a://datalake/cancer-1.csv, range: 55122065-66146478, partition values: [empty row]\n",
      "25/06/27 09:21:23 INFO FileScanRDD: Reading File path: s3a://datalake/cancer-1.csv, range: 22048826-33073239, partition values: [empty row]\n",
      "25/06/27 09:21:23 INFO FileScanRDD: Reading File path: s3a://datalake/cancer-1.csv, range: 44097652-55122065, partition values: [empty row]\n",
      "25/06/27 09:21:23 INFO FileScanRDD: Reading File path: s3a://datalake/cancer-1.csv, range: 77170891-84001007, partition values: [empty row]\n",
      "25/06/27 09:21:23 INFO FileScanRDD: Reading File path: s3a://datalake/cancer-1.csv, range: 11024413-22048826, partition values: [empty row]\n",
      "25/06/27 09:21:23 INFO BlockManagerInfo: Removed broadcast_31_piece0 on hal9000:34557 in memory (size: 35.4 KiB, free: 434.1 MiB)\n",
      "25/06/27 09:21:23 INFO BlockManagerInfo: Removed broadcast_34_piece0 on hal9000:34557 in memory (size: 26.1 KiB, free: 434.1 MiB)\n",
      "25/06/27 09:21:24 INFO BlockManagerInfo: Removed broadcast_32_piece0 on hal9000:34557 in memory (size: 35.4 KiB, free: 434.2 MiB)\n",
      "25/06/27 09:21:24 INFO BlockManagerInfo: Removed broadcast_33_piece0 on hal9000:34557 in memory (size: 23.5 KiB, free: 434.2 MiB)\n",
      "25/06/27 09:21:24 INFO Executor: Finished task 3.0 in stage 30.0 (TID 189). 3096 bytes result sent to driver\n",
      "25/06/27 09:21:24 INFO TaskSetManager: Starting task 8.0 in stage 30.0 (TID 194) (hal9000, executor driver, partition 8, PROCESS_LOCAL, 8005 bytes) \n",
      "25/06/27 09:21:24 INFO Executor: Running task 8.0 in stage 30.0 (TID 194)\n",
      "25/06/27 09:21:24 INFO TaskSetManager: Finished task 3.0 in stage 30.0 (TID 189) in 1103 ms on hal9000 (executor driver) (1/9)\n",
      "25/06/27 09:21:24 INFO Executor: Finished task 6.0 in stage 30.0 (TID 192). 3096 bytes result sent to driver\n",
      "25/06/27 09:21:24 INFO TaskSetManager: Finished task 6.0 in stage 30.0 (TID 192) in 1132 ms on hal9000 (executor driver) (2/9)\n",
      "25/06/27 09:21:24 INFO FileScanRDD: Reading File path: s3a://datalake/cancer-2.csv, range: 0-3668986, partition values: [empty row]\n",
      "25/06/27 09:21:24 INFO Executor: Finished task 7.0 in stage 30.0 (TID 193). 3096 bytes result sent to driver\n",
      "25/06/27 09:21:24 INFO TaskSetManager: Finished task 7.0 in stage 30.0 (TID 193) in 1239 ms on hal9000 (executor driver) (3/9)\n",
      "25/06/27 09:21:24 INFO Executor: Finished task 2.0 in stage 30.0 (TID 188). 3096 bytes result sent to driver\n",
      "25/06/27 09:21:24 INFO TaskSetManager: Finished task 2.0 in stage 30.0 (TID 188) in 1409 ms on hal9000 (executor driver) (4/9)\n",
      "25/06/27 09:21:24 INFO Executor: Finished task 8.0 in stage 30.0 (TID 194). 3053 bytes result sent to driver\n",
      "25/06/27 09:21:24 INFO TaskSetManager: Finished task 8.0 in stage 30.0 (TID 194) in 321 ms on hal9000 (executor driver) (5/9)\n",
      "25/06/27 09:21:25 INFO Executor: Finished task 0.0 in stage 30.0 (TID 186). 3096 bytes result sent to driver\n",
      "25/06/27 09:21:25 INFO TaskSetManager: Finished task 0.0 in stage 30.0 (TID 186) in 1504 ms on hal9000 (executor driver) (6/9)\n",
      "25/06/27 09:21:25 INFO Executor: Finished task 1.0 in stage 30.0 (TID 187). 3096 bytes result sent to driver\n",
      "25/06/27 09:21:25 INFO TaskSetManager: Finished task 1.0 in stage 30.0 (TID 187) in 1559 ms on hal9000 (executor driver) (7/9)\n",
      "25/06/27 09:21:25 INFO Executor: Finished task 4.0 in stage 30.0 (TID 190). 3096 bytes result sent to driver\n",
      "25/06/27 09:21:25 INFO TaskSetManager: Finished task 4.0 in stage 30.0 (TID 190) in 1586 ms on hal9000 (executor driver) (8/9)\n",
      "25/06/27 09:21:25 INFO Executor: Finished task 5.0 in stage 30.0 (TID 191). 3096 bytes result sent to driver\n",
      "25/06/27 09:21:25 INFO TaskSetManager: Finished task 5.0 in stage 30.0 (TID 191) in 1613 ms on hal9000 (executor driver) (9/9)\n",
      "25/06/27 09:21:25 INFO TaskSchedulerImpl: Removed TaskSet 30.0, whose tasks have all completed, from pool \n",
      "25/06/27 09:21:25 INFO DAGScheduler: ShuffleMapStage 30 (showString at NativeMethodAccessorImpl.java:0) finished in 1.656 s\n",
      "25/06/27 09:21:25 INFO DAGScheduler: looking for newly runnable stages\n",
      "25/06/27 09:21:25 INFO DAGScheduler: running: Set()\n",
      "25/06/27 09:21:25 INFO DAGScheduler: waiting: Set()\n",
      "25/06/27 09:21:25 INFO DAGScheduler: failed: Set()\n",
      "25/06/27 09:21:25 INFO ShufflePartitionsUtil: For shuffle(10), advisory target size: 67108864, actual target size 1048576, minimum partition size: 1048576\n",
      "25/06/27 09:21:25 INFO HashAggregateExec: spark.sql.codegen.aggregate.map.twolevel.enabled is set to true, but current version of codegened fast hashmap does not support this aggregate.\n",
      "25/06/27 09:21:25 INFO CodeGenerator: Code generated in 86.59239 ms\n",
      "25/06/27 09:21:25 INFO SparkContext: Starting job: showString at NativeMethodAccessorImpl.java:0\n",
      "25/06/27 09:21:25 INFO DAGScheduler: Got job 20 (showString at NativeMethodAccessorImpl.java:0) with 1 output partitions\n",
      "25/06/27 09:21:25 INFO DAGScheduler: Final stage: ResultStage 32 (showString at NativeMethodAccessorImpl.java:0)\n",
      "25/06/27 09:21:25 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 31)\n",
      "25/06/27 09:21:25 INFO DAGScheduler: Missing parents: List()\n",
      "25/06/27 09:21:25 INFO DAGScheduler: Submitting ResultStage 32 (MapPartitionsRDD[109] at showString at NativeMethodAccessorImpl.java:0), which has no missing parents\n",
      "25/06/27 09:21:25 INFO MemoryStore: Block broadcast_38 stored as values in memory (estimated size 56.7 KiB, free 433.1 MiB)\n",
      "25/06/27 09:21:25 INFO MemoryStore: Block broadcast_38_piece0 stored as bytes in memory (estimated size 24.1 KiB, free 433.0 MiB)\n",
      "25/06/27 09:21:25 INFO BlockManagerInfo: Added broadcast_38_piece0 in memory on hal9000:34557 (size: 24.1 KiB, free: 434.2 MiB)\n",
      "25/06/27 09:21:25 INFO SparkContext: Created broadcast 38 from broadcast at DAGScheduler.scala:1535\n",
      "25/06/27 09:21:25 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 32 (MapPartitionsRDD[109] at showString at NativeMethodAccessorImpl.java:0) (first 15 tasks are for partitions Vector(0))\n",
      "25/06/27 09:21:25 INFO TaskSchedulerImpl: Adding task set 32.0 with 1 tasks resource profile 0\n",
      "25/06/27 09:21:25 INFO TaskSetManager: Starting task 0.0 in stage 32.0 (TID 195) (hal9000, executor driver, partition 0, NODE_LOCAL, 7363 bytes) \n",
      "25/06/27 09:21:25 INFO Executor: Running task 0.0 in stage 32.0 (TID 195)\n",
      "25/06/27 09:21:25 INFO ShuffleBlockFetcherIterator: Getting 9 (12.8 KiB) non-empty blocks including 9 (12.8 KiB) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks\n",
      "25/06/27 09:21:25 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+------------+---------+---------+--------+\n",
      "|faixa_pk|faixa_etaria|idade_min|idade_max|id_idade|\n",
      "+--------+------------+---------+---------+--------+\n",
      "|       0|       35-39|       35|       39|      12|\n",
      "|       1|       40-44|       40|       44|      13|\n",
      "|       2|       25-29|       25|       29|      10|\n",
      "|       3|       70-74|       70|       74|      19|\n",
      "|       4|       20-24|       20|       24|       9|\n",
      "|       5|       65-69|       65|       69|      18|\n",
      "|       6|       50-54|       50|       54|      15|\n",
      "|       7|       80-84|       80|       84|      30|\n",
      "|       8|       90-94|       90|       94|      32|\n",
      "|       9|       15-19|       15|       19|       8|\n",
      "|      10|         95+|       95|      130|     235|\n",
      "|      11|       75-79|       75|       79|      20|\n",
      "|      12|       30-34|       30|       34|      11|\n",
      "|      13|       60-64|       60|       64|      17|\n",
      "|      14|       85-89|       85|       89|      31|\n",
      "|      15|       55-59|       55|       59|      16|\n",
      "|      16|       45-49|       45|       49|      14|\n",
      "|      17|       10-14|       10|       14|       7|\n",
      "|      18|         5-9|        5|        9|       6|\n",
      "|      19|         2-4|        2|        4|      34|\n",
      "+--------+------------+---------+---------+--------+\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "25/06/27 09:21:25 INFO Executor: Finished task 0.0 in stage 32.0 (TID 195). 6092 bytes result sent to driver\n",
      "25/06/27 09:21:25 INFO TaskSetManager: Finished task 0.0 in stage 32.0 (TID 195) in 67 ms on hal9000 (executor driver) (1/1)\n",
      "25/06/27 09:21:25 INFO TaskSchedulerImpl: Removed TaskSet 32.0, whose tasks have all completed, from pool \n",
      "25/06/27 09:21:25 INFO DAGScheduler: ResultStage 32 (showString at NativeMethodAccessorImpl.java:0) finished in 0.084 s\n",
      "25/06/27 09:21:25 INFO DAGScheduler: Job 20 is finished. Cancelling potential speculative or zombie tasks for this job\n",
      "25/06/27 09:21:25 INFO TaskSchedulerImpl: Killing all running tasks in stage 32: Stage finished\n",
      "25/06/27 09:21:25 INFO DAGScheduler: Job 20 finished: showString at NativeMethodAccessorImpl.java:0, took 0.094944 s\n",
      "25/06/27 09:21:25 INFO CodeGenerator: Code generated in 16.091953 ms            \n"
     ]
    }
   ],
   "source": [
    "# Transformações da Dimensão Faixa Etaria\n",
    "\n",
    "# Aqui há o tratamento das formatações desse campo, lidando com casos como:\n",
    "# '20-25' | '20 - 25' | '20-25 anos' | -> Formatações Heterogeneas\n",
    "\n",
    "\n",
    "df_faixa_etaria = (\n",
    "    df_cancer.select(\n",
    "        F.col(\"age_id\").alias(\"id_idade\"),\n",
    "        F.col(\"age_name\").alias(\"faixa_etaria\")\n",
    "    )\n",
    "    .distinct()\n",
    "    .withColumn(\n",
    "        \"faixa_etaria\",\n",
    "        F.regexp_replace(F.regexp_replace(F.col(\"faixa_etaria\"), \"anos\", \"\"), \" \", \"\")\n",
    "    )\n",
    "    .withColumn(\n",
    "        \"idade_min\",\n",
    "        F.when(\n",
    "            F.col(\"faixa_etaria\").contains(\"+\"),\n",
    "            F.regexp_replace(F.col(\"faixa_etaria\"), \"[^0-9]\", \"\").cast(\"int\")\n",
    "        ).otherwise(\n",
    "            F.split(F.col(\"faixa_etaria\"), \"-\")[0].cast(\"int\")\n",
    "        )\n",
    "    )\n",
    "    .withColumn(\n",
    "        \"idade_max\",\n",
    "        F.when(\n",
    "            F.col(\"faixa_etaria\").contains(\"+\"),\n",
    "            F.lit(130)\n",
    "        ).otherwise(\n",
    "            F.split(F.col(\"faixa_etaria\"), \"-\")[1].cast(\"int\")\n",
    "        )\n",
    "    )\n",
    "    .withColumn(\"faixa_pk\", F.monotonically_increasing_id())\n",
    "    .select(\"faixa_pk\", \"faixa_etaria\", \"idade_min\", \"idade_max\", \"id_idade\")\n",
    ")\n",
    "\n",
    "\n",
    "df_faixa_etaria.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "0313806d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "25/06/27 09:21:25 INFO FileSourceStrategy: Pushed Filters: \n",
      "25/06/27 09:21:25 INFO FileSourceStrategy: Post-Scan Filters: \n",
      "25/06/27 09:21:25 INFO FileSourceStrategy: Pushed Filters: \n",
      "25/06/27 09:21:25 INFO FileSourceStrategy: Post-Scan Filters: \n",
      "25/06/27 09:21:25 WARN WindowExec: No Partition Defined for Window operation! Moving all data to a single partition, this can cause serious performance degradation.\n",
      "25/06/27 09:21:25 WARN WindowExec: No Partition Defined for Window operation! Moving all data to a single partition, this can cause serious performance degradation.\n",
      "25/06/27 09:21:25 WARN WindowExec: No Partition Defined for Window operation! Moving all data to a single partition, this can cause serious performance degradation.\n",
      "25/06/27 09:21:25 INFO HashAggregateExec: spark.sql.codegen.aggregate.map.twolevel.enabled is set to true, but current version of codegened fast hashmap does not support this aggregate.\n",
      "25/06/27 09:21:25 INFO MemoryStore: Block broadcast_39 stored as values in memory (estimated size 203.2 KiB, free 432.8 MiB)\n",
      "25/06/27 09:21:25 INFO MemoryStore: Block broadcast_39_piece0 stored as bytes in memory (estimated size 35.4 KiB, free 432.8 MiB)\n",
      "25/06/27 09:21:25 INFO BlockManagerInfo: Added broadcast_39_piece0 in memory on hal9000:34557 (size: 35.4 KiB, free: 434.1 MiB)\n",
      "25/06/27 09:21:25 INFO SparkContext: Created broadcast 39 from showString at NativeMethodAccessorImpl.java:0\n",
      "25/06/27 09:21:25 INFO FileSourceScanExec: Planning scan with bin packing, max size: 11024413 bytes, open cost is considered as scanning 4194304 bytes.\n",
      "25/06/27 09:21:25 INFO MemoryStore: Block broadcast_40 stored as values in memory (estimated size 203.2 KiB, free 432.6 MiB)\n",
      "25/06/27 09:21:25 INFO MemoryStore: Block broadcast_40_piece0 stored as bytes in memory (estimated size 35.4 KiB, free 432.6 MiB)\n",
      "25/06/27 09:21:25 INFO BlockManagerInfo: Added broadcast_40_piece0 in memory on hal9000:34557 (size: 35.4 KiB, free: 434.1 MiB)\n",
      "25/06/27 09:21:25 INFO SparkContext: Created broadcast 40 from showString at NativeMethodAccessorImpl.java:0\n",
      "25/06/27 09:21:25 INFO FileSourceScanExec: Planning scan with bin packing, max size: 4194304 bytes, open cost is considered as scanning 4194304 bytes.\n",
      "25/06/27 09:21:25 INFO DAGScheduler: Registering RDD 118 (showString at NativeMethodAccessorImpl.java:0) as input to shuffle 11\n",
      "25/06/27 09:21:25 INFO DAGScheduler: Got map stage job 21 (showString at NativeMethodAccessorImpl.java:0) with 9 output partitions\n",
      "25/06/27 09:21:25 INFO DAGScheduler: Final stage: ShuffleMapStage 33 (showString at NativeMethodAccessorImpl.java:0)\n",
      "25/06/27 09:21:25 INFO DAGScheduler: Parents of final stage: List()\n",
      "25/06/27 09:21:25 INFO DAGScheduler: Missing parents: List()\n",
      "25/06/27 09:21:25 INFO DAGScheduler: Submitting ShuffleMapStage 33 (MapPartitionsRDD[118] at showString at NativeMethodAccessorImpl.java:0), which has no missing parents\n",
      "25/06/27 09:21:25 INFO MemoryStore: Block broadcast_41 stored as values in memory (estimated size 37.9 KiB, free 432.5 MiB)\n",
      "25/06/27 09:21:25 INFO MemoryStore: Block broadcast_41_piece0 stored as bytes in memory (estimated size 17.0 KiB, free 432.5 MiB)\n",
      "25/06/27 09:21:25 INFO BlockManagerInfo: Added broadcast_41_piece0 in memory on hal9000:34557 (size: 17.0 KiB, free: 434.1 MiB)\n",
      "25/06/27 09:21:25 INFO SparkContext: Created broadcast 41 from broadcast at DAGScheduler.scala:1535\n",
      "25/06/27 09:21:25 INFO DAGScheduler: Submitting 9 missing tasks from ShuffleMapStage 33 (MapPartitionsRDD[118] at showString at NativeMethodAccessorImpl.java:0) (first 15 tasks are for partitions Vector(0, 1, 2, 3, 4, 5, 6, 7, 8))\n",
      "25/06/27 09:21:25 INFO TaskSchedulerImpl: Adding task set 33.0 with 9 tasks resource profile 0\n",
      "25/06/27 09:21:25 INFO TaskSetManager: Starting task 0.0 in stage 33.0 (TID 196) (hal9000, executor driver, partition 0, PROCESS_LOCAL, 8005 bytes) \n",
      "25/06/27 09:21:25 INFO TaskSetManager: Starting task 1.0 in stage 33.0 (TID 197) (hal9000, executor driver, partition 1, PROCESS_LOCAL, 8005 bytes) \n",
      "25/06/27 09:21:25 INFO TaskSetManager: Starting task 2.0 in stage 33.0 (TID 198) (hal9000, executor driver, partition 2, PROCESS_LOCAL, 8005 bytes) \n",
      "25/06/27 09:21:25 INFO TaskSetManager: Starting task 3.0 in stage 33.0 (TID 199) (hal9000, executor driver, partition 3, PROCESS_LOCAL, 8005 bytes) \n",
      "25/06/27 09:21:25 INFO TaskSetManager: Starting task 4.0 in stage 33.0 (TID 200) (hal9000, executor driver, partition 4, PROCESS_LOCAL, 8005 bytes) \n",
      "25/06/27 09:21:25 INFO TaskSetManager: Starting task 5.0 in stage 33.0 (TID 201) (hal9000, executor driver, partition 5, PROCESS_LOCAL, 8005 bytes) \n",
      "25/06/27 09:21:25 INFO TaskSetManager: Starting task 6.0 in stage 33.0 (TID 202) (hal9000, executor driver, partition 6, PROCESS_LOCAL, 8005 bytes) \n",
      "25/06/27 09:21:25 INFO TaskSetManager: Starting task 7.0 in stage 33.0 (TID 203) (hal9000, executor driver, partition 7, PROCESS_LOCAL, 8005 bytes) \n",
      "25/06/27 09:21:25 INFO Executor: Running task 3.0 in stage 33.0 (TID 199)\n",
      "25/06/27 09:21:25 INFO Executor: Running task 0.0 in stage 33.0 (TID 196)\n",
      "25/06/27 09:21:25 INFO Executor: Running task 5.0 in stage 33.0 (TID 201)\n",
      "25/06/27 09:21:25 INFO Executor: Running task 1.0 in stage 33.0 (TID 197)\n",
      "25/06/27 09:21:25 INFO Executor: Running task 6.0 in stage 33.0 (TID 202)\n",
      "25/06/27 09:21:25 INFO Executor: Running task 4.0 in stage 33.0 (TID 200)\n",
      "25/06/27 09:21:25 INFO Executor: Running task 7.0 in stage 33.0 (TID 203)\n",
      "25/06/27 09:21:25 INFO Executor: Running task 2.0 in stage 33.0 (TID 198)\n",
      "25/06/27 09:21:25 INFO FileScanRDD: Reading File path: s3a://datalake/cancer-1.csv, range: 22048826-33073239, partition values: [empty row]\n",
      "25/06/27 09:21:25 INFO FileScanRDD: Reading File path: s3a://datalake/cancer-1.csv, range: 66146478-77170891, partition values: [empty row]\n",
      "25/06/27 09:21:25 INFO FileScanRDD: Reading File path: s3a://datalake/cancer-1.csv, range: 44097652-55122065, partition values: [empty row]\n",
      "25/06/27 09:21:25 INFO FileScanRDD: Reading File path: s3a://datalake/cancer-1.csv, range: 77170891-84001007, partition values: [empty row]\n",
      "25/06/27 09:21:25 INFO FileScanRDD: Reading File path: s3a://datalake/cancer-1.csv, range: 11024413-22048826, partition values: [empty row]\n",
      "25/06/27 09:21:25 INFO FileScanRDD: Reading File path: s3a://datalake/cancer-1.csv, range: 33073239-44097652, partition values: [empty row]\n",
      "25/06/27 09:21:25 INFO FileScanRDD: Reading File path: s3a://datalake/cancer-1.csv, range: 55122065-66146478, partition values: [empty row]\n",
      "25/06/27 09:21:25 INFO FileScanRDD: Reading File path: s3a://datalake/cancer-1.csv, range: 0-11024413, partition values: [empty row]\n",
      "25/06/27 09:21:25 INFO BlockManagerInfo: Removed broadcast_38_piece0 on hal9000:34557 in memory (size: 24.1 KiB, free: 434.1 MiB)\n",
      "25/06/27 09:21:26 INFO BlockManagerInfo: Removed broadcast_35_piece0 on hal9000:34557 in memory (size: 35.4 KiB, free: 434.1 MiB)\n",
      "25/06/27 09:21:26 INFO BlockManagerInfo: Removed broadcast_36_piece0 on hal9000:34557 in memory (size: 35.4 KiB, free: 434.2 MiB)\n",
      "25/06/27 09:21:26 INFO BlockManagerInfo: Removed broadcast_37_piece0 on hal9000:34557 in memory (size: 17.6 KiB, free: 434.2 MiB)\n",
      "25/06/27 09:21:26 INFO Executor: Finished task 7.0 in stage 33.0 (TID 203). 3096 bytes result sent to driver\n",
      "25/06/27 09:21:26 INFO TaskSetManager: Finished task 7.0 in stage 33.0 (TID 203) in 725 ms on hal9000 (executor driver) (1/9)\n",
      "25/06/27 09:21:26 INFO TaskSetManager: Starting task 8.0 in stage 33.0 (TID 204) (hal9000, executor driver, partition 8, PROCESS_LOCAL, 8005 bytes) \n",
      "25/06/27 09:21:26 INFO Executor: Running task 8.0 in stage 33.0 (TID 204)\n",
      "25/06/27 09:21:26 INFO FileScanRDD: Reading File path: s3a://datalake/cancer-2.csv, range: 0-3668986, partition values: [empty row]\n",
      "25/06/27 09:21:26 INFO Executor: Finished task 4.0 in stage 33.0 (TID 200). 3096 bytes result sent to driver\n",
      "25/06/27 09:21:26 INFO TaskSetManager: Finished task 4.0 in stage 33.0 (TID 200) in 920 ms on hal9000 (executor driver) (2/9)\n",
      "25/06/27 09:21:26 INFO Executor: Finished task 1.0 in stage 33.0 (TID 197). 3096 bytes result sent to driver\n",
      "25/06/27 09:21:26 INFO TaskSetManager: Finished task 1.0 in stage 33.0 (TID 197) in 1056 ms on hal9000 (executor driver) (3/9)\n",
      "25/06/27 09:21:26 INFO Executor: Finished task 8.0 in stage 33.0 (TID 204). 3096 bytes result sent to driver\n",
      "25/06/27 09:21:26 INFO TaskSetManager: Finished task 8.0 in stage 33.0 (TID 204) in 351 ms on hal9000 (executor driver) (4/9)\n",
      "25/06/27 09:21:26 INFO Executor: Finished task 0.0 in stage 33.0 (TID 196). 3096 bytes result sent to driver\n",
      "25/06/27 09:21:26 INFO TaskSetManager: Finished task 0.0 in stage 33.0 (TID 196) in 1119 ms on hal9000 (executor driver) (5/9)\n",
      "25/06/27 09:21:26 INFO Executor: Finished task 2.0 in stage 33.0 (TID 198). 3096 bytes result sent to driver\n",
      "25/06/27 09:21:26 INFO TaskSetManager: Finished task 2.0 in stage 33.0 (TID 198) in 1184 ms on hal9000 (executor driver) (6/9)\n",
      "25/06/27 09:21:26 INFO Executor: Finished task 3.0 in stage 33.0 (TID 199). 3096 bytes result sent to driver\n",
      "25/06/27 09:21:26 INFO TaskSetManager: Finished task 3.0 in stage 33.0 (TID 199) in 1205 ms on hal9000 (executor driver) (7/9)\n",
      "25/06/27 09:21:26 INFO Executor: Finished task 5.0 in stage 33.0 (TID 201). 3096 bytes result sent to driver\n",
      "25/06/27 09:21:26 INFO TaskSetManager: Finished task 5.0 in stage 33.0 (TID 201) in 1256 ms on hal9000 (executor driver) (8/9)\n",
      "25/06/27 09:21:26 INFO Executor: Finished task 6.0 in stage 33.0 (TID 202). 3096 bytes result sent to driver\n",
      "25/06/27 09:21:26 INFO TaskSetManager: Finished task 6.0 in stage 33.0 (TID 202) in 1319 ms on hal9000 (executor driver) (9/9)\n",
      "25/06/27 09:21:26 INFO TaskSchedulerImpl: Removed TaskSet 33.0, whose tasks have all completed, from pool \n",
      "25/06/27 09:21:26 INFO DAGScheduler: ShuffleMapStage 33 (showString at NativeMethodAccessorImpl.java:0) finished in 1.334 s\n",
      "25/06/27 09:21:26 INFO DAGScheduler: looking for newly runnable stages\n",
      "25/06/27 09:21:26 INFO DAGScheduler: running: Set()\n",
      "25/06/27 09:21:26 INFO DAGScheduler: waiting: Set()\n",
      "25/06/27 09:21:26 INFO DAGScheduler: failed: Set()\n",
      "25/06/27 09:21:26 WARN WindowExec: No Partition Defined for Window operation! Moving all data to a single partition, this can cause serious performance degradation.\n",
      "25/06/27 09:21:26 WARN WindowExec: No Partition Defined for Window operation! Moving all data to a single partition, this can cause serious performance degradation.\n",
      "25/06/27 09:21:26 INFO ShufflePartitionsUtil: For shuffle(11), advisory target size: 67108864, actual target size 1048576, minimum partition size: 1048576\n",
      "25/06/27 09:21:26 WARN WindowExec: No Partition Defined for Window operation! Moving all data to a single partition, this can cause serious performance degradation.\n",
      "25/06/27 09:21:27 INFO CodeGenerator: Code generated in 13.678663 ms\n",
      "25/06/27 09:21:27 INFO CodeGenerator: Code generated in 6.63469 ms\n",
      "25/06/27 09:21:27 INFO HashAggregateExec: spark.sql.codegen.aggregate.map.twolevel.enabled is set to true, but current version of codegened fast hashmap does not support this aggregate.\n",
      "25/06/27 09:21:27 INFO CodeGenerator: Code generated in 11.101941 ms\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+------------+\n",
      "|metrica_pk|tipo_metrica|\n",
      "+----------+------------+\n",
      "|         1|      Número|\n",
      "|         2|  Percentual|\n",
      "|         3|        Taxa|\n",
      "+----------+------------+\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "25/06/27 09:21:27 INFO SparkContext: Starting job: showString at NativeMethodAccessorImpl.java:0\n",
      "25/06/27 09:21:27 INFO DAGScheduler: Got job 22 (showString at NativeMethodAccessorImpl.java:0) with 1 output partitions\n",
      "25/06/27 09:21:27 INFO DAGScheduler: Final stage: ResultStage 35 (showString at NativeMethodAccessorImpl.java:0)\n",
      "25/06/27 09:21:27 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 34)\n",
      "25/06/27 09:21:27 INFO DAGScheduler: Missing parents: List()\n",
      "25/06/27 09:21:27 INFO DAGScheduler: Submitting ResultStage 35 (MapPartitionsRDD[124] at showString at NativeMethodAccessorImpl.java:0), which has no missing parents\n",
      "25/06/27 09:21:27 INFO MemoryStore: Block broadcast_42 stored as values in memory (estimated size 49.8 KiB, free 433.1 MiB)\n",
      "25/06/27 09:21:27 INFO MemoryStore: Block broadcast_42_piece0 stored as bytes in memory (estimated size 22.8 KiB, free 433.1 MiB)\n",
      "25/06/27 09:21:27 INFO BlockManagerInfo: Added broadcast_42_piece0 in memory on hal9000:34557 (size: 22.8 KiB, free: 434.2 MiB)\n",
      "25/06/27 09:21:27 INFO SparkContext: Created broadcast 42 from broadcast at DAGScheduler.scala:1535\n",
      "25/06/27 09:21:27 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 35 (MapPartitionsRDD[124] at showString at NativeMethodAccessorImpl.java:0) (first 15 tasks are for partitions Vector(0))\n",
      "25/06/27 09:21:27 INFO TaskSchedulerImpl: Adding task set 35.0 with 1 tasks resource profile 0\n",
      "25/06/27 09:21:27 INFO TaskSetManager: Starting task 0.0 in stage 35.0 (TID 205) (hal9000, executor driver, partition 0, NODE_LOCAL, 7363 bytes) \n",
      "25/06/27 09:21:27 INFO Executor: Running task 0.0 in stage 35.0 (TID 205)\n",
      "25/06/27 09:21:27 INFO ShuffleBlockFetcherIterator: Getting 9 (2016.0 B) non-empty blocks including 9 (2016.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks\n",
      "25/06/27 09:21:27 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms\n",
      "25/06/27 09:21:27 INFO CodeGenerator: Code generated in 12.267803 ms\n",
      "25/06/27 09:21:27 INFO Executor: Finished task 0.0 in stage 35.0 (TID 205). 6766 bytes result sent to driver\n",
      "25/06/27 09:21:27 INFO TaskSetManager: Finished task 0.0 in stage 35.0 (TID 205) in 58 ms on hal9000 (executor driver) (1/1)\n",
      "25/06/27 09:21:27 INFO TaskSchedulerImpl: Removed TaskSet 35.0, whose tasks have all completed, from pool \n",
      "25/06/27 09:21:27 INFO DAGScheduler: ResultStage 35 (showString at NativeMethodAccessorImpl.java:0) finished in 0.074 s\n",
      "25/06/27 09:21:27 INFO DAGScheduler: Job 22 is finished. Cancelling potential speculative or zombie tasks for this job\n",
      "25/06/27 09:21:27 INFO TaskSchedulerImpl: Killing all running tasks in stage 35: Stage finished\n",
      "25/06/27 09:21:27 INFO DAGScheduler: Job 22 finished: showString at NativeMethodAccessorImpl.java:0, took 0.090352 s\n",
      "25/06/27 09:21:27 INFO CodeGenerator: Code generated in 5.514843 ms             \n"
     ]
    }
   ],
   "source": [
    "# Transfomações da Dimensão Metrica\n",
    "\n",
    "df_metrica = (\n",
    "    df_cancer\n",
    "    .select(F.col(\"metric_name\").alias(\"tipo_metrica\"))\n",
    "    .distinct()\n",
    "    .withColumn(\"metrica_pk\", F.row_number().over(Window.orderBy(\"tipo_metrica\")))\n",
    "    .select(\"metrica_pk\", \"tipo_metrica\")\n",
    ")\n",
    "\n",
    "df_metrica.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f71344bb",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "25/06/27 09:21:27 INFO FileSourceStrategy: Pushed Filters: IsNotNull(cidade),IsNotNull(latitude),IsNotNull(longitude)\n",
      "25/06/27 09:21:27 INFO FileSourceStrategy: Post-Scan Filters: isnotnull(date_add(cast(concat(cast(YEAR#217 as string), -01-01) as date), (DOY#218 - 1))),isnotnull(cidade#214),isnotnull(latitude#215),isnotnull(longitude#216)\n",
      "25/06/27 09:21:27 INFO FileSourceStrategy: Pushed Filters: \n",
      "25/06/27 09:21:27 INFO FileSourceStrategy: Post-Scan Filters: \n",
      "25/06/27 09:21:27 INFO FileSourceStrategy: Pushed Filters: \n",
      "25/06/27 09:21:27 INFO FileSourceStrategy: Post-Scan Filters: \n",
      "25/06/27 09:21:27 WARN WindowExec: No Partition Defined for Window operation! Moving all data to a single partition, this can cause serious performance degradation.\n",
      "25/06/27 09:21:28 WARN WindowExec: No Partition Defined for Window operation! Moving all data to a single partition, this can cause serious performance degradation.\n",
      "25/06/27 09:21:28 WARN WindowExec: No Partition Defined for Window operation! Moving all data to a single partition, this can cause serious performance degradation.\n",
      "25/06/27 09:21:28 WARN WindowExec: No Partition Defined for Window operation! Moving all data to a single partition, this can cause serious performance degradation.\n",
      "25/06/27 09:21:28 INFO CodeGenerator: Code generated in 20.993846 ms\n",
      "25/06/27 09:21:28 INFO MemoryStore: Block broadcast_43 stored as values in memory (estimated size 203.2 KiB, free 432.9 MiB)\n",
      "25/06/27 09:21:28 INFO MemoryStore: Block broadcast_43_piece0 stored as bytes in memory (estimated size 35.4 KiB, free 432.8 MiB)\n",
      "25/06/27 09:21:28 INFO BlockManagerInfo: Added broadcast_43_piece0 in memory on hal9000:34557 (size: 35.4 KiB, free: 434.1 MiB)\n",
      "25/06/27 09:21:28 INFO SparkContext: Created broadcast 43 from showString at NativeMethodAccessorImpl.java:0\n",
      "25/06/27 09:21:28 INFO FileSourceScanExec: Planning scan with bin packing, max size: 134217728 bytes, open cost is considered as scanning 4194304 bytes.\n",
      "25/06/27 09:21:28 INFO HashAggregateExec: spark.sql.codegen.aggregate.map.twolevel.enabled is set to true, but current version of codegened fast hashmap does not support this aggregate.\n",
      "25/06/27 09:21:28 INFO DAGScheduler: Registering RDD 128 (showString at NativeMethodAccessorImpl.java:0) as input to shuffle 12\n",
      "25/06/27 09:21:28 INFO DAGScheduler: Got map stage job 23 (showString at NativeMethodAccessorImpl.java:0) with 33 output partitions\n",
      "25/06/27 09:21:28 INFO DAGScheduler: Final stage: ShuffleMapStage 36 (showString at NativeMethodAccessorImpl.java:0)\n",
      "25/06/27 09:21:28 INFO DAGScheduler: Parents of final stage: List()\n",
      "25/06/27 09:21:28 INFO DAGScheduler: Missing parents: List()\n",
      "25/06/27 09:21:28 INFO DAGScheduler: Submitting ShuffleMapStage 36 (MapPartitionsRDD[128] at showString at NativeMethodAccessorImpl.java:0), which has no missing parents\n",
      "25/06/27 09:21:28 INFO MemoryStore: Block broadcast_44 stored as values in memory (estimated size 24.8 KiB, free 432.8 MiB)\n",
      "25/06/27 09:21:28 INFO MemoryStore: Block broadcast_44_piece0 stored as bytes in memory (estimated size 10.9 KiB, free 432.8 MiB)\n",
      "25/06/27 09:21:28 INFO BlockManagerInfo: Added broadcast_44_piece0 in memory on hal9000:34557 (size: 10.9 KiB, free: 434.1 MiB)\n",
      "25/06/27 09:21:28 INFO SparkContext: Created broadcast 44 from broadcast at DAGScheduler.scala:1535\n",
      "25/06/27 09:21:28 INFO DAGScheduler: Submitting 33 missing tasks from ShuffleMapStage 36 (MapPartitionsRDD[128] at showString at NativeMethodAccessorImpl.java:0) (first 15 tasks are for partitions Vector(0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14))\n",
      "25/06/27 09:21:28 INFO TaskSchedulerImpl: Adding task set 36.0 with 33 tasks resource profile 0\n",
      "25/06/27 09:21:28 INFO TaskSetManager: Starting task 0.0 in stage 36.0 (TID 206) (hal9000, executor driver, partition 0, PROCESS_LOCAL, 7895 bytes) \n",
      "25/06/27 09:21:28 INFO TaskSetManager: Starting task 1.0 in stage 36.0 (TID 207) (hal9000, executor driver, partition 1, PROCESS_LOCAL, 7895 bytes) \n",
      "25/06/27 09:21:28 INFO TaskSetManager: Starting task 2.0 in stage 36.0 (TID 208) (hal9000, executor driver, partition 2, PROCESS_LOCAL, 7895 bytes) \n",
      "25/06/27 09:21:28 INFO TaskSetManager: Starting task 3.0 in stage 36.0 (TID 209) (hal9000, executor driver, partition 3, PROCESS_LOCAL, 7895 bytes) \n",
      "25/06/27 09:21:28 INFO TaskSetManager: Starting task 4.0 in stage 36.0 (TID 210) (hal9000, executor driver, partition 4, PROCESS_LOCAL, 7895 bytes) \n",
      "25/06/27 09:21:28 INFO TaskSetManager: Starting task 5.0 in stage 36.0 (TID 211) (hal9000, executor driver, partition 5, PROCESS_LOCAL, 7895 bytes) \n",
      "25/06/27 09:21:28 INFO TaskSetManager: Starting task 6.0 in stage 36.0 (TID 212) (hal9000, executor driver, partition 6, PROCESS_LOCAL, 7895 bytes) \n",
      "25/06/27 09:21:28 INFO TaskSetManager: Starting task 7.0 in stage 36.0 (TID 213) (hal9000, executor driver, partition 7, PROCESS_LOCAL, 7895 bytes) \n",
      "25/06/27 09:21:28 INFO Executor: Running task 7.0 in stage 36.0 (TID 213)\n",
      "25/06/27 09:21:28 INFO Executor: Running task 3.0 in stage 36.0 (TID 209)\n",
      "25/06/27 09:21:28 INFO Executor: Running task 0.0 in stage 36.0 (TID 206)\n",
      "25/06/27 09:21:28 INFO Executor: Running task 4.0 in stage 36.0 (TID 210)\n",
      "25/06/27 09:21:28 INFO Executor: Running task 2.0 in stage 36.0 (TID 208)\n",
      "25/06/27 09:21:28 INFO Executor: Running task 1.0 in stage 36.0 (TID 207)\n",
      "25/06/27 09:21:28 INFO Executor: Running task 5.0 in stage 36.0 (TID 211)\n",
      "25/06/27 09:21:28 INFO Executor: Running task 6.0 in stage 36.0 (TID 212)\n",
      "25/06/27 09:21:28 INFO CodeGenerator: Code generated in 74.736472 ms\n",
      "25/06/27 09:21:28 INFO CodeGenerator: Code generated in 24.323895 ms\n",
      "25/06/27 09:21:28 INFO MemoryStore: Block broadcast_45 stored as values in memory (estimated size 203.2 KiB, free 432.6 MiB)\n",
      "25/06/27 09:21:28 INFO FileScanRDD: Reading File path: s3a://datalake/climate.csv, range: 805306368-939524096, partition values: [empty row]\n",
      "25/06/27 09:21:28 INFO FileScanRDD: Reading File path: s3a://datalake/climate.csv, range: 939524096-1073741824, partition values: [empty row]\n",
      "25/06/27 09:21:28 INFO FileScanRDD: Reading File path: s3a://datalake/climate.csv, range: 671088640-805306368, partition values: [empty row]\n",
      "25/06/27 09:21:28 INFO FileScanRDD: Reading File path: s3a://datalake/climate.csv, range: 402653184-536870912, partition values: [empty row]\n",
      "25/06/27 09:21:28 INFO FileScanRDD: Reading File path: s3a://datalake/climate.csv, range: 0-134217728, partition values: [empty row]\n",
      "25/06/27 09:21:28 INFO FileScanRDD: Reading File path: s3a://datalake/climate.csv, range: 536870912-671088640, partition values: [empty row]\n",
      "25/06/27 09:21:28 INFO FileScanRDD: Reading File path: s3a://datalake/climate.csv, range: 268435456-402653184, partition values: [empty row]\n",
      "25/06/27 09:21:28 INFO FileScanRDD: Reading File path: s3a://datalake/climate.csv, range: 134217728-268435456, partition values: [empty row]\n",
      "25/06/27 09:21:28 INFO MemoryStore: Block broadcast_45_piece0 stored as bytes in memory (estimated size 35.4 KiB, free 432.6 MiB)\n",
      "25/06/27 09:21:28 INFO CodeGenerator: Code generated in 33.797158 ms\n",
      "25/06/27 09:21:28 INFO BlockManagerInfo: Added broadcast_45_piece0 in memory on hal9000:34557 (size: 35.4 KiB, free: 434.1 MiB)\n",
      "25/06/27 09:21:28 INFO SparkContext: Created broadcast 45 from showString at NativeMethodAccessorImpl.java:0\n",
      "25/06/27 09:21:28 INFO FileSourceScanExec: Planning scan with bin packing, max size: 134217728 bytes, open cost is considered as scanning 4194304 bytes.\n",
      "25/06/27 09:21:28 INFO CodeGenerator: Code generated in 14.53928 ms\n",
      "25/06/27 09:21:28 INFO DAGScheduler: Registering RDD 132 (showString at NativeMethodAccessorImpl.java:0) as input to shuffle 13\n",
      "25/06/27 09:21:28 INFO DAGScheduler: Got map stage job 24 (showString at NativeMethodAccessorImpl.java:0) with 33 output partitions\n",
      "25/06/27 09:21:28 INFO DAGScheduler: Final stage: ShuffleMapStage 37 (showString at NativeMethodAccessorImpl.java:0)\n",
      "25/06/27 09:21:28 INFO DAGScheduler: Parents of final stage: List()\n",
      "25/06/27 09:21:28 INFO DAGScheduler: Missing parents: List()\n",
      "25/06/27 09:21:28 INFO DAGScheduler: Submitting ShuffleMapStage 37 (MapPartitionsRDD[132] at showString at NativeMethodAccessorImpl.java:0), which has no missing parents\n",
      "25/06/27 09:21:28 INFO HashAggregateExec: spark.sql.codegen.aggregate.map.twolevel.enabled is set to true, but current version of codegened fast hashmap does not support this aggregate.\n",
      "25/06/27 09:21:28 INFO CodeGenerator: Code generated in 18.978259 ms\n",
      "25/06/27 09:21:28 INFO MemoryStore: Block broadcast_46 stored as values in memory (estimated size 41.5 KiB, free 432.5 MiB)\n",
      "25/06/27 09:21:28 INFO MemoryStore: Block broadcast_46_piece0 stored as bytes in memory (estimated size 19.0 KiB, free 432.5 MiB)\n",
      "25/06/27 09:21:28 INFO BlockManagerInfo: Added broadcast_46_piece0 in memory on hal9000:34557 (size: 19.0 KiB, free: 434.1 MiB)\n",
      "25/06/27 09:21:28 INFO SparkContext: Created broadcast 46 from broadcast at DAGScheduler.scala:1535\n",
      "25/06/27 09:21:28 INFO DAGScheduler: Submitting 33 missing tasks from ShuffleMapStage 37 (MapPartitionsRDD[132] at showString at NativeMethodAccessorImpl.java:0) (first 15 tasks are for partitions Vector(0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14))\n",
      "25/06/27 09:21:28 INFO CodeGenerator: Code generated in 19.52826 ms\n",
      "25/06/27 09:21:28 INFO TaskSchedulerImpl: Adding task set 37.0 with 33 tasks resource profile 0\n",
      "25/06/27 09:21:28 INFO CodeGenerator: Code generated in 52.708152 ms\n",
      "25/06/27 09:21:28 INFO MemoryStore: Block broadcast_47 stored as values in memory (estimated size 203.2 KiB, free 432.3 MiB)\n",
      "25/06/27 09:21:28 INFO BlockManagerInfo: Removed broadcast_40_piece0 on hal9000:34557 in memory (size: 35.4 KiB, free: 434.1 MiB)\n",
      "25/06/27 09:21:28 INFO MemoryStore: Block broadcast_47_piece0 stored as bytes in memory (estimated size 35.4 KiB, free 432.5 MiB)\n",
      "25/06/27 09:21:28 INFO BlockManagerInfo: Added broadcast_47_piece0 in memory on hal9000:34557 (size: 35.4 KiB, free: 434.1 MiB)\n",
      "25/06/27 09:21:28 INFO SparkContext: Created broadcast 47 from showString at NativeMethodAccessorImpl.java:0\n",
      "25/06/27 09:21:28 INFO FileSourceScanExec: Planning scan with bin packing, max size: 134217728 bytes, open cost is considered as scanning 4194304 bytes.\n",
      "25/06/27 09:21:28 INFO DAGScheduler: Registering RDD 136 (showString at NativeMethodAccessorImpl.java:0) as input to shuffle 14\n",
      "25/06/27 09:21:28 INFO DAGScheduler: Got map stage job 25 (showString at NativeMethodAccessorImpl.java:0) with 33 output partitions\n",
      "25/06/27 09:21:28 INFO DAGScheduler: Final stage: ShuffleMapStage 38 (showString at NativeMethodAccessorImpl.java:0)\n",
      "25/06/27 09:21:28 INFO DAGScheduler: Parents of final stage: List()\n",
      "25/06/27 09:21:28 INFO DAGScheduler: Missing parents: List()\n",
      "25/06/27 09:21:28 INFO DAGScheduler: Submitting ShuffleMapStage 38 (MapPartitionsRDD[136] at showString at NativeMethodAccessorImpl.java:0), which has no missing parents\n",
      "25/06/27 09:21:28 INFO MemoryStore: Block broadcast_48 stored as values in memory (estimated size 34.6 KiB, free 432.5 MiB)\n",
      "25/06/27 09:21:28 INFO MemoryStore: Block broadcast_48_piece0 stored as bytes in memory (estimated size 16.2 KiB, free 432.4 MiB)\n",
      "25/06/27 09:21:28 INFO BlockManagerInfo: Added broadcast_48_piece0 in memory on hal9000:34557 (size: 16.2 KiB, free: 434.1 MiB)\n",
      "25/06/27 09:21:28 INFO SparkContext: Created broadcast 48 from broadcast at DAGScheduler.scala:1535\n",
      "25/06/27 09:21:28 INFO DAGScheduler: Submitting 33 missing tasks from ShuffleMapStage 38 (MapPartitionsRDD[136] at showString at NativeMethodAccessorImpl.java:0) (first 15 tasks are for partitions Vector(0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14))\n",
      "25/06/27 09:21:28 INFO TaskSchedulerImpl: Adding task set 38.0 with 33 tasks resource profile 0\n",
      "25/06/27 09:21:28 INFO BlockManagerInfo: Removed broadcast_42_piece0 on hal9000:34557 in memory (size: 22.8 KiB, free: 434.1 MiB)\n",
      "25/06/27 09:21:28 INFO BlockManagerInfo: Removed broadcast_39_piece0 on hal9000:34557 in memory (size: 35.4 KiB, free: 434.1 MiB)\n",
      "25/06/27 09:21:28 INFO BlockManagerInfo: Removed broadcast_41_piece0 on hal9000:34557 in memory (size: 17.0 KiB, free: 434.1 MiB)\n",
      "25/06/27 09:21:30 INFO BlockManagerInfo: Removed broadcast_24_piece0 on hal9000:34557 in memory (size: 35.4 KiB, free: 434.2 MiB)\n",
      "25/06/27 09:21:30 INFO BlockManagerInfo: Removed broadcast_23_piece0 on hal9000:34557 in memory (size: 35.4 KiB, free: 434.2 MiB)\n",
      "25/06/27 09:21:30 INFO BlockManagerInfo: Removed broadcast_25_piece0 on hal9000:34557 in memory (size: 17.0 KiB, free: 434.2 MiB)\n",
      "25/06/27 09:21:30 INFO BlockManagerInfo: Removed broadcast_20_piece0 on hal9000:34557 in memory (size: 35.4 KiB, free: 434.3 MiB)\n",
      "25/06/27 09:21:53 INFO Executor: Finished task 0.0 in stage 36.0 (TID 206). 2083 bytes result sent to driver\n",
      "25/06/27 09:21:53 INFO TaskSetManager: Starting task 8.0 in stage 36.0 (TID 214) (hal9000, executor driver, partition 8, PROCESS_LOCAL, 7895 bytes) \n",
      "25/06/27 09:21:53 INFO TaskSetManager: Finished task 0.0 in stage 36.0 (TID 206) in 25726 ms on hal9000 (executor driver) (1/33)\n",
      "25/06/27 09:21:54 INFO Executor: Running task 8.0 in stage 36.0 (TID 214)/ 33]\n",
      "25/06/27 09:21:54 INFO FileScanRDD: Reading File path: s3a://datalake/climate.csv, range: 1073741824-1207959552, partition values: [empty row]\n",
      "25/06/27 09:21:54 INFO Executor: Finished task 5.0 in stage 36.0 (TID 211). 2083 bytes result sent to driver\n",
      "25/06/27 09:21:54 INFO TaskSetManager: Starting task 9.0 in stage 36.0 (TID 215) (hal9000, executor driver, partition 9, PROCESS_LOCAL, 7895 bytes) \n",
      "25/06/27 09:21:54 INFO TaskSetManager: Finished task 5.0 in stage 36.0 (TID 211) in 26236 ms on hal9000 (executor driver) (2/33)\n",
      "25/06/27 09:21:54 INFO Executor: Running task 9.0 in stage 36.0 (TID 215)\n",
      "25/06/27 09:21:54 INFO FileScanRDD: Reading File path: s3a://datalake/climate.csv, range: 1207959552-1342177280, partition values: [empty row]\n",
      "25/06/27 09:21:54 INFO Executor: Finished task 3.0 in stage 36.0 (TID 209). 2083 bytes result sent to driver\n",
      "25/06/27 09:21:54 INFO TaskSetManager: Starting task 10.0 in stage 36.0 (TID 216) (hal9000, executor driver, partition 10, PROCESS_LOCAL, 7895 bytes) \n",
      "25/06/27 09:21:54 INFO TaskSetManager: Finished task 3.0 in stage 36.0 (TID 209) in 26727 ms on hal9000 (executor driver) (3/33)\n",
      "25/06/27 09:21:54 INFO Executor: Running task 10.0 in stage 36.0 (TID 216)\n",
      "25/06/27 09:21:54 INFO FileScanRDD: Reading File path: s3a://datalake/climate.csv, range: 1342177280-1476395008, partition values: [empty row]\n",
      "25/06/27 09:21:56 INFO Executor: Finished task 2.0 in stage 36.0 (TID 208). 2083 bytes result sent to driver\n",
      "25/06/27 09:21:56 INFO TaskSetManager: Starting task 11.0 in stage 36.0 (TID 217) (hal9000, executor driver, partition 11, PROCESS_LOCAL, 7895 bytes) \n",
      "25/06/27 09:21:56 INFO Executor: Running task 11.0 in stage 36.0 (TID 217)\n",
      "25/06/27 09:21:56 INFO TaskSetManager: Finished task 2.0 in stage 36.0 (TID 208) in 28202 ms on hal9000 (executor driver) (4/33)\n",
      "25/06/27 09:21:56 INFO FileScanRDD: Reading File path: s3a://datalake/climate.csv, range: 1476395008-1610612736, partition values: [empty row]\n",
      "25/06/27 09:21:57 INFO Executor: Finished task 7.0 in stage 36.0 (TID 213). 2083 bytes result sent to driver\n",
      "25/06/27 09:21:57 INFO TaskSetManager: Starting task 12.0 in stage 36.0 (TID 218) (hal9000, executor driver, partition 12, PROCESS_LOCAL, 7895 bytes) \n",
      "25/06/27 09:21:57 INFO Executor: Running task 12.0 in stage 36.0 (TID 218)\n",
      "25/06/27 09:21:57 INFO TaskSetManager: Finished task 7.0 in stage 36.0 (TID 213) in 29345 ms on hal9000 (executor driver) (5/33)\n",
      "25/06/27 09:21:57 INFO FileScanRDD: Reading File path: s3a://datalake/climate.csv, range: 1610612736-1744830464, partition values: [empty row]\n",
      "25/06/27 09:21:59 INFO Executor: Finished task 1.0 in stage 36.0 (TID 207). 2083 bytes result sent to driver\n",
      "25/06/27 09:21:59 INFO TaskSetManager: Starting task 13.0 in stage 36.0 (TID 219) (hal9000, executor driver, partition 13, PROCESS_LOCAL, 7895 bytes) \n",
      "25/06/27 09:21:59 INFO Executor: Running task 13.0 in stage 36.0 (TID 219)\n",
      "25/06/27 09:21:59 INFO TaskSetManager: Finished task 1.0 in stage 36.0 (TID 207) in 30906 ms on hal9000 (executor driver) (6/33)\n",
      "25/06/27 09:21:59 INFO FileScanRDD: Reading File path: s3a://datalake/climate.csv, range: 1744830464-1879048192, partition values: [empty row]\n",
      "25/06/27 09:21:59 INFO Executor: Finished task 6.0 in stage 36.0 (TID 212). 2083 bytes result sent to driver\n",
      "25/06/27 09:21:59 INFO TaskSetManager: Starting task 14.0 in stage 36.0 (TID 220) (hal9000, executor driver, partition 14, PROCESS_LOCAL, 7895 bytes) \n",
      "25/06/27 09:21:59 INFO TaskSetManager: Finished task 6.0 in stage 36.0 (TID 212) in 31472 ms on hal9000 (executor driver) (7/33)\n",
      "25/06/27 09:21:59 INFO Executor: Running task 14.0 in stage 36.0 (TID 220)\n",
      "25/06/27 09:21:59 INFO FileScanRDD: Reading File path: s3a://datalake/climate.csv, range: 1879048192-2013265920, partition values: [empty row]\n",
      "25/06/27 09:21:59 INFO Executor: Finished task 4.0 in stage 36.0 (TID 210). 2083 bytes result sent to driver\n",
      "25/06/27 09:21:59 INFO TaskSetManager: Starting task 15.0 in stage 36.0 (TID 221) (hal9000, executor driver, partition 15, PROCESS_LOCAL, 7895 bytes) \n",
      "25/06/27 09:21:59 INFO Executor: Running task 15.0 in stage 36.0 (TID 221)\n",
      "25/06/27 09:21:59 INFO TaskSetManager: Finished task 4.0 in stage 36.0 (TID 210) in 31626 ms on hal9000 (executor driver) (8/33)\n",
      "25/06/27 09:21:59 INFO FileScanRDD: Reading File path: s3a://datalake/climate.csv, range: 2013265920-2147483648, partition values: [empty row]\n",
      "25/06/27 09:22:29 INFO Executor: Finished task 9.0 in stage 36.0 (TID 215). 2083 bytes result sent to driver\n",
      "25/06/27 09:22:29 INFO TaskSetManager: Starting task 16.0 in stage 36.0 (TID 222) (hal9000, executor driver, partition 16, PROCESS_LOCAL, 7895 bytes) \n",
      "25/06/27 09:22:29 INFO TaskSetManager: Finished task 9.0 in stage 36.0 (TID 215) in 35099 ms on hal9000 (executor driver) (9/33)\n",
      "25/06/27 09:22:29 INFO Executor: Running task 16.0 in stage 36.0 (TID 222)\n",
      "25/06/27 09:22:29 INFO FileScanRDD: Reading File path: s3a://datalake/climate.csv, range: 2147483648-2281701376, partition values: [empty row]\n",
      "25/06/27 09:22:32 INFO Executor: Finished task 8.0 in stage 36.0 (TID 214). 2083 bytes result sent to driver\n",
      "25/06/27 09:22:32 INFO TaskSetManager: Starting task 17.0 in stage 36.0 (TID 223) (hal9000, executor driver, partition 17, PROCESS_LOCAL, 7895 bytes) \n",
      "25/06/27 09:22:32 INFO TaskSetManager: Finished task 8.0 in stage 36.0 (TID 214) in 38587 ms on hal9000 (executor driver) (10/33)\n",
      "25/06/27 09:22:32 INFO Executor: Running task 17.0 in stage 36.0 (TID 223)\n",
      "25/06/27 09:22:32 INFO FileScanRDD: Reading File path: s3a://datalake/climate.csv, range: 2281701376-2415919104, partition values: [empty row]\n",
      "25/06/27 09:22:33 INFO Executor: Finished task 11.0 in stage 36.0 (TID 217). 2083 bytes result sent to driver\n",
      "25/06/27 09:22:33 INFO TaskSetManager: Starting task 18.0 in stage 36.0 (TID 224) (hal9000, executor driver, partition 18, PROCESS_LOCAL, 7895 bytes) \n",
      "25/06/27 09:22:33 INFO TaskSetManager: Finished task 11.0 in stage 36.0 (TID 217) in 37018 ms on hal9000 (executor driver) (11/33)\n",
      "25/06/27 09:22:33 INFO Executor: Running task 18.0 in stage 36.0 (TID 224)\n",
      "25/06/27 09:22:33 INFO FileScanRDD: Reading File path: s3a://datalake/climate.csv, range: 2415919104-2550136832, partition values: [empty row]\n",
      "25/06/27 09:22:38 INFO Executor: Finished task 10.0 in stage 36.0 (TID 216). 2083 bytes result sent to driver\n",
      "25/06/27 09:22:38 INFO TaskSetManager: Starting task 19.0 in stage 36.0 (TID 225) (hal9000, executor driver, partition 19, PROCESS_LOCAL, 7895 bytes) \n",
      "25/06/27 09:22:38 INFO Executor: Running task 19.0 in stage 36.0 (TID 225)\n",
      "25/06/27 09:22:38 INFO TaskSetManager: Finished task 10.0 in stage 36.0 (TID 216) in 43356 ms on hal9000 (executor driver) (12/33)\n",
      "25/06/27 09:22:38 INFO FileScanRDD: Reading File path: s3a://datalake/climate.csv, range: 2550136832-2684354560, partition values: [empty row]\n",
      "25/06/27 09:22:38 INFO Executor: Finished task 15.0 in stage 36.0 (TID 221). 2083 bytes result sent to driver\n",
      "25/06/27 09:22:38 INFO TaskSetManager: Starting task 20.0 in stage 36.0 (TID 226) (hal9000, executor driver, partition 20, PROCESS_LOCAL, 7895 bytes) \n",
      "25/06/27 09:22:38 INFO Executor: Running task 20.0 in stage 36.0 (TID 226)\n",
      "25/06/27 09:22:38 INFO TaskSetManager: Finished task 15.0 in stage 36.0 (TID 221) in 38564 ms on hal9000 (executor driver) (13/33)\n",
      "25/06/27 09:22:38 INFO FileScanRDD: Reading File path: s3a://datalake/climate.csv, range: 2684354560-2818572288, partition values: [empty row]\n",
      "25/06/27 09:22:39 INFO Executor: Finished task 12.0 in stage 36.0 (TID 218). 2126 bytes result sent to driver\n",
      "25/06/27 09:22:39 INFO TaskSetManager: Starting task 21.0 in stage 36.0 (TID 227) (hal9000, executor driver, partition 21, PROCESS_LOCAL, 7895 bytes) \n",
      "25/06/27 09:22:39 INFO Executor: Running task 21.0 in stage 36.0 (TID 227)\n",
      "25/06/27 09:22:39 INFO TaskSetManager: Finished task 12.0 in stage 36.0 (TID 218) in 41644 ms on hal9000 (executor driver) (14/33)\n",
      "25/06/27 09:22:39 INFO FileScanRDD: Reading File path: s3a://datalake/climate.csv, range: 2818572288-2952790016, partition values: [empty row]\n",
      "25/06/27 09:22:43 INFO Executor: Finished task 13.0 in stage 36.0 (TID 219). 2083 bytes result sent to driver\n",
      "25/06/27 09:22:43 INFO TaskSetManager: Starting task 22.0 in stage 36.0 (TID 228) (hal9000, executor driver, partition 22, PROCESS_LOCAL, 7895 bytes) \n",
      "25/06/27 09:22:43 INFO TaskSetManager: Finished task 13.0 in stage 36.0 (TID 219) in 43998 ms on hal9000 (executor driver) (15/33)\n",
      "25/06/27 09:22:43 INFO Executor: Running task 22.0 in stage 36.0 (TID 228)\n",
      "25/06/27 09:22:43 INFO FileScanRDD: Reading File path: s3a://datalake/climate.csv, range: 2952790016-3087007744, partition values: [empty row]\n",
      "25/06/27 09:22:43 INFO Executor: Finished task 14.0 in stage 36.0 (TID 220). 2083 bytes result sent to driver\n",
      "25/06/27 09:22:43 INFO TaskSetManager: Starting task 23.0 in stage 36.0 (TID 229) (hal9000, executor driver, partition 23, PROCESS_LOCAL, 7895 bytes) \n",
      "25/06/27 09:22:43 INFO Executor: Running task 23.0 in stage 36.0 (TID 229)\n",
      "25/06/27 09:22:43 INFO TaskSetManager: Finished task 14.0 in stage 36.0 (TID 220) in 44008 ms on hal9000 (executor driver) (16/33)\n",
      "25/06/27 09:22:43 INFO FileScanRDD: Reading File path: s3a://datalake/climate.csv, range: 3087007744-3221225472, partition values: [empty row]\n",
      "[Stage 36:> (16 + 8) / 33][Stage 37:>  (0 + 0) / 33][Stage 38:>  (0 + 0) / 33]\r"
     ]
    }
   ],
   "source": [
    "# Transformação da Dimensão Clima\n",
    "\n",
    "df_fato_clima = (\n",
    "    df_clima.withColumn(\n",
    "            \"data_completa\",\n",
    "            F.expr(\"date_add(to_date(concat(YEAR, '-01-01')), DOY - 1)\")\n",
    "        ) \n",
    "        .join(df_data, [\"data_completa\"], \"left\") \n",
    "        .join(df_localidade, [\"cidade\", \"latitude\", \"longitude\"], \"left\")\n",
    "        .filter(F.col(\"localidade_pk\").isNotNull() & F.col(\"data_pk\").isNotNull()) # Elimina campos Nulos\n",
    "        .select(\n",
    "            F.col(\"data_pk\"),\n",
    "            F.col(\"localidade_pk\"),\n",
    "            F.round(F.col(\"T2M\"), 2).cast(DoubleType()).alias(\"temperatura_media\"),\n",
    "            F.round(F.col(\"T2M_MAX\"), 2).cast(DoubleType()).alias(\"temperatura_max\"),\n",
    "            F.round(F.col(\"T2M_MIN\"), 2).cast(DoubleType()).alias(\"temperatura_min\"),\n",
    "            F.round(F.col(\"ALLSKY_SFC_UV_INDEX\"), 2).cast(DoubleType()).alias(\"radiacao_uv\"),\n",
    "            F.round(F.col(\"ALLSKY_SFC_UVA\"), 2).cast(DoubleType()).alias(\"radiacao_uva\"),\n",
    "            F.round(F.col(\"ALLSKY_SFC_UVB\"), 2).cast(DoubleType()).alias(\"radiacao_uvb\"),\n",
    "            F.round(F.col(\"PRECTOTCORR\"), 2).cast(DoubleType()).alias(\"precipitacao\")\n",
    "        )\n",
    ")\n",
    "\n",
    "df_fato_clima.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd486a23",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "25/06/26 22:07:09 WARN WindowExec: No Partition Defined for Window operation! Moving all data to a single partition, this can cause serious performance degradation.\n",
      "25/06/26 22:07:09 WARN WindowExec: No Partition Defined for Window operation! Moving all data to a single partition, this can cause serious performance degradation.\n",
      "25/06/26 22:07:09 WARN WindowExec: No Partition Defined for Window operation! Moving all data to a single partition, this can cause serious performance degradation.\n",
      "25/06/26 22:08:24 WARN WindowExec: No Partition Defined for Window operation! Moving all data to a single partition, this can cause serious performance degradation.\n",
      "25/06/26 22:08:24 WARN WindowExec: No Partition Defined for Window operation! Moving all data to a single partition, this can cause serious performance degradation.\n",
      "25/06/26 22:08:24 WARN WindowExec: No Partition Defined for Window operation! Moving all data to a single partition, this can cause serious performance degradation.\n",
      "25/06/26 22:08:24 WARN WindowExec: No Partition Defined for Window operation! Moving all data to a single partition, this can cause serious performance degradation.\n",
      "25/06/26 22:08:24 WARN WindowExec: No Partition Defined for Window operation! Moving all data to a single partition, this can cause serious performance degradation.\n",
      "25/06/26 22:08:24 WARN WindowExec: No Partition Defined for Window operation! Moving all data to a single partition, this can cause serious performance degradation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------+-------------------+\n",
      "|estado_pk|             estado|\n",
      "+---------+-------------------+\n",
      "|        1|               Acre|\n",
      "|        2|            Alagoas|\n",
      "|        3|              Amapá|\n",
      "|        4|           Amazonas|\n",
      "|        5|              Bahia|\n",
      "|        6|              Ceará|\n",
      "|        7|   Distrito Federal|\n",
      "|        8|     Espírito Santo|\n",
      "|        9|              Goiás|\n",
      "|       10|           Maranhão|\n",
      "|       11|        Mato Grosso|\n",
      "|       12| Mato Grosso do Sul|\n",
      "|       13|       Minas Gerais|\n",
      "|       14|             Paraná|\n",
      "|       15|            Paraíba|\n",
      "|       16|               Pará|\n",
      "|       17|         Pernambuco|\n",
      "|       18|              Piauí|\n",
      "|       19|Rio Grande do Norte|\n",
      "|       20|  Rio Grande do Sul|\n",
      "+---------+-------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 372:=====================================================> (32 + 1) / 33]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+----+\n",
      "|ano_pk| ano|\n",
      "+------+----+\n",
      "|     1|2001|\n",
      "|     2|2002|\n",
      "|     3|2003|\n",
      "|     4|2004|\n",
      "|     5|2005|\n",
      "|     6|2006|\n",
      "|     7|2007|\n",
      "|     8|2008|\n",
      "|     9|2009|\n",
      "|    10|2010|\n",
      "|    11|2011|\n",
      "|    12|2012|\n",
      "|    13|2013|\n",
      "|    14|2014|\n",
      "|    15|2015|\n",
      "|    16|2016|\n",
      "|    17|2017|\n",
      "|    18|2018|\n",
      "|    19|2019|\n",
      "|    20|2020|\n",
      "+------+----+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "25/06/26 22:09:29 WARN WindowExec: No Partition Defined for Window operation! Moving all data to a single partition, this can cause serious performance degradation.\n",
      "25/06/26 22:09:29 WARN WindowExec: No Partition Defined for Window operation! Moving all data to a single partition, this can cause serious performance degradation.\n",
      "25/06/26 22:09:29 WARN WindowExec: No Partition Defined for Window operation! Moving all data to a single partition, this can cause serious performance degradation.\n",
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "# Criação temporaria dos dados do Estado e do Ano para Tabela de Fatos Cancer\n",
    "\n",
    "df_estado = (\n",
    "    df_localidade\n",
    "    .filter(F.col(\"estado\").isNotNull())\n",
    "    .select(F.col(\"estado\"))\n",
    "    .distinct()\n",
    ")\n",
    "\n",
    "window_estado = Window.orderBy(\"estado\")\n",
    "df_estado = (\n",
    "    df_estado\n",
    "    .withColumn(\"estado_pk\", F.row_number().over(window_estado))\n",
    "    \n",
    "\n",
    "    .select(\"estado_pk\", \"estado\")\n",
    ")\n",
    "\n",
    "df_ano = (\n",
    "    df_data\n",
    "    .select(F.col(\"data_ano\").alias(\"ano\"))\n",
    "    .distinct()\n",
    ")\n",
    "\n",
    "window_ano = Window.orderBy(\"ano\")\n",
    "df_ano = (\n",
    "    df_ano\n",
    "    .withColumn(\"ano_pk\", F.row_number().over(window_ano))\n",
    "    .select(\"ano_pk\", \"ano\")\n",
    ")\n",
    "\n",
    "df_estado.show()\n",
    "df_ano.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18c2dc50",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "25/06/26 22:09:30 WARN WindowExec: No Partition Defined for Window operation! Moving all data to a single partition, this can cause serious performance degradation.\n",
      "25/06/26 22:09:30 WARN WindowExec: No Partition Defined for Window operation! Moving all data to a single partition, this can cause serious performance degradation.\n",
      "25/06/26 22:09:30 WARN WindowExec: No Partition Defined for Window operation! Moving all data to a single partition, this can cause serious performance degradation.\n",
      "25/06/26 22:09:30 WARN WindowExec: No Partition Defined for Window operation! Moving all data to a single partition, this can cause serious performance degradation.\n",
      "25/06/26 22:09:30 WARN WindowExec: No Partition Defined for Window operation! Moving all data to a single partition, this can cause serious performance degradation.\n",
      "25/06/26 22:09:30 WARN WindowExec: No Partition Defined for Window operation! Moving all data to a single partition, this can cause serious performance degradation.\n",
      "25/06/26 22:09:31 WARN WindowExec: No Partition Defined for Window operation! Moving all data to a single partition, this can cause serious performance degradation.\n",
      "25/06/26 22:09:31 WARN WindowExec: No Partition Defined for Window operation! Moving all data to a single partition, this can cause serious performance degradation.\n",
      "25/06/26 22:09:31 WARN WindowExec: No Partition Defined for Window operation! Moving all data to a single partition, this can cause serious performance degradation.\n",
      "25/06/26 22:09:31 WARN WindowExec: No Partition Defined for Window operation! Moving all data to a single partition, this can cause serious performance degradation.\n",
      "25/06/26 22:09:31 WARN WindowExec: No Partition Defined for Window operation! Moving all data to a single partition, this can cause serious performance degradation.\n",
      "25/06/26 22:09:31 WARN WindowExec: No Partition Defined for Window operation! Moving all data to a single partition, this can cause serious performance degradation.\n",
      "25/06/26 22:10:11 WARN WindowExec: No Partition Defined for Window operation! Moving all data to a single partition, this can cause serious performance degradation.\n",
      "25/06/26 22:10:11 WARN WindowExec: No Partition Defined for Window operation! Moving all data to a single partition, this can cause serious performance degradation.\n",
      "25/06/26 22:10:11 WARN WindowExec: No Partition Defined for Window operation! Moving all data to a single partition, this can cause serious performance degradation.\n",
      "25/06/26 22:10:11 WARN WindowExec: No Partition Defined for Window operation! Moving all data to a single partition, this can cause serious performance degradation.\n",
      "25/06/26 22:10:11 WARN WindowExec: No Partition Defined for Window operation! Moving all data to a single partition, this can cause serious performance degradation.\n",
      "25/06/26 22:10:11 WARN WindowExec: No Partition Defined for Window operation! Moving all data to a single partition, this can cause serious performance degradation.\n",
      "25/06/26 22:10:11 WARN WindowExec: No Partition Defined for Window operation! Moving all data to a single partition, this can cause serious performance degradation.\n",
      "25/06/26 22:10:11 WARN WindowExec: No Partition Defined for Window operation! Moving all data to a single partition, this can cause serious performance degradation.\n",
      "25/06/26 22:10:11 WARN WindowExec: No Partition Defined for Window operation! Moving all data to a single partition, this can cause serious performance degradation.\n",
      "25/06/26 22:10:11 WARN WindowExec: No Partition Defined for Window operation! Moving all data to a single partition, this can cause serious performance degradation.\n",
      "25/06/26 22:10:11 WARN WindowExec: No Partition Defined for Window operation! Moving all data to a single partition, this can cause serious performance degradation.\n",
      "25/06/26 22:10:11 WARN WindowExec: No Partition Defined for Window operation! Moving all data to a single partition, this can cause serious performance degradation.\n",
      "25/06/26 22:10:11 WARN WindowExec: No Partition Defined for Window operation! Moving all data to a single partition, this can cause serious performance degradation.\n",
      "25/06/26 22:10:11 WARN WindowExec: No Partition Defined for Window operation! Moving all data to a single partition, this can cause serious performance degradation.\n",
      "25/06/26 22:10:11 WARN WindowExec: No Partition Defined for Window operation! Moving all data to a single partition, this can cause serious performance degradation.\n",
      "25/06/26 22:10:11 WARN WindowExec: No Partition Defined for Window operation! Moving all data to a single partition, this can cause serious performance degradation.\n",
      "25/06/26 22:10:11 WARN WindowExec: No Partition Defined for Window operation! Moving all data to a single partition, this can cause serious performance degradation.\n",
      "25/06/26 22:10:11 WARN WindowExec: No Partition Defined for Window operation! Moving all data to a single partition, this can cause serious performance degradation.\n",
      "25/06/26 22:10:12 WARN WindowExec: No Partition Defined for Window operation! Moving all data to a single partition, this can cause serious performance degradation.\n",
      "25/06/26 22:10:12 WARN WindowExec: No Partition Defined for Window operation! Moving all data to a single partition, this can cause serious performance degradation.\n",
      "25/06/26 22:10:12 WARN WindowExec: No Partition Defined for Window operation! Moving all data to a single partition, this can cause serious performance degradation.\n",
      "25/06/26 22:10:12 WARN WindowExec: No Partition Defined for Window operation! Moving all data to a single partition, this can cause serious performance degradation.\n",
      "25/06/26 22:10:12 WARN WindowExec: No Partition Defined for Window operation! Moving all data to a single partition, this can cause serious performance degradation.\n",
      "25/06/26 22:10:12 WARN WindowExec: No Partition Defined for Window operation! Moving all data to a single partition, this can cause serious performance degradation.\n",
      "25/06/26 22:10:49 WARN WindowExec: No Partition Defined for Window operation! Moving all data to a single partition, this can cause serious performance degradation.\n",
      "25/06/26 22:10:49 WARN WindowExec: No Partition Defined for Window operation! Moving all data to a single partition, this can cause serious performance degradation.\n",
      "25/06/26 22:10:49 WARN WindowExec: No Partition Defined for Window operation! Moving all data to a single partition, this can cause serious performance degradation.\n",
      "25/06/26 22:10:49 WARN WindowExec: No Partition Defined for Window operation! Moving all data to a single partition, this can cause serious performance degradation.\n",
      "25/06/26 22:10:49 WARN WindowExec: No Partition Defined for Window operation! Moving all data to a single partition, this can cause serious performance degradation.\n",
      "25/06/26 22:10:49 WARN WindowExec: No Partition Defined for Window operation! Moving all data to a single partition, this can cause serious performance degradation.\n",
      "25/06/26 22:10:49 WARN WindowExec: No Partition Defined for Window operation! Moving all data to a single partition, this can cause serious performance degradation.\n",
      "25/06/26 22:10:49 WARN WindowExec: No Partition Defined for Window operation! Moving all data to a single partition, this can cause serious performance degradation.\n",
      "25/06/26 22:10:49 WARN WindowExec: No Partition Defined for Window operation! Moving all data to a single partition, this can cause serious performance degradation.\n",
      "25/06/26 22:10:49 WARN WindowExec: No Partition Defined for Window operation! Moving all data to a single partition, this can cause serious performance degradation.\n",
      "25/06/26 22:10:49 WARN WindowExec: No Partition Defined for Window operation! Moving all data to a single partition, this can cause serious performance degradation.\n",
      "25/06/26 22:10:49 WARN WindowExec: No Partition Defined for Window operation! Moving all data to a single partition, this can cause serious performance degradation.\n",
      "25/06/26 22:10:50 WARN WindowExec: No Partition Defined for Window operation! Moving all data to a single partition, this can cause serious performance degradation.\n",
      "25/06/26 22:10:50 WARN WindowExec: No Partition Defined for Window operation! Moving all data to a single partition, this can cause serious performance degradation.\n",
      "25/06/26 22:10:50 WARN WindowExec: No Partition Defined for Window operation! Moving all data to a single partition, this can cause serious performance degradation.\n",
      "25/06/26 22:10:50 WARN WindowExec: No Partition Defined for Window operation! Moving all data to a single partition, this can cause serious performance degradation.\n",
      "25/06/26 22:10:50 WARN WindowExec: No Partition Defined for Window operation! Moving all data to a single partition, this can cause serious performance degradation.\n",
      "25/06/26 22:10:50 WARN WindowExec: No Partition Defined for Window operation! Moving all data to a single partition, this can cause serious performance degradation.\n",
      "25/06/26 22:10:50 WARN WindowExec: No Partition Defined for Window operation! Moving all data to a single partition, this can cause serious performance degradation.\n",
      "25/06/26 22:10:50 WARN WindowExec: No Partition Defined for Window operation! Moving all data to a single partition, this can cause serious performance degradation.\n",
      "25/06/26 22:10:50 WARN WindowExec: No Partition Defined for Window operation! Moving all data to a single partition, this can cause serious performance degradation.\n",
      "25/06/26 22:10:50 WARN WindowExec: No Partition Defined for Window operation! Moving all data to a single partition, this can cause serious performance degradation.\n",
      "25/06/26 22:10:50 WARN WindowExec: No Partition Defined for Window operation! Moving all data to a single partition, this can cause serious performance degradation.\n",
      "25/06/26 22:10:50 WARN WindowExec: No Partition Defined for Window operation! Moving all data to a single partition, this can cause serious performance degradation.\n",
      "25/06/26 22:10:50 WARN WindowExec: No Partition Defined for Window operation! Moving all data to a single partition, this can cause serious performance degradation.\n",
      "25/06/26 22:10:50 WARN WindowExec: No Partition Defined for Window operation! Moving all data to a single partition, this can cause serious performance degradation.\n",
      "25/06/26 22:10:50 WARN WindowExec: No Partition Defined for Window operation! Moving all data to a single partition, this can cause serious performance degradation.\n",
      "25/06/26 22:10:50 WARN WindowExec: No Partition Defined for Window operation! Moving all data to a single partition, this can cause serious performance degradation.\n",
      "25/06/26 22:10:50 WARN WindowExec: No Partition Defined for Window operation! Moving all data to a single partition, this can cause serious performance degradation.\n",
      "25/06/26 22:10:50 WARN WindowExec: No Partition Defined for Window operation! Moving all data to a single partition, this can cause serious performance degradation.\n",
      "25/06/26 22:10:50 WARN WindowExec: No Partition Defined for Window operation! Moving all data to a single partition, this can cause serious performance degradation.\n",
      "25/06/26 22:10:50 WARN WindowExec: No Partition Defined for Window operation! Moving all data to a single partition, this can cause serious performance degradation.\n",
      "25/06/26 22:10:50 WARN WindowExec: No Partition Defined for Window operation! Moving all data to a single partition, this can cause serious performance degradation.\n",
      "25/06/26 22:10:50 WARN WindowExec: No Partition Defined for Window operation! Moving all data to a single partition, this can cause serious performance degradation.\n",
      "25/06/26 22:10:50 WARN WindowExec: No Partition Defined for Window operation! Moving all data to a single partition, this can cause serious performance degradation.\n",
      "25/06/26 22:10:50 WARN WindowExec: No Partition Defined for Window operation! Moving all data to a single partition, this can cause serious performance degradation.\n",
      "25/06/26 22:10:50 WARN WindowExec: No Partition Defined for Window operation! Moving all data to a single partition, this can cause serious performance degradation.\n",
      "25/06/26 22:10:50 WARN WindowExec: No Partition Defined for Window operation! Moving all data to a single partition, this can cause serious performance degradation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Numero de Tuplas:  204120\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "25/06/26 22:10:52 WARN WindowExec: No Partition Defined for Window operation! Moving all data to a single partition, this can cause serious performance degradation.\n",
      "25/06/26 22:10:52 WARN WindowExec: No Partition Defined for Window operation! Moving all data to a single partition, this can cause serious performance degradation.\n",
      "25/06/26 22:10:52 WARN WindowExec: No Partition Defined for Window operation! Moving all data to a single partition, this can cause serious performance degradation.\n",
      "25/06/26 22:10:52 WARN WindowExec: No Partition Defined for Window operation! Moving all data to a single partition, this can cause serious performance degradation.\n",
      "25/06/26 22:10:52 WARN WindowExec: No Partition Defined for Window operation! Moving all data to a single partition, this can cause serious performance degradation.\n",
      "25/06/26 22:10:52 WARN WindowExec: No Partition Defined for Window operation! Moving all data to a single partition, this can cause serious performance degradation.\n",
      "25/06/26 22:10:53 WARN WindowExec: No Partition Defined for Window operation! Moving all data to a single partition, this can cause serious performance degradation.\n",
      "25/06/26 22:10:53 WARN WindowExec: No Partition Defined for Window operation! Moving all data to a single partition, this can cause serious performance degradation.\n",
      "25/06/26 22:10:53 WARN WindowExec: No Partition Defined for Window operation! Moving all data to a single partition, this can cause serious performance degradation.\n",
      "25/06/26 22:10:53 WARN WindowExec: No Partition Defined for Window operation! Moving all data to a single partition, this can cause serious performance degradation.\n",
      "25/06/26 22:10:53 WARN WindowExec: No Partition Defined for Window operation! Moving all data to a single partition, this can cause serious performance degradation.\n",
      "25/06/26 22:10:53 WARN WindowExec: No Partition Defined for Window operation! Moving all data to a single partition, this can cause serious performance degradation.\n",
      "25/06/26 22:11:31 WARN WindowExec: No Partition Defined for Window operation! Moving all data to a single partition, this can cause serious performance degradation.\n",
      "25/06/26 22:11:31 WARN WindowExec: No Partition Defined for Window operation! Moving all data to a single partition, this can cause serious performance degradation.\n",
      "25/06/26 22:11:31 WARN WindowExec: No Partition Defined for Window operation! Moving all data to a single partition, this can cause serious performance degradation.\n",
      "25/06/26 22:11:31 WARN WindowExec: No Partition Defined for Window operation! Moving all data to a single partition, this can cause serious performance degradation.\n",
      "25/06/26 22:11:31 WARN WindowExec: No Partition Defined for Window operation! Moving all data to a single partition, this can cause serious performance degradation.\n",
      "25/06/26 22:11:31 WARN WindowExec: No Partition Defined for Window operation! Moving all data to a single partition, this can cause serious performance degradation.\n",
      "25/06/26 22:11:31 WARN WindowExec: No Partition Defined for Window operation! Moving all data to a single partition, this can cause serious performance degradation.\n",
      "25/06/26 22:11:31 WARN WindowExec: No Partition Defined for Window operation! Moving all data to a single partition, this can cause serious performance degradation.\n",
      "25/06/26 22:11:31 WARN WindowExec: No Partition Defined for Window operation! Moving all data to a single partition, this can cause serious performance degradation.\n",
      "25/06/26 22:11:31 WARN WindowExec: No Partition Defined for Window operation! Moving all data to a single partition, this can cause serious performance degradation.\n",
      "25/06/26 22:11:31 WARN WindowExec: No Partition Defined for Window operation! Moving all data to a single partition, this can cause serious performance degradation.\n",
      "25/06/26 22:11:31 WARN WindowExec: No Partition Defined for Window operation! Moving all data to a single partition, this can cause serious performance degradation.\n",
      "25/06/26 22:11:32 WARN WindowExec: No Partition Defined for Window operation! Moving all data to a single partition, this can cause serious performance degradation.\n",
      "25/06/26 22:11:32 WARN WindowExec: No Partition Defined for Window operation! Moving all data to a single partition, this can cause serious performance degradation.\n",
      "25/06/26 22:11:32 WARN WindowExec: No Partition Defined for Window operation! Moving all data to a single partition, this can cause serious performance degradation.\n",
      "25/06/26 22:11:32 WARN WindowExec: No Partition Defined for Window operation! Moving all data to a single partition, this can cause serious performance degradation.\n",
      "25/06/26 22:11:32 WARN WindowExec: No Partition Defined for Window operation! Moving all data to a single partition, this can cause serious performance degradation.\n",
      "25/06/26 22:11:32 WARN WindowExec: No Partition Defined for Window operation! Moving all data to a single partition, this can cause serious performance degradation.\n",
      "25/06/26 22:11:33 WARN WindowExec: No Partition Defined for Window operation! Moving all data to a single partition, this can cause serious performance degradation.\n",
      "25/06/26 22:11:33 WARN WindowExec: No Partition Defined for Window operation! Moving all data to a single partition, this can cause serious performance degradation.\n",
      "25/06/26 22:11:33 WARN WindowExec: No Partition Defined for Window operation! Moving all data to a single partition, this can cause serious performance degradation.\n",
      "25/06/26 22:11:33 WARN WindowExec: No Partition Defined for Window operation! Moving all data to a single partition, this can cause serious performance degradation.\n",
      "25/06/26 22:11:33 WARN WindowExec: No Partition Defined for Window operation! Moving all data to a single partition, this can cause serious performance degradation.\n",
      "25/06/26 22:11:33 WARN WindowExec: No Partition Defined for Window operation! Moving all data to a single partition, this can cause serious performance degradation.\n",
      "25/06/26 22:12:10 WARN WindowExec: No Partition Defined for Window operation! Moving all data to a single partition, this can cause serious performance degradation.\n",
      "25/06/26 22:12:10 WARN WindowExec: No Partition Defined for Window operation! Moving all data to a single partition, this can cause serious performance degradation.\n",
      "25/06/26 22:12:10 WARN WindowExec: No Partition Defined for Window operation! Moving all data to a single partition, this can cause serious performance degradation.\n",
      "25/06/26 22:12:10 WARN WindowExec: No Partition Defined for Window operation! Moving all data to a single partition, this can cause serious performance degradation.\n",
      "25/06/26 22:12:10 WARN WindowExec: No Partition Defined for Window operation! Moving all data to a single partition, this can cause serious performance degradation.\n",
      "25/06/26 22:12:10 WARN WindowExec: No Partition Defined for Window operation! Moving all data to a single partition, this can cause serious performance degradation.\n",
      "25/06/26 22:12:10 WARN WindowExec: No Partition Defined for Window operation! Moving all data to a single partition, this can cause serious performance degradation.\n",
      "25/06/26 22:12:10 WARN WindowExec: No Partition Defined for Window operation! Moving all data to a single partition, this can cause serious performance degradation.\n",
      "25/06/26 22:12:10 WARN WindowExec: No Partition Defined for Window operation! Moving all data to a single partition, this can cause serious performance degradation.\n",
      "25/06/26 22:12:10 WARN WindowExec: No Partition Defined for Window operation! Moving all data to a single partition, this can cause serious performance degradation.\n",
      "25/06/26 22:12:10 WARN WindowExec: No Partition Defined for Window operation! Moving all data to a single partition, this can cause serious performance degradation.\n",
      "25/06/26 22:12:10 WARN WindowExec: No Partition Defined for Window operation! Moving all data to a single partition, this can cause serious performance degradation.\n",
      "25/06/26 22:12:10 WARN WindowExec: No Partition Defined for Window operation! Moving all data to a single partition, this can cause serious performance degradation.\n",
      "25/06/26 22:12:10 WARN WindowExec: No Partition Defined for Window operation! Moving all data to a single partition, this can cause serious performance degradation.\n",
      "25/06/26 22:12:10 WARN WindowExec: No Partition Defined for Window operation! Moving all data to a single partition, this can cause serious performance degradation.\n",
      "25/06/26 22:12:10 WARN WindowExec: No Partition Defined for Window operation! Moving all data to a single partition, this can cause serious performance degradation.\n",
      "25/06/26 22:12:10 WARN WindowExec: No Partition Defined for Window operation! Moving all data to a single partition, this can cause serious performance degradation.\n",
      "25/06/26 22:12:10 WARN WindowExec: No Partition Defined for Window operation! Moving all data to a single partition, this can cause serious performance degradation.\n",
      "25/06/26 22:12:11 WARN WindowExec: No Partition Defined for Window operation! Moving all data to a single partition, this can cause serious performance degradation.\n",
      "25/06/26 22:12:11 WARN WindowExec: No Partition Defined for Window operation! Moving all data to a single partition, this can cause serious performance degradation.\n",
      "25/06/26 22:12:11 WARN WindowExec: No Partition Defined for Window operation! Moving all data to a single partition, this can cause serious performance degradation.\n",
      "25/06/26 22:12:11 WARN WindowExec: No Partition Defined for Window operation! Moving all data to a single partition, this can cause serious performance degradation.\n",
      "25/06/26 22:12:11 WARN WindowExec: No Partition Defined for Window operation! Moving all data to a single partition, this can cause serious performance degradation.\n",
      "25/06/26 22:12:11 WARN WindowExec: No Partition Defined for Window operation! Moving all data to a single partition, this can cause serious performance degradation.\n",
      "25/06/26 22:12:11 WARN WindowExec: No Partition Defined for Window operation! Moving all data to a single partition, this can cause serious performance degradation.\n",
      "25/06/26 22:12:11 WARN WindowExec: No Partition Defined for Window operation! Moving all data to a single partition, this can cause serious performance degradation.\n",
      "[Stage 461:===================>                                     (1 + 2) / 3]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+---------+-------+--------+--------------+----------+-----------------+------------------+-------------+\n",
      "|ano_pk|estado_pk|sexo_pk|faixa_pk|tipo_cancer_pk|metrica_pk|incidencia_cancer|prevalencia_cancer|obitos_cancer|\n",
      "+------+---------+-------+--------+--------------+----------+-----------------+------------------+-------------+\n",
      "|    21|       11|      1|      14|             1|         1|            2.861|             8.207|         1.68|\n",
      "|     4|        8|      1|       3|             2|         1|            1.607|             2.491|        1.675|\n",
      "|    16|        2|      0|      16|             1|         1|            0.557|             0.327|        0.577|\n",
      "|    10|       16|      1|       4|             1|         1|            0.787|             4.473|        0.351|\n",
      "|    18|       14|      1|       5|             1|         3|            11.45|            29.483|        7.128|\n",
      "|    14|       27|      0|      13|             1|         3|            0.557|             4.397|        0.153|\n",
      "|     9|       11|      0|       8|             1|         2|              0.0|               0.0|        0.001|\n",
      "|    17|        3|      0|      16|             1|         2|              0.0|               0.0|        0.001|\n",
      "|    16|       14|      0|       8|             0|         2|            0.001|               0.0|          0.0|\n",
      "|    11|       21|      0|      17|             1|         2|              0.0|               0.0|        0.002|\n",
      "|     6|       19|      0|       9|             1|         1|             0.29|             0.151|         0.35|\n",
      "|    19|       25|      1|       3|             2|         1|             5.92|             6.543|        2.172|\n",
      "|    10|       13|      0|       7|             2|         1|            21.71|            27.072|        3.223|\n",
      "|     7|       21|      1|       0|             2|         3|            0.969|             1.237|        0.298|\n",
      "|     1|        6|      0|       2|             2|         3|            0.072|             0.104|        0.076|\n",
      "|     9|       26|      1|      17|             1|         3|            7.442|            23.551|        4.303|\n",
      "|     7|        2|      0|      14|             0|         2|              0.0|               0.0|          0.0|\n",
      "|     8|       16|      1|       7|             2|         2|              0.0|               0.0|        0.002|\n",
      "|    21|       23|      0|      19|             2|         2|              0.0|               0.0|          0.0|\n",
      "|    19|       14|      0|       1|             0|         1|           88.716|            12.108|          0.0|\n",
      "+------+---------+-------+--------+--------------+----------+-----------------+------------------+-------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "# Transformação da Tabela de Fatos Cancer\n",
    "\n",
    "df_fato_cancer = (\n",
    "    df_cancer\n",
    "    .join(df_estado, df_cancer.location_name == df_estado.estado, \"left\")\n",
    "    .join(df_sexo, df_cancer.sex_name == df_sexo.sexo, \"left\")\n",
    "    .join(df_faixa_etaria, df_cancer.age_id == df_faixa_etaria.id_idade, \"left\") \n",
    "    .join(df_tipo_cancer, df_cancer.cause_name == df_tipo_cancer.tipo_cancer, \"left\")\n",
    "    .join(df_ano, df_cancer.year == df_ano.ano, \"left\")\n",
    "    .join(df_metrica, df_cancer.metric_name == df_metrica.tipo_metrica, \"left\")\n",
    "    .groupBy(\"ano_pk\", \"estado_pk\", \"sexo_pk\", \"faixa_pk\", \"tipo_cancer_pk\", \"metrica_pk\")\n",
    "    .pivot(\"measure_name\")\n",
    "    .agg(F.sum(\"val\"))\n",
    ")\n",
    "\n",
    "group_cols = [\"ano_pk\", \"estado_pk\", \"sexo_pk\", \"faixa_pk\", \"tipo_cancer_pk\", \"metrica_pk\"]\n",
    "pivot_cols = [c for c in df_fato_cancer.columns if c not in group_cols]\n",
    "\n",
    "for col_name in pivot_cols:\n",
    "    df_fato_cancer = df_fato_cancer.withColumn(\n",
    "        col_name,\n",
    "        F.round(F.coalesce(F.col(col_name), F.lit(0.0)), 3).cast(DoubleType())\n",
    "    )\n",
    "\n",
    "df_fato_cancer = df_fato_cancer \\\n",
    "    .withColumnRenamed(\"Incidência\", \"incidencia_cancer\") \\\n",
    "    .withColumnRenamed(\"Prevalência\", \"prevalencia_cancer\") \\\n",
    "    .withColumnRenamed(\"Óbitos\", \"obitos_cancer\")\n",
    "\n",
    "df_fato_cancer.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "83d67320",
   "metadata": {},
   "source": [
    "## Load"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d14a3d37",
   "metadata": {},
   "outputs": [],
   "source": [
    "load_dotenv() \n",
    "\n",
    "DB_HOST = os.getenv(\"DB_HOST\")\n",
    "DB_PORT = os.getenv(\"DB_PORT\")\n",
    "DB_NAME = os.getenv(\"DB_NAME\")\n",
    "DB_USER = os.getenv(\"DB_USER\")\n",
    "DB_PASSWORD = os.getenv(\"DB_PASSWORD\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aef67985",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "25/06/26 22:12:13 WARN WindowExec: No Partition Defined for Window operation! Moving all data to a single partition, this can cause serious performance degradation.\n",
      "25/06/26 22:12:13 WARN WindowExec: No Partition Defined for Window operation! Moving all data to a single partition, this can cause serious performance degradation.\n",
      "25/06/26 22:12:13 WARN WindowExec: No Partition Defined for Window operation! Moving all data to a single partition, this can cause serious performance degradation.\n",
      "25/06/26 22:12:53 WARN WindowExec: No Partition Defined for Window operation! Moving all data to a single partition, this can cause serious performance degradation.\n",
      "25/06/26 22:12:53 WARN WindowExec: No Partition Defined for Window operation! Moving all data to a single partition, this can cause serious performance degradation.\n",
      "25/06/26 22:12:53 WARN WindowExec: No Partition Defined for Window operation! Moving all data to a single partition, this can cause serious performance degradation.\n",
      "25/06/26 22:12:53 WARN WindowExec: No Partition Defined for Window operation! Moving all data to a single partition, this can cause serious performance degradation.\n",
      "25/06/26 22:12:53 WARN WindowExec: No Partition Defined for Window operation! Moving all data to a single partition, this can cause serious performance degradation.\n",
      "25/06/26 22:12:53 WARN WindowExec: No Partition Defined for Window operation! Moving all data to a single partition, this can cause serious performance degradation.\n",
      "25/06/26 22:12:53 WARN WindowExec: No Partition Defined for Window operation! Moving all data to a single partition, this can cause serious performance degradation.\n",
      "25/06/26 22:13:38 WARN WindowExec: No Partition Defined for Window operation! Moving all data to a single partition, this can cause serious performance degradation.\n",
      "25/06/26 22:13:38 WARN WindowExec: No Partition Defined for Window operation! Moving all data to a single partition, this can cause serious performance degradation.\n",
      "25/06/26 22:13:38 WARN WindowExec: No Partition Defined for Window operation! Moving all data to a single partition, this can cause serious performance degradation.\n",
      "25/06/26 22:13:38 WARN WindowExec: No Partition Defined for Window operation! Moving all data to a single partition, this can cause serious performance degradation.\n",
      "25/06/26 22:13:41 WARN WindowExec: No Partition Defined for Window operation! Moving all data to a single partition, this can cause serious performance degradation.\n",
      "25/06/26 22:13:41 WARN WindowExec: No Partition Defined for Window operation! Moving all data to a single partition, this can cause serious performance degradation.\n",
      "25/06/26 22:13:41 WARN WindowExec: No Partition Defined for Window operation! Moving all data to a single partition, this can cause serious performance degradation.\n",
      "25/06/26 22:13:41 WARN WindowExec: No Partition Defined for Window operation! Moving all data to a single partition, this can cause serious performance degradation.\n",
      "25/06/26 22:13:41 WARN WindowExec: No Partition Defined for Window operation! Moving all data to a single partition, this can cause serious performance degradation.\n",
      "25/06/26 22:13:41 WARN WindowExec: No Partition Defined for Window operation! Moving all data to a single partition, this can cause serious performance degradation.\n",
      "25/06/26 22:13:41 WARN WindowExec: No Partition Defined for Window operation! Moving all data to a single partition, this can cause serious performance degradation.\n",
      "25/06/26 22:13:42 WARN WindowExec: No Partition Defined for Window operation! Moving all data to a single partition, this can cause serious performance degradation.\n",
      "25/06/26 22:13:42 WARN WindowExec: No Partition Defined for Window operation! Moving all data to a single partition, this can cause serious performance degradation.\n",
      "25/06/26 22:13:42 WARN WindowExec: No Partition Defined for Window operation! Moving all data to a single partition, this can cause serious performance degradation.\n",
      "25/06/26 22:13:42 WARN WindowExec: No Partition Defined for Window operation! Moving all data to a single partition, this can cause serious performance degradation.\n",
      "25/06/26 22:14:53 WARN WindowExec: No Partition Defined for Window operation! Moving all data to a single partition, this can cause serious performance degradation.\n",
      "25/06/26 22:14:53 WARN WindowExec: No Partition Defined for Window operation! Moving all data to a single partition, this can cause serious performance degradation.\n",
      "25/06/26 22:14:53 WARN WindowExec: No Partition Defined for Window operation! Moving all data to a single partition, this can cause serious performance degradation.\n",
      "25/06/26 22:14:53 WARN WindowExec: No Partition Defined for Window operation! Moving all data to a single partition, this can cause serious performance degradation.\n",
      "25/06/26 22:15:40 WARN WindowExec: No Partition Defined for Window operation! Moving all data to a single partition, this can cause serious performance degradation.\n",
      "25/06/26 22:15:40 WARN WindowExec: No Partition Defined for Window operation! Moving all data to a single partition, this can cause serious performance degradation.\n",
      "25/06/26 22:15:40 WARN WindowExec: No Partition Defined for Window operation! Moving all data to a single partition, this can cause serious performance degradation.\n",
      "25/06/26 22:15:40 WARN WindowExec: No Partition Defined for Window operation! Moving all data to a single partition, this can cause serious performance degradation.\n",
      "25/06/26 22:16:33 WARN WindowExec: No Partition Defined for Window operation! Moving all data to a single partition, this can cause serious performance degradation.\n",
      "25/06/26 22:16:33 WARN WindowExec: No Partition Defined for Window operation! Moving all data to a single partition, this can cause serious performance degradation.\n",
      "25/06/26 22:16:33 WARN WindowExec: No Partition Defined for Window operation! Moving all data to a single partition, this can cause serious performance degradation.\n",
      "25/06/26 22:16:33 WARN WindowExec: No Partition Defined for Window operation! Moving all data to a single partition, this can cause serious performance degradation.\n",
      "25/06/26 22:16:33 WARN WindowExec: No Partition Defined for Window operation! Moving all data to a single partition, this can cause serious performance degradation.\n",
      "25/06/26 22:16:33 WARN WindowExec: No Partition Defined for Window operation! Moving all data to a single partition, this can cause serious performance degradation.\n",
      "25/06/26 22:16:35 WARN WindowExec: No Partition Defined for Window operation! Moving all data to a single partition, this can cause serious performance degradation.\n",
      "25/06/26 22:16:35 WARN WindowExec: No Partition Defined for Window operation! Moving all data to a single partition, this can cause serious performance degradation.\n",
      "25/06/26 22:16:46 WARN WindowExec: No Partition Defined for Window operation! Moving all data to a single partition, this can cause serious performance degradation.\n",
      "25/06/26 22:16:46 WARN WindowExec: No Partition Defined for Window operation! Moving all data to a single partition, this can cause serious performance degradation.\n",
      "25/06/26 22:20:38 WARN WindowExec: No Partition Defined for Window operation! Moving all data to a single partition, this can cause serious performance degradation.\n",
      "25/06/26 22:20:38 WARN WindowExec: No Partition Defined for Window operation! Moving all data to a single partition, this can cause serious performance degradation.\n",
      "25/06/26 22:20:38 WARN WindowExec: No Partition Defined for Window operation! Moving all data to a single partition, this can cause serious performance degradation.\n",
      "25/06/26 22:20:38 WARN WindowExec: No Partition Defined for Window operation! Moving all data to a single partition, this can cause serious performance degradation.\n",
      "25/06/26 22:20:38 WARN WindowExec: No Partition Defined for Window operation! Moving all data to a single partition, this can cause serious performance degradation.\n",
      "25/06/26 22:20:38 WARN WindowExec: No Partition Defined for Window operation! Moving all data to a single partition, this can cause serious performance degradation.\n",
      "25/06/26 22:20:40 WARN WindowExec: No Partition Defined for Window operation! Moving all data to a single partition, this can cause serious performance degradation.\n",
      "25/06/26 22:20:40 WARN WindowExec: No Partition Defined for Window operation! Moving all data to a single partition, this can cause serious performance degradation.\n",
      "25/06/26 22:20:40 WARN WindowExec: No Partition Defined for Window operation! Moving all data to a single partition, this can cause serious performance degradation.\n",
      "25/06/26 22:20:40 WARN WindowExec: No Partition Defined for Window operation! Moving all data to a single partition, this can cause serious performance degradation.\n",
      "25/06/26 22:20:40 WARN WindowExec: No Partition Defined for Window operation! Moving all data to a single partition, this can cause serious performance degradation.\n",
      "25/06/26 22:20:40 WARN WindowExec: No Partition Defined for Window operation! Moving all data to a single partition, this can cause serious performance degradation.\n",
      "25/06/26 22:21:25 WARN WindowExec: No Partition Defined for Window operation! Moving all data to a single partition, this can cause serious performance degradation.\n",
      "25/06/26 22:21:25 WARN WindowExec: No Partition Defined for Window operation! Moving all data to a single partition, this can cause serious performance degradation.\n",
      "25/06/26 22:21:25 WARN WindowExec: No Partition Defined for Window operation! Moving all data to a single partition, this can cause serious performance degradation.\n",
      "25/06/26 22:21:25 WARN WindowExec: No Partition Defined for Window operation! Moving all data to a single partition, this can cause serious performance degradation.\n",
      "25/06/26 22:21:25 WARN WindowExec: No Partition Defined for Window operation! Moving all data to a single partition, this can cause serious performance degradation.\n",
      "25/06/26 22:21:25 WARN WindowExec: No Partition Defined for Window operation! Moving all data to a single partition, this can cause serious performance degradation.\n",
      "25/06/26 22:21:25 WARN WindowExec: No Partition Defined for Window operation! Moving all data to a single partition, this can cause serious performance degradation.\n",
      "25/06/26 22:21:25 WARN WindowExec: No Partition Defined for Window operation! Moving all data to a single partition, this can cause serious performance degradation.\n",
      "25/06/26 22:21:25 WARN WindowExec: No Partition Defined for Window operation! Moving all data to a single partition, this can cause serious performance degradation.\n",
      "25/06/26 22:21:25 WARN WindowExec: No Partition Defined for Window operation! Moving all data to a single partition, this can cause serious performance degradation.\n",
      "25/06/26 22:21:25 WARN WindowExec: No Partition Defined for Window operation! Moving all data to a single partition, this can cause serious performance degradation.\n",
      "25/06/26 22:21:25 WARN WindowExec: No Partition Defined for Window operation! Moving all data to a single partition, this can cause serious performance degradation.\n",
      "25/06/26 22:21:26 WARN WindowExec: No Partition Defined for Window operation! Moving all data to a single partition, this can cause serious performance degradation.\n",
      "25/06/26 22:21:26 WARN WindowExec: No Partition Defined for Window operation! Moving all data to a single partition, this can cause serious performance degradation.\n",
      "25/06/26 22:21:26 WARN WindowExec: No Partition Defined for Window operation! Moving all data to a single partition, this can cause serious performance degradation.\n",
      "25/06/26 22:21:26 WARN WindowExec: No Partition Defined for Window operation! Moving all data to a single partition, this can cause serious performance degradation.\n",
      "25/06/26 22:21:26 WARN WindowExec: No Partition Defined for Window operation! Moving all data to a single partition, this can cause serious performance degradation.\n",
      "25/06/26 22:21:26 WARN WindowExec: No Partition Defined for Window operation! Moving all data to a single partition, this can cause serious performance degradation.\n",
      "25/06/26 22:21:27 WARN WindowExec: No Partition Defined for Window operation! Moving all data to a single partition, this can cause serious performance degradation.\n",
      "25/06/26 22:21:27 WARN WindowExec: No Partition Defined for Window operation! Moving all data to a single partition, this can cause serious performance degradation.\n",
      "25/06/26 22:21:27 WARN WindowExec: No Partition Defined for Window operation! Moving all data to a single partition, this can cause serious performance degradation.\n",
      "25/06/26 22:21:27 WARN WindowExec: No Partition Defined for Window operation! Moving all data to a single partition, this can cause serious performance degradation.\n",
      "25/06/26 22:21:27 WARN WindowExec: No Partition Defined for Window operation! Moving all data to a single partition, this can cause serious performance degradation.\n",
      "25/06/26 22:21:27 WARN WindowExec: No Partition Defined for Window operation! Moving all data to a single partition, this can cause serious performance degradation.\n",
      "25/06/26 22:22:13 WARN WindowExec: No Partition Defined for Window operation! Moving all data to a single partition, this can cause serious performance degradation.\n",
      "25/06/26 22:22:13 WARN WindowExec: No Partition Defined for Window operation! Moving all data to a single partition, this can cause serious performance degradation.\n",
      "25/06/26 22:22:13 WARN WindowExec: No Partition Defined for Window operation! Moving all data to a single partition, this can cause serious performance degradation.\n",
      "25/06/26 22:22:13 WARN WindowExec: No Partition Defined for Window operation! Moving all data to a single partition, this can cause serious performance degradation.\n",
      "25/06/26 22:22:13 WARN WindowExec: No Partition Defined for Window operation! Moving all data to a single partition, this can cause serious performance degradation.\n",
      "25/06/26 22:22:13 WARN WindowExec: No Partition Defined for Window operation! Moving all data to a single partition, this can cause serious performance degradation.\n",
      "25/06/26 22:22:13 WARN WindowExec: No Partition Defined for Window operation! Moving all data to a single partition, this can cause serious performance degradation.\n",
      "25/06/26 22:22:13 WARN WindowExec: No Partition Defined for Window operation! Moving all data to a single partition, this can cause serious performance degradation.\n",
      "25/06/26 22:22:13 WARN WindowExec: No Partition Defined for Window operation! Moving all data to a single partition, this can cause serious performance degradation.\n",
      "25/06/26 22:22:13 WARN WindowExec: No Partition Defined for Window operation! Moving all data to a single partition, this can cause serious performance degradation.\n",
      "25/06/26 22:22:13 WARN WindowExec: No Partition Defined for Window operation! Moving all data to a single partition, this can cause serious performance degradation.\n",
      "25/06/26 22:22:13 WARN WindowExec: No Partition Defined for Window operation! Moving all data to a single partition, this can cause serious performance degradation.\n",
      "25/06/26 22:22:13 WARN WindowExec: No Partition Defined for Window operation! Moving all data to a single partition, this can cause serious performance degradation.\n",
      "25/06/26 22:22:13 WARN WindowExec: No Partition Defined for Window operation! Moving all data to a single partition, this can cause serious performance degradation.\n",
      "25/06/26 22:22:13 WARN WindowExec: No Partition Defined for Window operation! Moving all data to a single partition, this can cause serious performance degradation.\n",
      "25/06/26 22:22:13 WARN WindowExec: No Partition Defined for Window operation! Moving all data to a single partition, this can cause serious performance degradation.\n",
      "25/06/26 22:22:13 WARN WindowExec: No Partition Defined for Window operation! Moving all data to a single partition, this can cause serious performance degradation.\n",
      "25/06/26 22:22:13 WARN WindowExec: No Partition Defined for Window operation! Moving all data to a single partition, this can cause serious performance degradation.\n",
      "25/06/26 22:22:13 WARN WindowExec: No Partition Defined for Window operation! Moving all data to a single partition, this can cause serious performance degradation.\n",
      "25/06/26 22:22:13 WARN WindowExec: No Partition Defined for Window operation! Moving all data to a single partition, this can cause serious performance degradation.\n",
      "25/06/26 22:22:13 WARN WindowExec: No Partition Defined for Window operation! Moving all data to a single partition, this can cause serious performance degradation.\n",
      "25/06/26 22:22:13 WARN WindowExec: No Partition Defined for Window operation! Moving all data to a single partition, this can cause serious performance degradation.\n",
      "25/06/26 22:22:13 WARN WindowExec: No Partition Defined for Window operation! Moving all data to a single partition, this can cause serious performance degradation.\n",
      "25/06/26 22:22:13 WARN WindowExec: No Partition Defined for Window operation! Moving all data to a single partition, this can cause serious performance degradation.\n",
      "25/06/26 22:22:13 WARN WindowExec: No Partition Defined for Window operation! Moving all data to a single partition, this can cause serious performance degradation.\n",
      "25/06/26 22:22:13 WARN WindowExec: No Partition Defined for Window operation! Moving all data to a single partition, this can cause serious performance degradation.\n",
      "25/06/26 22:22:13 WARN WindowExec: No Partition Defined for Window operation! Moving all data to a single partition, this can cause serious performance degradation.\n",
      "25/06/26 22:22:13 WARN WindowExec: No Partition Defined for Window operation! Moving all data to a single partition, this can cause serious performance degradation.\n",
      "25/06/26 22:22:13 WARN WindowExec: No Partition Defined for Window operation! Moving all data to a single partition, this can cause serious performance degradation.\n",
      "25/06/26 22:22:13 WARN WindowExec: No Partition Defined for Window operation! Moving all data to a single partition, this can cause serious performance degradation.\n",
      "25/06/26 22:22:13 WARN WindowExec: No Partition Defined for Window operation! Moving all data to a single partition, this can cause serious performance degradation.\n",
      "25/06/26 22:22:13 WARN WindowExec: No Partition Defined for Window operation! Moving all data to a single partition, this can cause serious performance degradation.\n",
      "25/06/26 22:22:13 WARN WindowExec: No Partition Defined for Window operation! Moving all data to a single partition, this can cause serious performance degradation.\n",
      "25/06/26 22:22:13 WARN WindowExec: No Partition Defined for Window operation! Moving all data to a single partition, this can cause serious performance degradation.\n",
      "25/06/26 22:22:13 WARN WindowExec: No Partition Defined for Window operation! Moving all data to a single partition, this can cause serious performance degradation.\n",
      "25/06/26 22:22:13 WARN WindowExec: No Partition Defined for Window operation! Moving all data to a single partition, this can cause serious performance degradation.\n",
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "# Função para salvar os dados em um base Postgresql\n",
    "\n",
    "def salvar(df, tabela):\n",
    "    url = f\"jdbc:postgresql://{DB_HOST}:{DB_PORT}/{DB_NAME}\"\n",
    "    df.write \\\n",
    "      .format(\"jdbc\") \\\n",
    "      .option(\"url\", url) \\\n",
    "      .option(\"dbtable\", tabela) \\\n",
    "      .option(\"user\", DB_USER) \\\n",
    "      .option(\"password\", DB_PASSWORD) \\\n",
    "      .option(\"driver\", \"org.postgresql.Driver\") \\\n",
    "      .mode('overwrite') \\\n",
    "      .save()\n",
    "\n",
    "salvar(df_data, \"dim_data\")\n",
    "salvar(df_localidade, \"dim_localidade\")\n",
    "salvar(df_sexo, \"dim_sexo\")\n",
    "salvar(df_faixa_etaria, \"dim_faixa_etaria\")\n",
    "salvar(df_tipo_cancer, \"dim_tipo_cancer\")\n",
    "salvar(df_metrica, \"dim_metrica\")\n",
    "salvar(df_fato_clima, \"fato_clima\")\n",
    "salvar(df_fato_cancer, \"fato_cancer\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "973bddda",
   "metadata": {},
   "outputs": [],
   "source": [
    "def executa_sql_postgres(sql_texto):\n",
    "    conn = psycopg2.connect(\n",
    "        dbname=DB_NAME,\n",
    "        user=DB_USER,\n",
    "        password=DB_PASSWORD,\n",
    "        host=DB_HOST,\n",
    "        port=DB_PORT\n",
    "    )\n",
    "    try:\n",
    "        with conn:\n",
    "            with conn.cursor() as cur:\n",
    "                cur.execute(sql_texto)\n",
    "    finally:\n",
    "        conn.close()\n",
    "\n",
    "# Criação das Views que serão utilizadas nas consultas\n",
    "\n",
    "sql_dim_ano = \"\"\"\n",
    "CREATE OR REPLACE VIEW vw_ano AS\n",
    "SELECT\n",
    "    ROW_NUMBER() OVER (ORDER BY data_ano) AS ano_pk,\n",
    "    data_ano AS cancer_ano,\n",
    "    data_decada AS cancer_decada\n",
    "FROM (\n",
    "    SELECT DISTINCT\n",
    "        data_ano,\n",
    "        data_decada\n",
    "    FROM\n",
    "        dim_data\n",
    ") AS sub;\n",
    "\"\"\"\n",
    "\n",
    "sql_dim_dia = \"\"\"\n",
    "CREATE OR REPLACE VIEW vw_dia AS\n",
    "SELECT\n",
    "    data_pk,\n",
    "    data_completa AS clima_data_completa,\n",
    "    data_dia AS clima_dia,\n",
    "    data_mes AS clima_mes,\n",
    "    data_ano AS clima_ano,\n",
    "    data_decada AS clima_decada\n",
    "FROM dim_data;\n",
    "\"\"\"\n",
    "\n",
    "sql_dim_estado = \"\"\"\n",
    "CREATE OR REPLACE VIEW vw_estado AS\n",
    "SELECT\n",
    "    ROW_NUMBER() OVER (ORDER BY estado) AS estado_pk,\n",
    "    estado AS cancer_estado,\n",
    "    regiao AS cancer_regiao,\n",
    "    pais AS cancer_pais\n",
    "FROM (\n",
    "    SELECT DISTINCT\n",
    "        estado,\n",
    "        regiao,\n",
    "        pais\n",
    "    FROM\n",
    "        dim_localidade\n",
    ") AS sub;\n",
    "\"\"\"\n",
    "\n",
    "sql_dim_cidade = \"\"\"\n",
    "CREATE OR REPLACE VIEW vw_cidade AS\n",
    "SELECT\n",
    "    localidade_pk,\n",
    "    latitude,\n",
    "    longitude,\n",
    "    cidade AS clima_cidade,\n",
    "    estado AS clima_estado,\n",
    "    regiao AS clima_regiao,\n",
    "    pais AS clima_pais\n",
    "FROM dim_localidade;\n",
    "\"\"\"\n",
    "\n",
    "executa_sql_postgres(sql_dim_ano)\n",
    "executa_sql_postgres(sql_dim_dia)\n",
    "executa_sql_postgres(sql_dim_cidade)\n",
    "executa_sql_postgres(sql_dim_estado)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
